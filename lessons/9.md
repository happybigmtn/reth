# Lesson 9: Database Transactions and Cursors

*"The worthwhile problems are the ones you can really solve or help solve, the ones you can really contribute something to." - Richard Feynman*

## Files with Inline Comments for This Lesson
- `crates/storage/db/src/implementation/mdbx/tx.rs` - Transaction implementation
- `crates/storage/db/src/implementation/mdbx/cursor.rs` - Cursor implementation
- `crates/storage/db-api/src/transaction.rs` - Transaction traits

## Understanding Database Transactions

Transactions are the fundamental unit of work in databases. They provide ACID guarantees:

- **Atomicity**: All operations succeed or all fail
- **Consistency**: Database remains valid after transaction
- **Isolation**: Concurrent transactions don't interfere  
- **Durability**: Committed changes survive crashes

## Transaction Types in Reth

### Read-Only Transactions (RO)

```rust
// Multiple readers can work concurrently
let tx1 = db.tx()?;  // Read transaction 1
let tx2 = db.tx()?;  // Read transaction 2 (concurrent)

// Both can read simultaneously
let account1 = tx1.get::<AccountsTable>(address)?;
let account2 = tx2.get::<AccountsTable>(address)?;
```

Benefits:
- No blocking between readers
- Snapshot isolation (sees consistent view)
- Automatic cleanup on drop

### Read-Write Transactions (RW)

```rust
// Only one writer at a time
let tx = db.tx_mut()?;  // Exclusive write access

// Make changes
tx.put::<AccountsTable>(address, new_account)?;
tx.delete::<StorageTable>(old_key, None)?;

// Changes visible only after commit
tx.commit()?;
```

Properties:
- Exclusive access (no other writers)
- Changes buffered until commit
- Can rollback with abort()

## The Transaction Lifecycle

### 1. Opening a Transaction

```rust
impl<K: TransactionKind> Tx<K> {
    pub fn new_with_metrics(
        inner: Transaction<K>,
        env_metrics: Option<Arc<DatabaseEnvMetrics>>,
    ) -> Result<Self> {
        // Record transaction start time
        let start = Instant::now();
        
        // Track open transactions for monitoring
        if let Some(metrics) = env_metrics {
            metrics.record_opened_transaction(mode);
        }
        
        Ok(Tx { inner, metrics_handler })
    }
}
```

### 2. Performing Operations

```rust
// Read operation
fn get<T: Table>(&self, key: T::Key) -> Result<Option<T::Value>> {
    // Encode key for storage
    let encoded_key = key.encode();
    
    // Perform MDBX operation
    let raw_value = self.inner.get(dbi, encoded_key)?;
    
    // Decode and decompress value
    raw_value.map(|v| T::Value::decompress(v)).transpose()
}

// Write operation  
fn put<T: Table>(&self, key: T::Key, value: T::Value) -> Result<()> {
    // Encode and compress for storage
    let encoded_key = key.encode();
    let compressed_value = value.compress();
    
    // Write to MDBX (buffered until commit)
    self.inner.put(dbi, encoded_key, compressed_value, WriteFlags::UPSERT)?;
    
    Ok(())
}
```

### 3. Committing or Aborting

```rust
// Commit makes changes permanent
fn commit(self) -> Result<bool> {
    // Measure commit latency
    let start = Instant::now();
    
    // MDBX commit - flushes to disk
    let (success, latency) = self.inner.commit()?;
    
    // Record metrics
    self.metrics.record_commit(start.elapsed(), latency);
    
    Ok(success)
}

// Abort discards all changes
fn abort(self) {
    // Simply drop the transaction
    drop(self.inner);
    // MDBX automatically rolls back
}
```

## MVCC - Multi-Version Concurrency Control

MDBX uses MVCC to allow concurrent readers without blocking:

```rust
// Time T1: Writer creates new version
let tx_write = db.tx_mut()?;
tx_write.put::<AccountsTable>(addr, Account { balance: 100 })?;

// Time T2: Reader still sees old version
let tx_read = db.tx()?;
let account = tx_read.get::<AccountsTable>(addr)?;  // Sees old balance

// Time T3: Writer commits
tx_write.commit()?;

// Time T4: New reader sees new version
let tx_read2 = db.tx()?;
let account = tx_read2.get::<AccountsTable>(addr)?;  // Sees balance: 100
```

## Long Transaction Detection

Long-running read transactions are problematic:

```rust
const LONG_TRANSACTION_DURATION: Duration = Duration::from_secs(60);

impl MetricsHandler {
    fn log_backtrace_on_long_read_transaction(&self) {
        let duration = self.start.elapsed();
        
        if duration >= LONG_TRANSACTION_DURATION {
            // Log warning with backtrace
            warn!(
                "Read transaction open for {:?} - may prevent garbage collection",
                duration
            );
            
            // In debug builds, show where it was opened
            #[cfg(debug_assertions)]
            warn!("Opened at: {}", self.open_backtrace);
        }
    }
}
```

Why this matters:
- MDBX can't reclaim space while old readers exist
- Database file grows unnecessarily
- Performance degrades over time

## Cursors - Efficient Iteration

Cursors maintain position in the B+ tree for efficient sequential access:

### Basic Cursor Operations

```rust
// Create a cursor for a table
let mut cursor = tx.cursor::<HeadersTable>()?;

// Navigate to first entry
if let Some((number, header)) = cursor.first()? {
    println!("First block: {}", number);
}

// Seek to specific position
cursor.seek(BlockNumber(1000))?;

// Iterate forward
while let Some((number, header)) = cursor.next()? {
    if number > BlockNumber(2000) { break; }
    // Process blocks 1000-2000
}
```

### Cursor vs Repeated Lookups

```rust
// Inefficient - O(n log n)
for block_num in 1000..2000 {
    let header = tx.get::<HeadersTable>(block_num)?;
    process(header);
}

// Efficient with cursor - O(n)
let mut cursor = tx.cursor::<HeadersTable>()?;
cursor.seek(BlockNumber(1000))?;
while let Some((num, header)) = cursor.next()? {
    if num >= BlockNumber(2000) { break; }
    process(Some(header));
}
```

### Advanced Cursor Patterns

#### 1. Range Iteration

```rust
// Walk a specific range
let walker = cursor.walk_range(BlockNumber(1000)..=BlockNumber(2000))?;
for result in walker {
    let (number, header) = result?;
    // Process header
}
```

#### 2. Reverse Iteration

```rust
// Walk backwards from a point
cursor.seek(BlockNumber(2000))?;
while let Some((number, header)) = cursor.prev()? {
    if number < BlockNumber(1000) { break; }
    // Process in reverse order
}
```

#### 3. Prefix Iteration (DupSort)

```rust
// For tables with duplicate keys
let mut cursor = tx.cursor_dup::<StorageTable>()?;

// Seek to address
cursor.seek_exact((address, StorageKey::ZERO))?;

// Iterate all storage for this address
while let Some(((addr, key), value)) = cursor.next_dup()? {
    if addr != address { break; }  // Moved to next address
    // Process storage slot
}
```

## Cursor Implementation Details

### Buffer Management

```rust
pub struct Cursor<K: TransactionKind, T: Table> {
    inner: reth_libmdbx::Cursor<K>,
    buf: Vec<u8>,  // Reusable decompression buffer
    _phantom: PhantomData<T>,
}

impl<K, T> Cursor<K, T> {
    fn get_value(&mut self, raw: &[u8]) -> Result<T::Value> {
        // Reuse buffer to avoid allocations
        self.buf.clear();
        
        // Decompress into buffer
        decompress_to(&mut self.buf, raw)?;
        
        // Decode from buffer
        T::Value::decode(&self.buf)
    }
}
```

### Type Safety

The cursor is generic over:
- `K: TransactionKind` - Ensures read cursors can't write
- `T: Table` - Ensures type-safe access to specific tables

```rust
// This won't compile - type safety!
let cursor = tx.cursor::<AccountsTable>()?;
// cursor.put(header)?;  // ERROR: AccountsTable != HeadersTable
```

## Write Cursors

Write cursors support additional operations:

```rust
impl<T: Table> DbCursorRW<T> for Cursor<RW, T> {
    // Insert at current position
    fn insert(&mut self, key: T::Key, value: T::Value) -> Result<()> {
        // Cursor maintains position after insert
        self.inner.put(key.encode(), value.compress(), WriteFlags::NO_OVERWRITE)?;
        Ok(())
    }
    
    // Delete current entry
    fn delete_current(&mut self) -> Result<()> {
        self.inner.del(WriteFlags::CURRENT)?;
        Ok(())
    }
    
    // Append (optimization for sorted inserts)
    fn append(&mut self, key: T::Key, value: T::Value) -> Result<()> {
        // Skip tree traversal if key > all existing
        self.inner.put(key.encode(), value.compress(), WriteFlags::APPEND)?;
        Ok(())
    }
}
```

## Performance Considerations

### 1. Transaction Duration

```rust
// Bad - long transaction
let tx = db.tx()?;
let data = tx.get(key)?;
expensive_computation(&data);  // Transaction still open!
tx.commit()?;

// Good - minimize transaction lifetime
let data = {
    let tx = db.tx()?;
    tx.get(key)?
};  // Transaction closed
expensive_computation(&data);
```

### 2. Batch Operations

```rust
// Inefficient - many transactions
for (key, value) in updates {
    let tx = db.tx_mut()?;
    tx.put(key, value)?;
    tx.commit()?;  // Disk sync each time
}

// Efficient - batch in one transaction
let tx = db.tx_mut()?;
for (key, value) in updates {
    tx.put(key, value)?;
}
tx.commit()?;  // One disk sync
```

### 3. Cursor vs Random Access

```rust
// Use cursor for sequential access
let mut cursor = tx.cursor::<T>()?;
cursor.seek(start)?;
while condition {
    cursor.next()?;  // O(1) per step
}

// Use get for random access
let value = tx.get::<T>(random_key)?;  // O(log n)
```

## Common Patterns

### 1. Read-Modify-Write

```rust
fn increment_nonce(db: &DB, address: Address) -> Result<()> {
    let tx = db.tx_mut()?;
    
    // Read current value
    let mut account = tx.get::<AccountsTable>(address)?
        .ok_or("Account not found")?;
    
    // Modify
    account.nonce += 1;
    
    // Write back
    tx.put::<AccountsTable>(address, account)?;
    
    tx.commit()
}
```

### 2. Conditional Updates

```rust
fn transfer_if_sufficient(
    tx: &Tx<RW>,
    from: Address,
    to: Address,
    amount: U256,
) -> Result<bool> {
    // Check balance
    let mut from_account = tx.get::<AccountsTable>(from)?
        .ok_or("From account not found")?;
    
    if from_account.balance < amount {
        return Ok(false);  // Insufficient funds
    }
    
    // Perform transfer
    from_account.balance -= amount;
    tx.put::<AccountsTable>(from, from_account)?;
    
    let mut to_account = tx.get::<AccountsTable>(to)?
        .unwrap_or_default();
    to_account.balance += amount;
    tx.put::<AccountsTable>(to, to_account)?;
    
    Ok(true)
}
```

### 3. Cursor-based Aggregation

```rust
fn sum_balances_in_range(
    tx: &Tx<impl TransactionKind>,
    start: Address,
    end: Address,
) -> Result<U256> {
    let mut cursor = tx.cursor::<AccountsTable>()?;
    let mut total = U256::ZERO;
    
    cursor.seek(start)?;
    while let Some((addr, account)) = cursor.next()? {
        if addr > end { break; }
        total += account.balance;
    }
    
    Ok(total)
}
```

## Assignments with Solutions

### 1. Implement a function to find all transactions in a block range

```rust
use reth_db::transaction::DbTx;
use reth_primitives::{BlockNumber, TransactionSigned};

fn get_transactions_in_range(
    tx: &impl DbTx,
    start_block: BlockNumber,
    end_block: BlockNumber,
) -> Result<Vec<TransactionSigned>, DatabaseError> {
    let mut transactions = Vec::new();
    
    // Get a cursor for the block bodies table
    let mut block_cursor = tx.cursor_read::<tables::BlockBodyIndices>()?;
    
    // Seek to start block
    block_cursor.seek(start_block)?;
    
    // Iterate through blocks
    while let Some((block_num, body_indices)) = block_cursor.next()? {
        if block_num > end_block {
            break;
        }
        
        // Get a cursor for transactions
        let mut tx_cursor = tx.cursor_read::<tables::Transactions>()?;
        
        // Seek to first transaction of this block
        tx_cursor.seek(body_indices.first_tx_num)?;
        
        // Read all transactions for this block
        for _ in 0..body_indices.tx_count {
            if let Some((_, transaction)) = tx_cursor.next()? {
                transactions.push(transaction);
            }
        }
    }
    
    Ok(transactions)
}
```

### 2. Write a function to clean up old receipts

```rust
fn prune_receipts_before(
    db: &DatabaseEnv,
    before_block: BlockNumber,
) -> Result<usize, DatabaseError> {
    let tx = db.tx_mut()?;
    let mut deleted = 0;
    
    // Find the last transaction number for the cutoff block
    let cutoff_tx_num = if let Some(body) = tx.get::<tables::BlockBodyIndices>(before_block)? {
        body.first_tx_num
    } else {
        return Ok(0);  // Block not found
    };
    
    // Use a write cursor to delete efficiently
    let mut cursor = tx.cursor_write::<tables::Receipts>()?;
    
    // Start from beginning
    cursor.first()?;
    
    // Delete all receipts before cutoff
    while let Some((tx_num, _receipt)) = cursor.current()? {
        if tx_num >= cutoff_tx_num {
            break;  // Reached cutoff
        }
        
        cursor.delete_current()?;
        deleted += 1;
        
        // Move to next (delete_current doesn't advance)
        cursor.next()?;
    }
    
    tx.commit()?;
    Ok(deleted)
}
```

### 3. Implement efficient account iteration with filtering

```rust
fn find_accounts_with_balance_above(
    tx: &impl DbTx,
    min_balance: U256,
    max_results: usize,
) -> Result<Vec<(Address, Account)>, DatabaseError> {
    let mut results = Vec::with_capacity(max_results);
    let mut cursor = tx.cursor_read::<tables::PlainAccountState>()?;
    
    // Start from beginning
    cursor.first()?;
    
    // Iterate all accounts
    while let Some((address, account)) = cursor.next()? {
        if account.balance > min_balance {
            results.push((address, account));
            
            if results.len() >= max_results {
                break;  // Found enough
            }
        }
    }
    
    Ok(results)
}

// Optimized version using parallel chunks
fn find_accounts_parallel(
    db: &DatabaseEnv,
    min_balance: U256,
) -> Result<Vec<(Address, Account)>, DatabaseError> {
    use rayon::prelude::*;
    use std::sync::Mutex;
    
    // Divide address space into chunks
    let chunk_size = Address::MAX / 16;  // 16 parallel workers
    let results = Mutex::new(Vec::new());
    
    (0..16).into_par_iter().try_for_each(|i| -> Result<(), DatabaseError> {
        let tx = db.tx()?;
        let mut cursor = tx.cursor_read::<tables::PlainAccountState>()?;
        
        // Each worker processes a range
        let start = Address::from(i * chunk_size);
        let end = Address::from((i + 1) * chunk_size);
        
        cursor.seek(start)?;
        
        let mut local_results = Vec::new();
        while let Some((addr, account)) = cursor.next()? {
            if addr >= end { break; }
            
            if account.balance > min_balance {
                local_results.push((addr, account));
            }
        }
        
        // Merge results
        results.lock().unwrap().extend(local_results);
        Ok(())
    })?;
    
    Ok(results.into_inner().unwrap())
}
```

## Questions to Ponder - Detailed Answers

### 1. Why does MDBX limit to one writer?

Single writer ensures:
- **Consistency**: No write-write conflicts
- **Simplicity**: No complex locking protocols
- **Performance**: No coordination overhead
- **Cache efficiency**: Writers can use full CPU cache

Multiple writers would require:
- Fine-grained locking (complexity)
- Conflict resolution (overhead)
- More memory for version tracking

MDBX optimizes for the common case: many readers, occasional writes.

### 2. Why are long read transactions problematic?

MVCC keeps old versions for active readers:
```
Time T1: Account A = 100 (Reader 1 starts)
Time T2: Writer changes A = 200
Time T3: Writer changes A = 300
Time T4: Writer changes A = 400
```

MDBX must keep version 100 for Reader 1, wasting space for versions 200, 300.

Problems:
- Database file grows (can't reclaim space)
- More versions to skip during searches
- Memory pressure from page cache
- Write amplification

### 3. When to use cursors vs direct lookups?

Use cursors for:
- Sequential access (next block, next account)
- Range queries (blocks 1000-2000)
- Prefix scans (all storage for address)
- Bulk operations (delete old data)

Use direct lookups for:
- Random access patterns
- Single key lookups
- Existence checks
- Simple read-modify-write

Rule of thumb: Use cursor if accessing > 2 consecutive keys.