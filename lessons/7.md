# Lesson 7: Database Tables and Schema

*"The worthwhile problems are the ones you can really solve or help solve, the ones you can really contribute something to." - Richard Feynman*

## Files with Inline Comments for This Lesson
- `crates/storage/db/src/tables/mod.rs` - Table definitions and schema
- `crates/storage/db-api/src/table.rs` - Table trait definition
- `crates/storage/db/src/tables/codecs/mod.rs` - Encoding/decoding for storage

## Understanding Reth's Database Schema

In Lesson 6, we learned about MDBX as the storage engine. Now let's explore how Reth organizes blockchain data into tables. Think of tables as labeled filing cabinets, each designed to store a specific type of information efficiently.

## The Table Trait - Type-Safe Storage

```rust
pub trait Table: Send + Sync + Debug + 'static {
    /// Table name as it appears in the database
    const NAME: &'static str;
    
    /// Key type - what we search by
    type Key: Key;
    
    /// Value type - what we store
    type Value: Value;
    
    /// Optional subkey for composite keys
    type SubKey: ?Sized = ();
}
```

This trait ensures:
1. **Type Safety**: Can't put accounts in the blocks table
2. **Automatic Serialization**: Keys and values know how to encode/decode
3. **Clear Schema**: The code is the documentation

## Reth's Table Categories

### 1. Canonical Chain Tables

These track the main chain:

```rust
table!(CanonicalHeaders, BlockNumber => HeaderHash);
table!(HeaderNumbers, HeaderHash => BlockNumber);
table!(Headers, BlockNumber => Header);
```

The relationship:
- `CanonicalHeaders`: "What's the canonical hash at height N?"
- `HeaderNumbers`: "What height is this hash at?"
- `Headers`: "Give me the full header at height N"

### 2. Block Body Tables

```rust
table!(BlockBodies, BlockNumber => StoredBlockBody);
table!(BlockOmmers, BlockNumber => Vec<Header>);
table!(Transactions, TxNumber => TransactionSignedNoHash);
```

Design decisions:
- Bodies stored separately from headers (headers are accessed more frequently)
- Transactions deduplicated with global numbering
- Ommers (uncles) stored separately (mostly empty post-merge)

### 3. Transaction Index Tables

```rust
table!(TransactionHashNumbers, TxHash => TxNumber);
table!(TransactionBlocks, TxNumber => BlockNumber);
```

Two-step lookup for efficiency:
1. Hash → TxNumber (fixed size)
2. TxNumber → Transaction data

This saves space because we store the hash only once.

### 4. State Tables

Current state:
```rust
table!(PlainAccountState, Address => Account);
table!(PlainStorageState, (Address, StorageKey) => StorageValue);
table!(Bytecodes, CodeHash => Bytecode);
```

Historical state:
```rust
table!(AccountChangeSets, BlockNumber => AccountChangeSet);
table!(StorageChangeSets, (BlockNumber, Address) => StorageChangeSet);
```

Key insight: We store current state directly, but historical changes as "changesets" to save space.

### 5. Hashed State Tables

```rust
table!(HashedAccounts, HashedAddress => Account);
table!(HashedStorages, (HashedAddress, HashedStorageKey) => StorageValue);
```

These store keccak256(address) instead of address for trie computation. The trie needs hashed keys, so we pre-compute them.

### 6. Trie Tables

```rust
table!(AccountsTrie, StoredNibbles => BranchNode);
table!(StoragesTrie, (HashedAddress, StoredNibbles) => BranchNode);
```

These store the actual Merkle Patricia Trie nodes. `StoredNibbles` are the path in the trie (nibbles = half-bytes).

### 7. History Index Tables

```rust
table!(AccountsHistory, ShardedKey<Address> => BlockNumberList);
table!(StoragesHistory, ShardedKey<(Address, StorageKey)> => BlockNumberList);
```

These are "inverted indices" - given an address, find all blocks where it changed. The `ShardedKey` includes the highest block number for efficient range queries.

## Sharded Keys - A Performance Optimization

```rust
pub struct ShardedKey<T> {
    pub key: T,
    pub highest_block_number: BlockNumber,
}
```

Why sharding?
1. **Locality**: Changes to an address cluster together
2. **Range queries**: "Find all changes between blocks X and Y"
3. **Pruning**: Easy to remove old shards

Example: To find when address A changed between blocks 1000-2000:
```rust
// Seek to ShardedKey { key: A, highest_block_number: 1000 }
// Iterate until highest_block_number > 2000
```

## Encoding and Compression

Reth uses custom encoding for space efficiency:

### Compact Encoding
```rust
impl Compact for BlockNumber {
    fn to_compact(&self, buf: &mut Vec<u8>) {
        // Uses variable-length encoding
        // 1 byte for 0-127, 2 bytes for 128-16383, etc.
    }
}
```

### Compression Flags
Some types use compression:
```rust
pub struct Transactions {
    pub transactions: Vec<TransactionSigned>,
}

impl Compress for Transactions {
    type Compressed = Vec<u8>;
    
    fn compress(self) -> Self::Compressed {
        // Uses zstd compression
        zstd::encode(&self.encode(), COMPRESSION_LEVEL)
    }
}
```

## Table Usage Patterns

### 1. Point Lookups
```rust
// Get account at address
let account = tx.get::<PlainAccountState>(address)?;
```

### 2. Range Queries
```rust
// Get all blocks from 1000 to 2000
let mut cursor = tx.cursor::<Headers>()?;
let walker = cursor.walk_range(1000..=2000)?;
for (number, header) in walker {
    // Process header
}
```

### 3. Prefix Iteration
```rust
// Get all storage for an address
let mut cursor = tx.cursor::<PlainStorageState>()?;
cursor.seek((address, StorageKey::ZERO))?;
while let Some(((addr, key), value)) = cursor.next()? {
    if addr != address { break; }
    // Process storage entry
}
```

## Performance Considerations

### 1. Key Ordering
Tables use specific key ordering for efficient range queries:
- `AccountsHistory`: Ordered by (Address, BlockNumber)
- `StorageChangeSets`: Ordered by (BlockNumber, Address)

Choose based on access pattern!

### 2. Duplication vs Normalization
Reth duplicates some data for performance:
- Transaction hashes stored separately from transactions
- Headers stored both individually and in bodies

Trade-off: Space for speed.

### 3. Composite Keys
```rust
table!(PlainStorageState, (Address, StorageKey) => StorageValue);
```

Composite keys enable efficient prefix queries: "Get all storage for address X".

## Migration and Versioning

Database schema evolves:
```rust
pub const TABLES: &[TableType] = &[
    TableType::Table(CanonicalHeaders::NAME),
    TableType::Table(Headers::NAME),
    // ... all tables listed for migration tools
];
```

This list ensures:
1. All tables are created on init
2. Migration tools know what exists
3. Clear documentation of schema

## Assignments with Solutions

### 1. Calculate storage for 1M accounts with 10 storage slots each

Account storage:
- Address: 20 bytes
- Account: ~80 bytes (nonce, balance, code hash)
- Total: 100 bytes × 1M = 100 MB

Storage slots:
- Key: 20 (address) + 32 (slot) = 52 bytes  
- Value: 32 bytes
- Total: 84 bytes × 10M = 840 MB

Plus indices and overhead: ~1 GB total

### 2. Design a table for ERC-20 balances
```rust
// Option 1: Specific table
table!(TokenBalances, (TokenAddress, HolderAddress) => U256);

// Option 2: Use existing storage table
// ERC-20 balances are at: keccak256(holder ++ slot_0)
// So they're already in PlainStorageState!

// Better approach: Build index on top
table!(TokenHolders, TokenAddress => Vec<HolderAddress>);
```

### 3. Write a function to find all transactions from an address
```rust
fn find_transactions_from(
    tx: &impl DbTx,
    sender: Address,
    block_range: Range<BlockNumber>,
) -> Result<Vec<TransactionSigned>> {
    let mut transactions = Vec::new();
    
    // Iterate through blocks
    for block_num in block_range {
        // Get block body
        if let Some(body) = tx.get::<BlockBodies>(block_num)? {
            // Get transaction numbers
            let tx_start = body.tx_num_range.start;
            let tx_end = body.tx_num_range.end;
            
            // Fetch each transaction
            for tx_num in tx_start..tx_end {
                if let Some(tx) = tx.get::<Transactions>(tx_num)? {
                    // Check sender (would need recovery)
                    if tx.recover_signer()? == sender {
                        transactions.push(tx);
                    }
                }
            }
        }
    }
    
    Ok(transactions)
}
```

## Questions to Ponder - Detailed Answers

### 1. Why separate Headers and Bodies tables?

Different access patterns:
- **Headers**: Accessed frequently for validation, chain navigation
- **Bodies**: Only needed for full block data, execution

Separating them:
- Improves cache efficiency (headers fit in memory)
- Allows partial node implementations
- Reduces I/O for common operations

### 2. Why use TxNumber instead of storing transactions in blocks?

Deduplication and efficiency:
- Same transaction can appear in multiple uncle blocks
- Sequential TxNumbers enable efficient range queries
- Smaller indices (u64 vs full transaction)
- Better compression of similar transactions

### 3. How do ShardedKeys improve performance?

They solve the "needle in haystack" problem:
- Without sharding: Scan entire history to find changes
- With sharding: Jump directly to relevant block range
- Trade-off: Larger keys for faster queries

Real example: Finding when account X changed in blocks 15M-16M:
- Without sharding: Scan all 16M blocks
- With sharding: Seek to (X, 15M), scan ~1000 entries