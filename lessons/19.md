# Lesson 19: Staged Sync

*"What I cannot create, I do not understand." - Richard Feynman*

## Files with Inline Comments for This Lesson
- `crates/stages/api/src/stage.rs` - Stage trait definition
- `crates/stages/api/src/pipeline.rs` - Pipeline orchestration
- `crates/stages/stages/src/stages/headers.rs` - Headers stage
- `crates/stages/stages/src/stages/execution.rs` - Execution stage

## Understanding Staged Sync

Staged sync is Reth's approach to synchronizing the blockchain efficiently. Instead of processing blocks sequentially, it breaks down sync into distinct stages that can be optimized independently:

```
Headers → Bodies → Execution → Merkle → Account Hashing → Storage Hashing → Transaction Lookup
   ↓         ↓          ↓           ↓              ↓                  ↓                ↓
Download  Download   Execute    Calculate      Hash          Hash            Index
Headers   Block      Trans-     State         Account       Storage      Transaction
Only      Bodies     actions    Root          Data          Data         Locations
```

## The Stage Trait

### Core Definition

```rust
/// A stage in the syncing pipeline
#[async_trait::async_trait]
pub trait Stage<DB>: Send + Sync {
    /// Execute the stage
    async fn execute(
        &mut self,
        provider: &DatabaseProviderRW<DB>,
        input: ExecInput,
    ) -> Result<ExecOutput, StageError>;
    
    /// Unwind the stage to a previous block
    async fn unwind(
        &mut self,
        provider: &DatabaseProviderRW<DB>,
        input: UnwindInput,
    ) -> Result<UnwindOutput, StageError>;
    
    /// Return the ID of the stage
    fn id(&self) -> StageId;
}
```

### Stage Input and Output

```rust
/// Input for stage execution
#[derive(Debug, Clone)]
pub struct ExecInput {
    /// The block to execute up to
    pub target: Option<BlockNumber>,
    /// Checkpoint of the previous stage run
    pub checkpoint: Option<StageCheckpoint>,
}

/// Output of stage execution
#[derive(Debug, Clone)]
pub struct ExecOutput {
    /// How far the stage got
    pub checkpoint: StageCheckpoint,
    /// Whether the stage is done
    pub done: bool,
}

/// Progress checkpoint for a stage
#[derive(Debug, Clone)]
pub struct StageCheckpoint {
    /// The block number
    pub block_number: BlockNumber,
    /// Stage-specific progress data
    pub stage_checkpoint: Option<Vec<u8>>,
}
```

## Pipeline Architecture

### The Pipeline Orchestrator

```rust
pub struct Pipeline<DB> {
    /// Stages to run in order
    stages: Vec<Box<dyn Stage<DB>>>,
    /// Maximum block to sync to
    max_block: Option<BlockNumber>,
    /// Progress tracking
    progress: PipelineProgress,
}

impl<DB> Pipeline<DB> {
    /// Run the pipeline
    pub async fn run(&mut self) -> Result<(), PipelineError> {
        loop {
            // Run each stage in sequence
            for stage in &mut self.stages {
                let input = self.create_input_for_stage(stage.id())?;
                
                // Execute the stage
                let output = stage.execute(&self.provider, input).await?;
                
                // Update progress
                self.progress.update(stage.id(), output.checkpoint);
                
                // Check if we should continue
                if !output.done {
                    break; // This stage isn't done, restart from it
                }
            }
            
            // Check if all stages are complete
            if self.all_stages_done() {
                break;
            }
        }
        
        Ok(())
    }
}
```

## Key Stages

### 1. Headers Stage

Downloads and validates block headers:

```rust
pub struct HeaderStage {
    /// Header downloader
    downloader: HeaderDownloader,
    /// Consensus engine for validation
    consensus: Arc<dyn Consensus>,
}

impl<DB> Stage<DB> for HeaderStage {
    async fn execute(
        &mut self,
        provider: &DatabaseProviderRW<DB>,
        input: ExecInput,
    ) -> Result<ExecOutput, StageError> {
        let start_block = input.checkpoint
            .map(|cp| cp.block_number + 1)
            .unwrap_or(0);
            
        // Download headers
        let headers = self.downloader
            .download_headers(start_block, input.target)
            .await?;
            
        // Validate and insert headers
        for header in headers {
            // Validate header
            self.consensus.validate_header(&header)?;
            
            // Insert into database
            provider.insert_header(header)?;
        }
        
        Ok(ExecOutput {
            checkpoint: StageCheckpoint {
                block_number: last_header_number,
                stage_checkpoint: None,
            },
            done: reached_target,
        })
    }
}
```

### 2. Bodies Stage

Downloads transaction and uncle/ommer data:

```rust
pub struct BodiesStage {
    /// Body downloader
    downloader: BodyDownloader,
}

impl<DB> Stage<DB> for BodiesStage {
    async fn execute(
        &mut self,
        provider: &DatabaseProviderRW<DB>,
        input: ExecInput,
    ) -> Result<ExecOutput, StageError> {
        // Get headers that need bodies
        let headers = provider.headers_without_bodies(
            input.checkpoint.map(|cp| cp.block_number + 1).unwrap_or(0),
            input.target,
        )?;
        
        // Download bodies
        for header in headers {
            let body = self.downloader
                .download_body(&header.hash())
                .await?;
                
            // Store transactions
            let tx_id = provider.insert_transactions(body.transactions)?;
            
            // Store block body indices
            provider.insert_block_body_indices(
                header.number,
                BlockBodyIndices {
                    first_tx_num: tx_id,
                    tx_count: body.transactions.len() as u64,
                },
            )?;
        }
        
        Ok(ExecOutput {
            checkpoint: StageCheckpoint {
                block_number: last_block,
                stage_checkpoint: None,
            },
            done: true,
        })
    }
}
```

### 3. Execution Stage

Executes transactions and updates state:

```rust
pub struct ExecutionStage {
    /// EVM executor factory
    executor_factory: ExecutorFactory,
}

impl<DB> Stage<DB> for ExecutionStage {
    async fn execute(
        &mut self,
        provider: &DatabaseProviderRW<DB>,
        input: ExecInput,
    ) -> Result<ExecOutput, StageError> {
        let start_block = input.checkpoint
            .map(|cp| cp.block_number + 1)
            .unwrap_or(0);
            
        // Execute blocks
        for block_number in start_block..=target_block {
            // Load block
            let block = provider.block_by_number(block_number)?
                .ok_or(StageError::MissingBlock)?;
                
            // Create executor
            let mut executor = self.executor_factory.with_state(provider);
            
            // Execute block
            let BlockExecutionOutput { state, receipts, .. } = 
                executor.execute_block(&block)?;
                
            // Write state changes
            state.write_to_db(provider)?;
            
            // Write receipts
            provider.insert_receipts(block_number, receipts)?;
            
            // Commit periodically
            if block_number % 1000 == 0 {
                provider.commit()?;
            }
        }
        
        Ok(ExecOutput {
            checkpoint: StageCheckpoint {
                block_number: target_block,
                stage_checkpoint: None,
            },
            done: true,
        })
    }
}
```

## Stage Dependencies and Ordering

Stages must run in a specific order due to dependencies:

```rust
/// Define the canonical stage order
pub fn default_stages<DB>() -> Vec<Box<dyn Stage<DB>>> {
    vec![
        Box::new(HeaderStage::new()),      // 1. Download headers
        Box::new(BodiesStage::new()),       // 2. Download bodies
        Box::new(SenderRecoveryStage::new()), // 3. Recover transaction senders
        Box::new(ExecutionStage::new()),    // 4. Execute transactions
        Box::new(MerkleStage::new()),       // 5. Calculate state root
        Box::new(AccountHashingStage::new()), // 6. Hash account data
        Box::new(StorageHashingStage::new()), // 7. Hash storage data
        Box::new(TransactionLookupStage::new()), // 8. Build tx index
        Box::new(IndexHistoryStage::new()), // 9. Build history indices
    ]
}
```

## Unwinding Stages

When reorgs happen, stages must be unwound in reverse order:

```rust
impl<DB> Pipeline<DB> {
    /// Unwind the pipeline to a previous block
    pub async fn unwind_to(&mut self, target: BlockNumber) -> Result<(), PipelineError> {
        // Unwind stages in reverse order
        for stage in self.stages.iter_mut().rev() {
            let checkpoint = self.progress.get(stage.id());
            
            if let Some(cp) = checkpoint {
                if cp.block_number > target {
                    let input = UnwindInput {
                        checkpoint: cp.clone(),
                        unwind_to: target,
                    };
                    
                    stage.unwind(&self.provider, input).await?;
                    
                    // Update progress
                    self.progress.update(stage.id(), StageCheckpoint {
                        block_number: target,
                        stage_checkpoint: None,
                    });
                }
            }
        }
        
        Ok(())
    }
}
```

## Checkpointing and Recovery

Stages save progress to handle interruptions:

```rust
/// Stage progress tracking
pub struct PipelineProgress {
    /// Progress for each stage
    checkpoints: HashMap<StageId, StageCheckpoint>,
}

impl PipelineProgress {
    /// Save progress to database
    pub fn save(&self, provider: &DatabaseProviderRW<DB>) -> Result<(), DatabaseError> {
        for (stage_id, checkpoint) in &self.checkpoints {
            provider.save_stage_checkpoint(*stage_id, checkpoint)?;
        }
        Ok(())
    }
    
    /// Load progress from database
    pub fn load(provider: &DatabaseProvider<DB>) -> Result<Self, DatabaseError> {
        let mut checkpoints = HashMap::new();
        
        for stage_id in StageId::ALL {
            if let Some(checkpoint) = provider.get_stage_checkpoint(stage_id)? {
                checkpoints.insert(stage_id, checkpoint);
            }
        }
        
        Ok(Self { checkpoints })
    }
}
```

## Performance Optimizations

### 1. Batch Processing

```rust
impl<DB> ExecutionStage<DB> {
    /// Execute blocks in batches for performance
    async fn execute_batch(
        &mut self,
        provider: &DatabaseProviderRW<DB>,
        blocks: Vec<Block>,
    ) -> Result<(), StageError> {
        // Pre-load all state needed for the batch
        let addresses: HashSet<_> = blocks.iter()
            .flat_map(|b| b.transactions.iter())
            .flat_map(|tx| tx.affected_addresses())
            .collect();
            
        let state = provider.basic_accounts(addresses)?;
        
        // Execute all blocks with cached state
        let mut executor = self.executor_factory.with_cached_state(state);
        
        for block in blocks {
            executor.execute_block(&block)?;
        }
        
        // Write all changes at once
        executor.finalize(provider)?;
        
        Ok(())
    }
}
```

### 2. Parallel Stage Execution

Some stages can run in parallel:

```rust
/// Stages that can run in parallel
pub struct ParallelStages {
    /// Account hashing stage
    account_hashing: AccountHashingStage,
    /// Storage hashing stage  
    storage_hashing: StorageHashingStage,
}

impl ParallelStages {
    pub async fn execute(
        &mut self,
        provider: DatabaseProviderRW<DB>,
    ) -> Result<(), StageError> {
        // Run both stages concurrently
        let (account_result, storage_result) = tokio::join!(
            self.account_hashing.execute(&provider.clone()),
            self.storage_hashing.execute(&provider.clone())
        );
        
        account_result?;
        storage_result?;
        
        Ok(())
    }
}
```

## Assignments

### Assignment 1: Custom Stage Implementation

Create a custom stage that indexes events:

```rust
use reth_stages::{Stage, ExecInput, ExecOutput, StageError, StageId};
use reth_db::{DatabaseProviderRW, tables};
use reth_primitives::{Log, B256};
use std::collections::HashMap;

pub struct EventIndexStage {
    /// Event signatures to index
    event_signatures: Vec<B256>,
}

#[async_trait::async_trait]
impl<DB> Stage<DB> for EventIndexStage {
    async fn execute(
        &mut self,
        provider: &DatabaseProviderRW<DB>,
        input: ExecInput,
    ) -> Result<ExecOutput, StageError> {
        let start_block = input.checkpoint
            .map(|cp| cp.block_number + 1)
            .unwrap_or(0);
        let target = input.target.unwrap_or(u64::MAX);
        
        // Create event index
        let mut event_index: HashMap<B256, Vec<(u64, usize)>> = HashMap::new();
        
        // Process blocks
        for block_number in start_block..=target {
            // Get receipts for this block
            let receipts = provider.receipts_by_block(block_number)?
                .ok_or(StageError::MissingData)?;
                
            // Index events
            for (tx_idx, receipt) in receipts.iter().enumerate() {
                for log in &receipt.logs {
                    if !log.topics.is_empty() {
                        let topic0 = log.topics[0];
                        
                        if self.event_signatures.contains(&topic0) {
                            event_index.entry(topic0)
                                .or_default()
                                .push((block_number, tx_idx));
                        }
                    }
                }
            }
            
            // Commit periodically
            if block_number % 100 == 0 {
                self.save_index(&event_index, provider)?;
                event_index.clear();
            }
        }
        
        // Save remaining
        self.save_index(&event_index, provider)?;
        
        Ok(ExecOutput {
            checkpoint: StageCheckpoint {
                block_number: target,
                stage_checkpoint: None,
            },
            done: true,
        })
    }
    
    async fn unwind(
        &mut self,
        provider: &DatabaseProviderRW<DB>,
        input: UnwindInput,
    ) -> Result<UnwindOutput, StageError> {
        // Remove indexed events after unwind_to
        // Implementation would delete from custom table
        
        Ok(UnwindOutput {
            checkpoint: StageCheckpoint {
                block_number: input.unwind_to,
                stage_checkpoint: None,
            },
        })
    }
    
    fn id(&self) -> StageId {
        StageId::Other("EventIndex")
    }
}

impl EventIndexStage {
    fn save_index(
        &self,
        index: &HashMap<B256, Vec<(u64, usize)>>,
        provider: &DatabaseProviderRW<DB>,
    ) -> Result<(), StageError> {
        // Save to a custom table
        // In practice, you'd define a custom table for this
        for (event_sig, locations) in index {
            for (block, tx_idx) in locations {
                // provider.put::<tables::EventIndex>(...)
                println!("Indexed event {} at block {} tx {}", event_sig, block, tx_idx);
            }
        }
        Ok(())
    }
}

// Usage
let stage = EventIndexStage {
    event_signatures: vec![
        // Transfer(address,address,uint256)
        B256::from_slice(&keccak256("Transfer(address,address,uint256)")[..]),
        // Approval(address,address,uint256)
        B256::from_slice(&keccak256("Approval(address,address,uint256)")[..]),
    ],
};
```

### Assignment 2: Stage Progress Tracking

Implement checkpointing for long-running stages:

```rust
use serde::{Serialize, Deserialize};

#[derive(Debug, Serialize, Deserialize)]
pub struct CustomStageProgress {
    /// Last processed item
    pub last_processed: u64,
    /// Items per second
    pub throughput: f64,
    /// Estimated time remaining
    pub eta_seconds: u64,
}

pub struct ProgressTrackingStage {
    /// Items to process per block
    items_per_block: u64,
    /// Start time
    start_time: Instant,
}

impl ProgressTrackingStage {
    fn calculate_progress(
        &self,
        current_block: u64,
        target_block: u64,
        items_processed: u64,
    ) -> CustomStageProgress {
        let elapsed = self.start_time.elapsed().as_secs_f64();
        let throughput = items_processed as f64 / elapsed;
        
        let remaining_blocks = target_block - current_block;
        let remaining_items = remaining_blocks * self.items_per_block;
        let eta_seconds = (remaining_items as f64 / throughput) as u64;
        
        CustomStageProgress {
            last_processed: items_processed,
            throughput,
            eta_seconds,
        }
    }
    
    fn save_progress(
        &self,
        progress: &CustomStageProgress,
        checkpoint: &mut StageCheckpoint,
    ) -> Result<(), StageError> {
        // Serialize progress to checkpoint
        checkpoint.stage_checkpoint = Some(
            bincode::serialize(progress)
                .map_err(|_| StageError::Other("Failed to serialize progress"))?
        );
        Ok(())
    }
    
    fn load_progress(
        &self,
        checkpoint: &StageCheckpoint,
    ) -> Result<Option<CustomStageProgress>, StageError> {
        match &checkpoint.stage_checkpoint {
            Some(data) => {
                let progress = bincode::deserialize(data)
                    .map_err(|_| StageError::Other("Failed to deserialize progress"))?;
                Ok(Some(progress))
            }
            None => Ok(None),
        }
    }
}

#[async_trait::async_trait]
impl<DB> Stage<DB> for ProgressTrackingStage {
    async fn execute(
        &mut self,
        provider: &DatabaseProviderRW<DB>,
        input: ExecInput,
    ) -> Result<ExecOutput, StageError> {
        // Load previous progress if resuming
        let previous_progress = input.checkpoint
            .as_ref()
            .and_then(|cp| self.load_progress(cp).ok())
            .flatten();
            
        let mut items_processed = previous_progress
            .map(|p| p.last_processed)
            .unwrap_or(0);
            
        let start_block = input.checkpoint
            .map(|cp| cp.block_number + 1)
            .unwrap_or(0);
            
        for block in start_block..=target {
            // Process items for this block
            for _ in 0..self.items_per_block {
                // Do work...
                items_processed += 1;
                
                // Update progress periodically
                if items_processed % 1000 == 0 {
                    let progress = self.calculate_progress(
                        block,
                        target,
                        items_processed,
                    );
                    
                    println!(
                        "Progress: {} items/sec, ETA: {} minutes",
                        progress.throughput,
                        progress.eta_seconds / 60,
                    );
                }
            }
        }
        
        let mut checkpoint = StageCheckpoint {
            block_number: target,
            stage_checkpoint: None,
        };
        
        let final_progress = self.calculate_progress(target, target, items_processed);
        self.save_progress(&final_progress, &mut checkpoint)?;
        
        Ok(ExecOutput {
            checkpoint,
            done: true,
        })
    }
}
```

### Assignment 3: Pipeline Monitoring

Create a monitoring system for the pipeline:

```rust
use std::sync::{Arc, RwLock};
use std::time::{Duration, Instant};

#[derive(Debug, Clone)]
pub struct StageMetrics {
    /// Stage name
    pub stage: StageId,
    /// Blocks processed
    pub blocks_processed: u64,
    /// Time spent
    pub duration: Duration,
    /// Blocks per second
    pub throughput: f64,
    /// Last error if any
    pub last_error: Option<String>,
}

pub struct PipelineMonitor {
    /// Metrics for each stage
    metrics: Arc<RwLock<HashMap<StageId, StageMetrics>>>,
}

impl PipelineMonitor {
    pub fn new() -> Self {
        Self {
            metrics: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    /// Record stage execution
    pub fn record_execution(
        &self,
        stage: StageId,
        start_block: u64,
        end_block: u64,
        duration: Duration,
        error: Option<StageError>,
    ) {
        let blocks = end_block.saturating_sub(start_block);
        let throughput = blocks as f64 / duration.as_secs_f64();
        
        let metrics = StageMetrics {
            stage,
            blocks_processed: blocks,
            duration,
            throughput,
            last_error: error.map(|e| e.to_string()),
        };
        
        self.metrics.write().unwrap().insert(stage, metrics);
    }
    
    /// Get current pipeline status
    pub fn status(&self) -> PipelineStatus {
        let metrics = self.metrics.read().unwrap();
        
        let total_blocks: u64 = metrics.values()
            .map(|m| m.blocks_processed)
            .sum();
            
        let total_time: Duration = metrics.values()
            .map(|m| m.duration)
            .sum();
            
        let avg_throughput = if !total_time.is_zero() {
            total_blocks as f64 / total_time.as_secs_f64()
        } else {
            0.0
        };
        
        PipelineStatus {
            stages: metrics.values().cloned().collect(),
            total_blocks,
            total_time,
            avg_throughput,
        }
    }
}

#[derive(Debug)]
pub struct PipelineStatus {
    pub stages: Vec<StageMetrics>,
    pub total_blocks: u64,
    pub total_time: Duration,
    pub avg_throughput: f64,
}

// Instrumented pipeline
pub struct MonitoredPipeline<DB> {
    inner: Pipeline<DB>,
    monitor: PipelineMonitor,
}

impl<DB> MonitoredPipeline<DB> {
    pub async fn run(&mut self) -> Result<(), PipelineError> {
        for stage in &mut self.inner.stages {
            let start = Instant::now();
            let input = self.inner.create_input_for_stage(stage.id())?;
            let start_block = input.checkpoint
                .map(|cp| cp.block_number)
                .unwrap_or(0);
                
            match stage.execute(&self.inner.provider, input).await {
                Ok(output) => {
                    self.monitor.record_execution(
                        stage.id(),
                        start_block,
                        output.checkpoint.block_number,
                        start.elapsed(),
                        None,
                    );
                }
                Err(e) => {
                    self.monitor.record_execution(
                        stage.id(),
                        start_block,
                        start_block,
                        start.elapsed(),
                        Some(e.clone()),
                    );
                    return Err(e.into());
                }
            }
        }
        
        // Print status
        let status = self.monitor.status();
        println!("Pipeline Status:");
        println!("  Total blocks: {}", status.total_blocks);
        println!("  Total time: {:?}", status.total_time);
        println!("  Avg throughput: {:.2} blocks/sec", status.avg_throughput);
        
        for metrics in &status.stages {
            println!("  {}: {} blocks in {:?} ({:.2} blocks/sec)",
                metrics.stage,
                metrics.blocks_processed,
                metrics.duration,
                metrics.throughput,
            );
        }
        
        Ok(())
    }
}
```

## Questions to Ponder - Detailed Answers

### 1. Why is staged sync more efficient than full sync?

**Answer**: Staged sync is more efficient for several reasons:

1. **Specialization**: Each stage can be optimized for its specific task. For example, the headers stage can download headers in parallel without worrying about execution, while the execution stage can batch process transactions.

2. **Memory Efficiency**: By processing data in stages, we only need to keep the working set for one stage in memory at a time. Full sync would need to keep headers, bodies, state, and receipts all in memory simultaneously.

3. **Parallelism**: Some stages can run in parallel (like account hashing and storage hashing), and within stages, work can be parallelized (like downloading headers from multiple peers).

4. **Checkpointing**: If sync is interrupted, staged sync can resume from the last completed stage rather than starting over. This is especially important for initial sync which can take days.

5. **Cache Locality**: Each stage accesses data in patterns that are cache-friendly. For example, the execution stage processes blocks sequentially, leading to good temporal locality.

### 2. How do stages handle chain reorganizations?

**Answer**: Stages handle reorgs through the unwind mechanism:

1. **Reverse Order**: Stages are unwound in reverse order from how they execute. This ensures dependencies are respected - you can't unwind execution before unwinding the state root calculation.

2. **Stage-Specific Unwinding**: Each stage implements its own unwind logic:
   - Headers: Remove headers after the reorg point
   - Bodies: Remove transactions and uncles
   - Execution: Revert state changes
   - Merkle: Remove calculated nodes
   - Indices: Remove index entries

3. **Checkpoint Updates**: After unwinding, each stage's checkpoint is updated to reflect the new position, ensuring the pipeline can resume correctly.

4. **Atomic Operations**: Unwinding uses database transactions to ensure consistency - either all changes for a stage are reverted or none are.

### 3. What happens if a stage fails midway through execution?

**Answer**: Stage failure is handled gracefully:

1. **Checkpoint Recovery**: The last saved checkpoint allows the stage to resume from where it left off rather than starting from the beginning.

2. **Transaction Rollback**: Database changes since the last checkpoint are rolled back, ensuring consistency.

3. **Progress Tracking**: Stages can save custom progress data in their checkpoints, allowing fine-grained recovery. For example, the execution stage might save the last successfully executed transaction within a block.

4. **Retry Logic**: The pipeline can implement retry logic with exponential backoff for transient failures (like network issues in the download stages).

5. **Error Propagation**: Errors are propagated up to the pipeline orchestrator, which can decide whether to retry, skip, or halt based on the error type and configured policies.

The staged sync architecture makes Reth's synchronization robust, efficient, and maintainable, allowing the client to sync with the Ethereum network reliably even under adverse conditions.