# Lesson 13: RPC Server Architecture

*"The worthwhile problems are the ones you can really solve or help solve, the ones you can really contribute something to." - Richard Feynman*

## Files with Inline Comments for This Lesson
- `crates/rpc/rpc/src/lib.rs` - Main RPC module
- `crates/rpc/rpc/src/eth/core.rs` - Eth API implementation
- `crates/rpc/rpc-builder/src/lib.rs` - RPC builder pattern
- `crates/rpc/rpc-server-types/src/lib.rs` - RPC server types

## What is JSON-RPC? - The Universal Language of Ethereum

### The Deep WHY: Why JSON-RPC for Blockchain?

**Real-World Analogy**: Think of JSON-RPC like a universal translator at the United Nations:
- **Standardized Format**: Everyone speaks the same "protocol language"
- **Request-Response**: "I need information X" → "Here is information X"
- **Language Agnostic**: Works with any programming language
- **Stateless**: Each request is independent (like asking separate questions)

**Why JSON-RPC specifically?**
1. **Simple**: Easy to understand and implement
2. **Lightweight**: Minimal overhead compared to SOAP/XML
3. **Ubiquitous**: Every programming language has JSON support
4. **Debuggable**: Human-readable format makes troubleshooting easier

```json
// Request - Like asking a librarian for a book
{
  "jsonrpc": "2.0",                    // Protocol version
  "method": "eth_getBalance",           // What you want to do
  "params": [                          // Specific details
    "0x742d35Cc6634C0532925a3b844Bc9e7595f7E83a",  // Which account
    "latest"                           // At what point in time
  ],
  "id": 1                              // Request ID (for matching responses)
}

// Response - Like the librarian giving you the book
{
  "jsonrpc": "2.0",                    // Same protocol version
  "result": "0x1234567890abcdef",       // The actual balance
  "id": 1                              // Same ID (proves it's the right answer)
}
```

**The Power of this Pattern**:
- **Decoupling**: Client doesn't need to know how server works internally
- **Extensibility**: New methods can be added without breaking existing clients
- **Tooling**: Standard tools can work with any Ethereum client
- **Interoperability**: Different implementations can communicate seamlessly

## RPC Architecture Overview: A Multi-Story Office Building

### The Deep WHY: Why Layered Architecture?

**Real-World Analogy**: Think of the RPC server like a modern office building:

```
┌─────────────────┐
│   JSON-RPC      │  ← Reception desk (standardizes all communication)
├─────────────────┤
│  Transport      │  ← Different entrances (HTTP/WS/IPC)
├─────────────────┤
│  Middleware     │  ← Security/Reception (auth, rate limiting)
├─────────────────┤
│  API Handlers   │  ← Department managers (business logic)
├─────────────────┤
│  Core Services  │  ← Backend departments (Database, EVM, Pool)
└─────────────────┘
```

**Why Each Layer Exists:**

1. **JSON-RPC Layer**: Like a standardized receptionist
   - Ensures all communication follows the same format
   - Routes requests to the right department
   - Packages responses consistently

2. **Transport Layer**: Like different building entrances
   - **HTTP**: Main public entrance (most visitors)
   - **WebSocket**: Express elevator (for VIPs who need real-time updates)
   - **IPC**: Private back entrance (local access only)

3. **Middleware Layer**: Like building security
   - **Authentication**: "Show me your badge"
   - **Rate Limiting**: "You can only visit 10 times per minute"
   - **Metrics**: "Log who visits when"

4. **API Handlers**: Like department managers
   - Understand what you're asking for
   - Know how to get the right information
   - Coordinate with other departments

5. **Core Services**: Like specialized departments
   - **Database**: Records department
   - **EVM**: Computing department  
   - **Transaction Pool**: Pending requests department

**Benefits of This Design:**
- **Separation of Concerns**: Each layer has one job
- **Modularity**: Can swap out layers independently
- **Testability**: Can test each layer in isolation
- **Scalability**: Can optimize each layer differently

## Transport Layers: Different Ways to Enter the Building

### Why Different Transports?

**Real-World Analogy**: Think of transport layers like different ways to enter a building:
- **HTTP**: Main entrance with a turnstile (one person at a time)
- **WebSocket**: Express elevator (stays connected, fast back-and-forth)
- **IPC**: Private staff entrance (local access only, very fast)

Each transport is optimized for different use cases!

### HTTP Transport - The Main Public Entrance

**Use Case**: "I want to quickly check my balance and leave"

**Characteristics**:
- **Stateless**: Each request is independent
- **Request-Response**: Simple question-answer pattern
- **Firewall-Friendly**: Works through corporate firewalls
- **Cacheable**: Responses can be cached by proxies

```rust
pub struct HttpServerConfig {
    /// Socket address to bind (like the building address)
    pub addr: SocketAddr,
    /// CORS configuration (like visitor access rules)
    pub cors: Option<CorsLayer>,
    /// Request size limit (like package size limits)
    pub max_request_body_size: u32,
    /// Max connections (like building capacity)
    pub max_connections: u32,
}

impl HttpServerConfig {
    pub fn start(self, modules: RpcModule) -> Result<ServerHandle> {
        let server = ServerBuilder::new()
            .set_http_only()
            .max_request_body_size(self.max_request_body_size)
            .max_connections(self.max_connections)
            .build(self.addr)?;
            
        let handle = server.start(modules)?;
        Ok(handle)
    }
}
```

### WebSocket Transport - The Express Elevator

**Use Case**: "I want to stay connected and get live updates"

**Characteristics**:
- **Stateful**: Connection stays open
- **Bidirectional**: Server can push updates to client
- **Real-time**: Perfect for subscriptions (new blocks, pending transactions)
- **Efficient**: No connection overhead after initial setup

```rust
pub struct WsServerConfig {
    /// Socket address (same building, different entrance)
    pub addr: SocketAddr,
    /// Max subscriptions per connection (like max notifications per person)
    pub max_subscriptions_per_connection: u32,
    /// Message size limit (like elevator weight limit)
    pub max_message_size: u32,
}

// Example subscription flow:
// 1. Client: "I want to know about new blocks"
// 2. Server: "Ok, I'll notify you"
// 3. New block arrives
// 4. Server: "Here's block #1000000!"
// 5. Client gets instant notification

impl WsServerConfig {
    pub fn start(self, modules: RpcModule) -> Result<ServerHandle> {
        let server = ServerBuilder::new()
            .set_ws_only()
            .max_subscriptions_per_connection(self.max_subscriptions_per_connection)
            .max_message_size(self.max_message_size)
            .build(self.addr)?;
            
        let handle = server.start(modules)?;
        Ok(handle)
    }
}
```

### IPC Transport - The Private Staff Entrance

**Use Case**: "I'm a local application that needs maximum performance"

**Characteristics**:
- **Local Only**: Only accessible from the same machine
- **High Performance**: No network stack overhead
- **Trusted**: Can expose admin methods safely
- **Platform-Specific**: Uses Unix sockets or named pipes

```rust
pub struct IpcServerConfig {
    /// IPC endpoint path (like the private entrance location)
    pub endpoint: PathBuf,  // e.g., "/tmp/reth.ipc" on Unix
}

// Performance comparison:
// HTTP:      ~1-5ms latency (network stack)
// WebSocket: ~0.5-2ms latency (persistent connection)
// IPC:       ~0.1-0.5ms latency (direct memory)

// Security comparison:
// HTTP:      Public, needs authentication
// WebSocket: Public, needs authentication 
// IPC:       Local only, can be trusted

impl IpcServerConfig {
    pub async fn start(self, modules: RpcModule) -> Result<IpcServerHandle> {
        let server = IpcServerBuilder::new()
            .set_endpoint(self.endpoint)
            .build()?;
            
        let handle = server.start(modules).await?;
        Ok(handle)
    }
}
```

## RPC Module System

### Module Definition

```rust
/// Available RPC modules
#[derive(Debug, Clone, Copy)]
pub enum RethRpcModule {
    /// `admin_` namespace
    Admin,
    /// `debug_` namespace
    Debug,
    /// `eth_` namespace
    Eth,
    /// `net_` namespace
    Net,
    /// `trace_` namespace
    Trace,
    /// `txpool_` namespace
    Txpool,
    /// `web3_` namespace
    Web3,
    /// `rpc_` namespace
    Rpc,
}

impl RethRpcModule {
    /// Returns the namespace string
    pub fn as_str(&self) -> &'static str {
        match self {
            Self::Admin => "admin",
            Self::Debug => "debug",
            Self::Eth => "eth",
            Self::Net => "net",
            Self::Trace => "trace",
            Self::Txpool => "txpool",
            Self::Web3 => "web3",
            Self::Rpc => "rpc",
        }
    }
}
```

### Module Selection

```rust
#[derive(Debug, Clone, Default)]
pub struct RpcModuleSelection(HashSet<RethRpcModule>);

impl RpcModuleSelection {
    /// Standard modules for public RPC
    pub fn standard() -> Self {
        Self::from_iter([
            RethRpcModule::Eth,
            RethRpcModule::Net,
            RethRpcModule::Web3,
        ])
    }
    
    /// All available modules
    pub fn all() -> Self {
        Self::from_iter([
            RethRpcModule::Admin,
            RethRpcModule::Debug,
            RethRpcModule::Eth,
            RethRpcModule::Net,
            RethRpcModule::Trace,
            RethRpcModule::Txpool,
            RethRpcModule::Web3,
            RethRpcModule::Rpc,
        ])
    }
    
    /// Check if selection is safe for IPC
    pub fn is_ipc_safe(&self) -> bool {
        // All modules are safe for IPC (local only)
        true
    }
}
```

## The RPC Module Builder

### Builder Pattern

```rust
pub struct RpcModuleBuilder<Provider, Pool, Network, Events, EvmConfig> {
    /// Database provider
    provider: Provider,
    /// Transaction pool
    pool: Pool,
    /// Network handle
    network: Network,
    /// Event subscriptions
    events: Events,
    /// EVM configuration
    evm_config: EvmConfig,
    /// Module configuration
    modules: RpcModuleSelection,
}

impl<Provider, Pool, Network, Events, EvmConfig> 
    RpcModuleBuilder<Provider, Pool, Network, Events, EvmConfig>
{
    /// Create eth module
    pub fn build_eth(&self) -> Result<RpcModule<()>> {
        let eth_api = EthApi::builder(
            self.provider.clone(),
            self.pool.clone(),
            self.network.clone(),
            self.evm_config.clone(),
        )
        .build();
        
        let mut module = RpcModule::new(());
        module.merge(eth_api.into_rpc())?;
        Ok(module)
    }
    
    /// Build all configured modules
    pub fn build(self) -> Result<TransportRpcModules> {
        let mut modules = TransportRpcModules::default();
        
        for selected in &self.modules.0 {
            let module = match selected {
                RethRpcModule::Eth => self.build_eth()?,
                RethRpcModule::Net => self.build_net()?,
                RethRpcModule::Web3 => self.build_web3()?,
                // ... other modules
            };
            
            modules.merge(module)?;
        }
        
        Ok(modules)
    }
}
```

## Eth API Implementation

### Core Methods

```rust
impl<Provider, Pool, Network, EvmConfig> EthApiServer for EthApi<Provider, Pool, Network, EvmConfig>
where
    Provider: BlockReader + StateProviderFactory,
    Pool: TransactionPool,
{
    /// Get account balance
    async fn balance(&self, address: Address, block_id: Option<BlockId>) -> Result<U256> {
        let block_id = block_id.unwrap_or(BlockId::latest());
        
        // Get state at block
        let state = self.state_at_block_id(block_id).await?;
        
        // Read account
        let account = state.basic_account(&address)?;
        
        Ok(account.map(|a| a.balance).unwrap_or_default())
    }
    
    /// Get storage value
    async fn storage_at(
        &self,
        address: Address,
        index: U256,
        block_id: Option<BlockId>,
    ) -> Result<B256> {
        let block_id = block_id.unwrap_or(BlockId::latest());
        
        // Get state at block
        let state = self.state_at_block_id(block_id).await?;
        
        // Read storage
        let value = state.storage(&address, &index)?;
        
        Ok(value.unwrap_or_default())
    }
    
    /// Get transaction count (nonce)
    async fn transaction_count(
        &self,
        address: Address,
        block_id: Option<BlockId>,
    ) -> Result<U256> {
        let block_id = block_id.unwrap_or(BlockId::latest());
        
        // Handle pending block specially
        if block_id.is_pending() {
            // Check pool for pending nonce
            let pool_nonce = self.pool.get_next_nonce(address);
            if let Some(nonce) = pool_nonce {
                return Ok(U256::from(nonce));
            }
        }
        
        // Get state at block
        let state = self.state_at_block_id(block_id).await?;
        
        // Read account
        let account = state.basic_account(&address)?;
        
        Ok(U256::from(account.map(|a| a.nonce).unwrap_or_default()))
    }
}
```

### EVM Execution Methods

```rust
impl<Provider, Pool, Network, EvmConfig> EthApi<Provider, Pool, Network, EvmConfig> {
    /// Execute a call without modifying state
    async fn call(
        &self,
        request: TransactionRequest,
        block_id: Option<BlockId>,
        state_overrides: Option<StateOverride>,
    ) -> Result<Bytes> {
        let block_id = block_id.unwrap_or(BlockId::latest());
        
        // Get execution environment
        let env = self.prepare_call_env(block_id, &request).await?;
        
        // Apply state overrides if any
        let state = if let Some(overrides) = state_overrides {
            self.state_with_overrides(env.state, overrides)?
        } else {
            env.state
        };
        
        // Execute call
        let result = self.execute_call(state, env, request)?;
        
        match result {
            ExecutionResult::Success { output, .. } => Ok(output.into()),
            ExecutionResult::Revert { output, .. } => Err(RpcError::Revert(output)),
            ExecutionResult::Halt { reason, .. } => Err(RpcError::ExecutionHalted(reason)),
        }
    }
    
    /// Estimate gas for a transaction
    async fn estimate_gas(
        &self,
        request: TransactionRequest,
        block_id: Option<BlockId>,
    ) -> Result<U256> {
        let block_id = block_id.unwrap_or(BlockId::latest());
        
        // Binary search for gas limit
        let mut low = MIN_GAS;
        let mut high = self.gas_cap;
        
        // Get execution environment
        let env = self.prepare_call_env(block_id, &request).await?;
        
        while low < high {
            let mid = (low + high) / 2;
            
            let mut test_request = request.clone();
            test_request.gas = Some(mid);
            
            match self.execute_call(env.state.clone(), env.clone(), test_request) {
                Ok(ExecutionResult::Success { gas_used, .. }) => {
                    // Try lower gas
                    high = gas_used;
                }
                _ => {
                    // Need more gas
                    low = mid + 1;
                }
            }
        }
        
        // Add 10% buffer
        Ok(U256::from(low * 110 / 100))
    }
}
```

## Transaction Pool Integration

### Sending Transactions

```rust
impl<Provider, Pool, Network, EvmConfig> EthApi<Provider, Pool, Network, EvmConfig>
where
    Pool: TransactionPool,
{
    /// Submit raw transaction
    async fn send_raw_transaction(&self, bytes: Bytes) -> Result<B256> {
        // Decode transaction
        let tx = TransactionSigned::decode(&bytes)
            .map_err(|_| RpcError::InvalidTransaction)?;
        
        // Validate transaction
        self.validate_transaction(&tx)?;
        
        // Submit to pool
        let hash = tx.hash();
        self.pool.add_transaction(tx).await?;
        
        Ok(hash)
    }
    
    /// Get pending transactions
    async fn pending_transactions(&self) -> Result<Vec<Transaction>> {
        let pending = self.pool.pending_transactions();
        
        Ok(pending.into_iter()
            .map(|tx| self.convert_transaction(tx))
            .collect())
    }
}
```

## Subscription Support

### WebSocket Subscriptions

```rust
pub trait EthPubSubApi {
    /// Subscribe to new block headers
    async fn subscribe_new_heads(&self, sink: SubscriptionSink) -> Result<()>;
    
    /// Subscribe to logs
    async fn subscribe_logs(&self, filter: Filter, sink: SubscriptionSink) -> Result<()>;
    
    /// Subscribe to pending transactions
    async fn subscribe_new_pending_transactions(&self, sink: SubscriptionSink) -> Result<()>;
}

impl<Provider, Pool, Network, Events> EthPubSubApi for EthPubSub<Provider, Pool, Network, Events>
where
    Events: CanonStateSubscriptions,
{
    async fn subscribe_new_heads(&self, sink: SubscriptionSink) -> Result<()> {
        let mut receiver = self.events.subscribe_new_heads();
        
        // Send updates to client
        tokio::spawn(async move {
            while let Some(header) = receiver.recv().await {
                if sink.send(&header).await.is_err() {
                    break; // Client disconnected
                }
            }
        });
        
        Ok(())
    }
    
    async fn subscribe_logs(&self, filter: Filter, sink: SubscriptionSink) -> Result<()> {
        let mut receiver = self.events.subscribe_logs(filter);
        
        tokio::spawn(async move {
            while let Some(log) = receiver.recv().await {
                if sink.send(&log).await.is_err() {
                    break;
                }
            }
        });
        
        Ok(())
    }
}
```

## Middleware Stack

### Authentication

```rust
pub struct AuthLayer {
    /// JWT secret for authentication
    secret: JwtSecret,
}

impl AuthLayer {
    pub fn new(secret: JwtSecret) -> Self {
        Self { secret }
    }
    
    /// Validate JWT token
    pub fn validate(&self, headers: &HeaderMap) -> Result<Claims> {
        let token = headers
            .get(AUTHORIZATION)
            .and_then(|h| h.to_str().ok())
            .and_then(|h| h.strip_prefix("Bearer "))
            .ok_or(AuthError::MissingToken)?;
            
        let claims = self.secret.validate(token)?;
        
        // Check expiration
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_secs();
            
        if claims.exp < now {
            return Err(AuthError::TokenExpired);
        }
        
        Ok(claims)
    }
}
```

### Rate Limiting

```rust
pub struct RateLimitLayer {
    /// Requests per second
    rate: u32,
    /// Per-IP limits
    limits: Arc<Mutex<HashMap<IpAddr, RateLimiter>>>,
}

impl RateLimitLayer {
    pub fn check(&self, ip: IpAddr) -> Result<()> {
        let mut limits = self.limits.lock();
        
        let limiter = limits.entry(ip)
            .or_insert_with(|| RateLimiter::new(self.rate));
            
        if !limiter.check() {
            return Err(RpcError::RateLimitExceeded);
        }
        
        Ok(())
    }
}
```

### Metrics Collection

```rust
pub struct MetricsLayer {
    /// Method call counters
    calls: Arc<HashMap<String, AtomicU64>>,
    /// Response time histogram
    response_times: Arc<Histogram>,
}

impl MetricsLayer {
    pub fn record_call(&self, method: &str, duration: Duration) {
        // Increment call counter
        self.calls
            .get(method)
            .unwrap_or(&AtomicU64::new(0))
            .fetch_add(1, Ordering::Relaxed);
            
        // Record response time
        self.response_times.record(duration.as_millis() as f64);
    }
}
```

## Error Handling

### RPC Error Types

```rust
#[derive(Debug, thiserror::Error)]
pub enum RpcError {
    /// Invalid request
    #[error("Invalid request: {0}")]
    InvalidRequest(String),
    
    /// Method not found
    #[error("Method not found: {0}")]
    MethodNotFound(String),
    
    /// Invalid params
    #[error("Invalid params: {0}")]
    InvalidParams(String),
    
    /// Internal error
    #[error("Internal error: {0}")]
    Internal(String),
    
    /// Execution error
    #[error("Execution reverted: {0:?}")]
    ExecutionReverted(Bytes),
}

impl From<RpcError> for jsonrpsee::core::Error {
    fn from(err: RpcError) -> Self {
        match err {
            RpcError::InvalidRequest(msg) => {
                jsonrpsee::core::Error::InvalidRequest(msg)
            }
            RpcError::MethodNotFound(method) => {
                jsonrpsee::core::Error::MethodNotFound(method)
            }
            RpcError::InvalidParams(msg) => {
                jsonrpsee::core::Error::InvalidParams(msg)
            }
            RpcError::Internal(msg) => {
                jsonrpsee::core::Error::Internal(msg)
            }
            RpcError::ExecutionReverted(output) => {
                jsonrpsee::core::Error::Custom(ErrorObject {
                    code: 3,
                    message: "execution reverted",
                    data: Some(output),
                })
            }
        }
    }
}
```

## Performance Optimizations

### Caching

```rust
pub struct EthStateCache {
    /// Block cache
    blocks: LruCache<B256, Block>,
    /// Receipt cache
    receipts: LruCache<B256, Vec<Receipt>>,
    /// State cache
    states: LruCache<(B256, Address), Account>,
}

impl EthStateCache {
    pub fn get_block(&self, hash: &B256) -> Option<Block> {
        self.blocks.get(hash).cloned()
    }
    
    pub fn cache_block(&mut self, block: Block) {
        self.blocks.put(block.hash(), block);
    }
}
```

### Batch Processing

```rust
impl EthApi {
    /// Process batch requests efficiently
    pub async fn handle_batch(&self, requests: Vec<Request>) -> Vec<Response> {
        // Group by method for optimization
        let mut by_method: HashMap<&str, Vec<(usize, Request)>> = HashMap::new();
        
        for (idx, req) in requests.into_iter().enumerate() {
            by_method.entry(&req.method)
                .or_default()
                .push((idx, req));
        }
        
        // Process each group in parallel
        let futures = by_method.into_iter().map(|(method, reqs)| {
            self.process_method_batch(method, reqs)
        });
        
        let results = join_all(futures).await;
        
        // Reorder results
        let mut responses = vec![None; requests.len()];
        for batch_result in results {
            for (idx, response) in batch_result {
                responses[idx] = Some(response);
            }
        }
        
        responses.into_iter().map(|r| r.unwrap()).collect()
    }
}
```

## Assignments with Solutions

### 1. Implement a custom RPC method

```rust
use jsonrpsee::{core::RpcResult, proc_macros::rpc};

#[rpc(server)]
pub trait CustomApi {
    /// Get node sync status with details
    #[method(name = "custom_syncStatus")]
    async fn sync_status(&self) -> RpcResult<SyncStatus>;
    
    /// Get peer statistics
    #[method(name = "custom_peerStats")]
    async fn peer_stats(&self) -> RpcResult<PeerStats>;
}

#[derive(Serialize, Deserialize)]
pub struct SyncStatus {
    pub syncing: bool,
    pub current_block: u64,
    pub highest_block: u64,
    pub peers: usize,
    pub mode: String,
}

#[derive(Serialize, Deserialize)]
pub struct PeerStats {
    pub connected: usize,
    pub inbound: usize,
    pub outbound: usize,
    pub avg_latency_ms: u64,
}

pub struct CustomApiImpl<Provider, Network> {
    provider: Provider,
    network: Network,
}

impl<Provider, Network> CustomApiServer for CustomApiImpl<Provider, Network>
where
    Provider: BlockReader,
    Network: NetworkInfo + Peers,
{
    async fn sync_status(&self) -> RpcResult<SyncStatus> {
        // Get current block
        let current_block = self.provider
            .best_block_number()
            .map_err(|e| RpcError::Internal(e.to_string()))?;
            
        // Get sync status from network
        let sync_info = self.network.sync_status();
        
        Ok(SyncStatus {
            syncing: sync_info.is_syncing(),
            current_block,
            highest_block: sync_info.highest_block().unwrap_or(current_block),
            peers: self.network.peer_count(),
            mode: if sync_info.is_syncing() { "full" } else { "synced" }.to_string(),
        })
    }
    
    async fn peer_stats(&self) -> RpcResult<PeerStats> {
        let peers = self.network.peers();
        
        let mut inbound = 0;
        let mut outbound = 0;
        let mut total_latency = 0;
        
        for peer in &peers {
            if peer.inbound {
                inbound += 1;
            } else {
                outbound += 1;
            }
            total_latency += peer.latency_ms;
        }
        
        Ok(PeerStats {
            connected: peers.len(),
            inbound,
            outbound,
            avg_latency_ms: if peers.is_empty() { 
                0 
            } else { 
                total_latency / peers.len() as u64 
            },
        })
    }
}

// Register the custom API
fn register_custom_api<Provider, Network>(
    provider: Provider,
    network: Network,
) -> RpcModule<()> 
where
    Provider: BlockReader + Clone + 'static,
    Network: NetworkInfo + Peers + Clone + 'static,
{
    let api = CustomApiImpl { provider, network };
    api.into_rpc()
}
```

### 2. Create a middleware for request logging

```rust
use jsonrpsee::server::middleware::{self, HttpMiddleware};
use std::time::Instant;

#[derive(Clone)]
pub struct LoggingMiddleware {
    logger: slog::Logger,
}

impl LoggingMiddleware {
    pub fn new(logger: slog::Logger) -> Self {
        Self { logger }
    }
}

#[async_trait]
impl HttpMiddleware for LoggingMiddleware {
    type Instant = Instant;
    
    async fn on_request(
        &self,
        request: &HttpRequest,
        transport: TransportProtocol,
    ) -> Self::Instant {
        slog::debug!(
            self.logger,
            "RPC request";
            "method" => %request.method,
            "transport" => ?transport,
            "remote_addr" => %request.remote_addr(),
        );
        
        Instant::now()
    }
    
    async fn on_response(
        &self,
        path: &str,
        started_at: Self::Instant,
        response: &HttpResponse,
    ) {
        let duration = started_at.elapsed();
        
        slog::info!(
            self.logger,
            "RPC response";
            "path" => path,
            "status" => response.status().as_u16(),
            "duration_ms" => duration.as_millis(),
        );
    }
    
    async fn on_call(
        &self,
        method: &str,
        params: Params,
        kind: MethodKind,
    ) {
        slog::debug!(
            self.logger,
            "RPC method call";
            "method" => method,
            "kind" => ?kind,
            "params" => ?params,
        );
    }
    
    async fn on_result(
        &self,
        method: &str,
        success: bool,
        started_at: Self::Instant,
    ) {
        let duration = started_at.elapsed();
        
        if success {
            slog::debug!(
                self.logger,
                "RPC method success";
                "method" => method,
                "duration_μs" => duration.as_micros(),
            );
        } else {
            slog::warn!(
                self.logger,
                "RPC method failed";
                "method" => method,
                "duration_μs" => duration.as_micros(),
            );
        }
    }
}

// Usage
fn create_server_with_logging() -> ServerBuilder {
    let logger = create_logger();
    let logging = LoggingMiddleware::new(logger);
    
    ServerBuilder::new()
        .set_http_middleware(middleware::ProxyGetRequestLayer::new(
            logging.clone()
        ))
        .set_ws_middleware(logging)
}
```

### 3. Build a rate limiter for RPC

```rust
use std::sync::Arc;
use tokio::sync::Mutex;
use std::collections::HashMap;
use std::net::IpAddr;
use std::time::{Duration, Instant};

pub struct RateLimiter {
    /// Maximum requests per window
    max_requests: u32,
    /// Time window
    window: Duration,
    /// Request tracking
    requests: Arc<Mutex<HashMap<IpAddr, WindowCounter>>>,
}

struct WindowCounter {
    count: u32,
    window_start: Instant,
}

impl RateLimiter {
    pub fn new(max_requests: u32, window: Duration) -> Self {
        Self {
            max_requests,
            window,
            requests: Arc::new(Mutex::new(HashMap::new())),
        }
    }
    
    pub async fn check_rate_limit(&self, ip: IpAddr) -> Result<(), RateLimitError> {
        let mut requests = self.requests.lock().await;
        let now = Instant::now();
        
        let counter = requests.entry(ip).or_insert_with(|| WindowCounter {
            count: 0,
            window_start: now,
        });
        
        // Reset window if expired
        if now.duration_since(counter.window_start) > self.window {
            counter.count = 0;
            counter.window_start = now;
        }
        
        // Check limit
        if counter.count >= self.max_requests {
            let retry_after = self.window - now.duration_since(counter.window_start);
            return Err(RateLimitError::LimitExceeded { retry_after });
        }
        
        // Increment counter
        counter.count += 1;
        Ok(())
    }
    
    /// Clean up old entries periodically
    pub async fn cleanup(&self) {
        let mut requests = self.requests.lock().await;
        let now = Instant::now();
        
        requests.retain(|_, counter| {
            now.duration_since(counter.window_start) <= self.window * 2
        });
    }
}

#[derive(Debug, thiserror::Error)]
pub enum RateLimitError {
    #[error("Rate limit exceeded. Retry after {retry_after:?}")]
    LimitExceeded { retry_after: Duration },
}

// Middleware implementation
pub struct RateLimitMiddleware {
    limiter: Arc<RateLimiter>,
    /// Cleanup task handle
    _cleanup_task: JoinHandle<()>,
}

impl RateLimitMiddleware {
    pub fn new(max_requests: u32, window: Duration) -> Self {
        let limiter = Arc::new(RateLimiter::new(max_requests, window));
        
        // Spawn cleanup task
        let cleanup_limiter = limiter.clone();
        let cleanup_task = tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_secs(60));
            loop {
                interval.tick().await;
                cleanup_limiter.cleanup().await;
            }
        });
        
        Self {
            limiter,
            _cleanup_task: cleanup_task,
        }
    }
}

#[async_trait]
impl HttpMiddleware for RateLimitMiddleware {
    type Instant = Instant;
    
    async fn on_request(
        &self,
        request: &HttpRequest,
        _transport: TransportProtocol,
    ) -> Result<Self::Instant, HttpResponse> {
        let ip = request.remote_addr().ip();
        
        match self.limiter.check_rate_limit(ip).await {
            Ok(()) => Ok(Instant::now()),
            Err(RateLimitError::LimitExceeded { retry_after }) => {
                let response = HttpResponse::too_many_requests()
                    .header("Retry-After", retry_after.as_secs().to_string())
                    .body("Rate limit exceeded");
                    
                Err(response)
            }
        }
    }
}
```

## Common Pitfalls and How to Avoid Them

### 1. Blocking the Async Runtime

**The Problem**: Using blocking operations in async handlers kills performance.

```rust
// ❌ DON'T: Blocking operation in async handler
async fn get_balance(&self, address: Address) -> Result<U256> {
    // This blocks the entire async runtime!
    let account = self.provider.get_account(address)?;
    Ok(account.balance)
}

// ✅ DO: Use spawn_blocking for CPU-intensive work
async fn get_balance(&self, address: Address) -> Result<U256> {
    let provider = self.provider.clone();
    let account = spawn_blocking(move || {
        provider.get_account(address)
    }).await??;
    Ok(account.balance)
}
```

**Why This Matters**: Async runtimes use a small thread pool. Blocking one thread can cause all other requests to wait.

### 2. Unbounded Resource Usage

**The Problem**: Expensive RPC calls can consume unlimited resources.

```rust
// ❌ DON'T: Allow unlimited gas in eth_call
async fn call(&self, request: TransactionRequest) -> Result<Bytes> {
    let gas_limit = request.gas.unwrap_or(u64::MAX); // Dangerous!
    self.execute_call(request, gas_limit).await
}

// ✅ DO: Enforce reasonable limits
async fn call(&self, request: TransactionRequest) -> Result<Bytes> {
    let gas_limit = request.gas
        .unwrap_or(self.default_gas_limit)
        .min(self.max_gas_limit); // Bounded!
    self.execute_call(request, gas_limit).await
}
```

### 3. Memory Leaks from Subscriptions

**The Problem**: WebSocket subscriptions can accumulate without cleanup.

```rust
// ❌ DON'T: Store subscriptions without cleanup
pub struct SubscriptionManager {
    subscriptions: HashMap<SubscriptionId, Subscription>, // Grows forever!
}

// ✅ DO: Implement proper cleanup
pub struct SubscriptionManager {
    subscriptions: HashMap<SubscriptionId, Subscription>,
    cleanup_interval: Duration,
}

impl SubscriptionManager {
    async fn cleanup_stale_subscriptions(&mut self) {
        self.subscriptions.retain(|_, sub| {
            !sub.is_closed() && sub.last_activity.elapsed() < Duration::from_secs(300)
        });
    }
}
```

## Connections to Other Concepts

### How RPC Server Connects to the Broader System

**1. With Transaction Pool (Lesson 14)**:
```rust
// RPC receives transactions and forwards to pool
impl EthApi {
    async fn send_raw_transaction(&self, tx_bytes: Bytes) -> Result<TxHash> {
        // Decode transaction
        let tx = TransactionSigned::decode(&tx_bytes)?;
        
        // Submit to pool (which handles validation, ordering, etc.)
        let hash = self.pool.add_transaction(tx).await?;
        
        // Broadcast to network
        self.network.propagate_transaction(tx);
        
        Ok(hash)
    }
}
```

**2. With P2P Network (Lesson 12)**:
```rust
// RPC exposes network status to external clients
impl EthApi {
    async fn syncing(&self) -> Result<SyncStatus> {
        let network_status = self.network.status();
        
        if network_status.is_syncing {
            Ok(SyncStatus::Syncing {
                current_block: network_status.current_block,
                highest_block: network_status.highest_block,
                starting_block: network_status.starting_block,
            })
        } else {
            Ok(SyncStatus::NotSyncing)
        }
    }
}
```

**3. With EVM Execution (Lesson 16)**:
```rust
// RPC provides interface to EVM for simulations
impl EthApi {
    async fn call(&self, request: TransactionRequest) -> Result<Bytes> {
        // Prepare EVM environment
        let env = self.build_evm_env(&request).await?;
        
        // Execute in EVM (without committing state)
        let result = self.evm.transact_commit(env)?;
        
        match result {
            ExecutionResult::Success { output, .. } => Ok(output),
            ExecutionResult::Revert { output, .. } => Err(RpcError::Revert(output)),
            ExecutionResult::Halt { reason, .. } => Err(RpcError::Halt(reason)),
        }
    }
}
```

**4. With Static Files (Lesson 11)**:
```rust
// RPC transparently serves historical data from static files
impl EthApi {
    async fn get_block(&self, number: BlockNumber) -> Result<Option<Block>> {
        // Try static files first (for old blocks)
        if let Some(block) = self.static_files.get_block(number).await? {
            return Ok(Some(block));
        }
        
        // Fall back to database (for recent blocks)
        self.provider.get_block(number).await
    }
}
```

## Questions to Ponder - Detailed Answers

### 1. Why separate transport layers (HTTP/WS/IPC)?

**The Short Answer**: Different applications have different needs.

**The Deep Answer**:

**Different use cases**:
- **HTTP**: "I want to check my balance quickly" (wallets, block explorers)
- **WebSocket**: "I want live updates" (trading bots, real-time dashboards)
- **IPC**: "I'm a local service that needs maximum speed" (consensus clients)

**Security implications**:
```rust
// Different transports, different security models
match transport {
    Transport::Http | Transport::WebSocket => {
        // Public-facing: need authentication
        self.authenticate_request(&request)?;
        self.rate_limit(&request.remote_ip)?;
        // Only expose safe methods
        if !SAFE_METHODS.contains(&request.method) {
            return Err("Method not allowed on public transport");
        }
    }
    Transport::Ipc => {
        // Local only: can be trusted
        // Allow admin methods like debug_*, admin_*
    }
}
```

**Performance characteristics**:
- **HTTP**: ~1-5ms overhead per request (connection setup)
- **WebSocket**: ~0.5-2ms after initial connection
- **IPC**: ~0.1-0.5ms (no network stack)

### 2. How to handle blocking operations in async RPC handlers?

**The Core Problem**: Mixing sync and async code incorrectly.

**Why It Matters**:
```rust
// Async runtime typically has 4-8 threads
// If you block one thread with CPU work, you lose 25% capacity!
// If you block all threads, the entire server stops responding
```

**Solution Patterns**:

1. **CPU-bound work**: Use `spawn_blocking`
   ```rust
   let result = spawn_blocking(move || {
       // Heavy computation
       calculate_merkle_root(&large_dataset)
   }).await?;
   ```

2. **I/O-bound work**: Use async I/O
   ```rust
   let data = async_file_read(&path).await?; // Non-blocking
   ```

3. **Database work**: Use async drivers or spawn_blocking
   ```rust
   // If DB driver is async
   let account = self.db.get_account(address).await?;
   
   // If DB driver is sync
   let account = spawn_blocking(move || {
       db.get_account(address)
   }).await??;
   ```

### 3. What are the security implications of RPC endpoints?

**The Threat Model**: RPC servers are high-value targets.

**Attack Vectors**:

1. **Resource Exhaustion (DoS)**:
   ```rust
   // Attacker sends expensive requests
   eth_call({
       to: "0x...",
       data: "0x...infinite_loop_bytecode",
       gas: "0xffffffff" // Try to use max gas
   })
   ```

2. **Data Exfiltration**:
   ```rust
   // Attacker tries to read sensitive state
   eth_getStorageAt("0x...private_contract", "0x0", "latest")
   ```

3. **Amplification Attacks**:
   ```rust
   // Small request → huge response
   eth_getLogs({
       fromBlock: "0x0",
       toBlock: "latest", // Entire blockchain!
       topics: []
   })
   ```

**Defense Strategies**:

1. **Input Validation**:
   ```rust
   fn validate_block_range(from: u64, to: u64) -> Result<()> {
       if to - from > MAX_BLOCK_RANGE {
           return Err("Block range too large");
       }
       Ok(())
   }
   ```

2. **Resource Limits**:
   ```rust
   const MAX_GAS_PER_CALL: u64 = 50_000_000;
   const MAX_LOGS_PER_REQUEST: usize = 10_000;
   const MAX_REQUEST_SIZE: usize = 1_000_000; // 1MB
   ```

3. **Rate Limiting**:
   ```rust
   // Different limits for different methods
   let limit = match method {
       "eth_getBalance" => 100, // requests per minute
       "eth_call" => 20,       // expensive operations
       "debug_traceTransaction" => 1, // very expensive
       _ => 50,
   };
   ```

4. **Method Restrictions**:
   ```rust
   // Only expose safe methods on public transports
   let public_methods = ["eth_getBalance", "eth_getTransactionCount", ...];
   let admin_methods = ["debug_*", "admin_*", ...]; // IPC only
   ```