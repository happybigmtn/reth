# Lesson 69: Chain Reorganization Handling

*"The only constant in life is change." - Heraclitus*

## Overview
Chain reorganizations (reorgs) occur when the blockchain switches to a different fork. This lesson covers reorg detection, handling strategies, and state recovery mechanisms.

## Key Concepts
- **Reorg**: Switch from one chain fork to another
- **Fork Detection**: Identifying when chains diverge
- **State Rollback**: Reverting to previous state
- **Recovery**: Rebuilding state on new chain

## Reorg Detection

```rust
pub struct ReorgDetector {
    chain_tracker: ChainTracker,
    fork_detector: ForkDetector,
    confidence_threshold: u64,
}

impl ReorgDetector {
    pub fn detect_reorg(&mut self, new_block: &Block) -> Result<Option<ReorgEvent>, ReorgError> {
        // Check if this block creates a fork
        let fork_info = self.fork_detector.analyze_block(new_block)?;
        
        match fork_info {
            ForkInfo::Extension => {
                // Normal block extending current chain
                Ok(None)
            }
            ForkInfo::Fork { common_ancestor, fork_length } => {
                // Potential reorg detected
                if fork_length > self.confidence_threshold {
                    Ok(Some(ReorgEvent {
                        common_ancestor,
                        old_chain: self.get_old_chain(common_ancestor)?,
                        new_chain: self.get_new_chain(common_ancestor, new_block)?,
                        depth: fork_length,
                    }))
                } else {
                    // Fork too short, might be temporary
                    Ok(None)
                }
            }
        }
    }
    
    fn get_old_chain(&self, common_ancestor: BlockHash) -> Result<Vec<Block>, ReorgError> {
        let mut chain = Vec::new();
        let mut current = self.chain_tracker.get_head_block()?;
        
        while current.hash() != common_ancestor {
            chain.push(current.clone());
            current = self.chain_tracker.get_parent_block(&current)?;
        }
        
        chain.reverse();
        Ok(chain)
    }
    
    fn get_new_chain(&self, common_ancestor: BlockHash, new_head: &Block) -> Result<Vec<Block>, ReorgError> {
        let mut chain = Vec::new();
        let mut current = new_head.clone();
        
        while current.hash() != common_ancestor {
            chain.push(current.clone());
            current = self.chain_tracker.get_parent_block(&current)?;
        }
        
        chain.reverse();
        Ok(chain)
    }
}
```

## Reorg Handler

```rust
pub struct ReorgHandler {
    state_manager: StateManager,
    transaction_pool: Arc<Mutex<TransactionPool>>,
    event_bus: EventBus,
    recovery_strategy: RecoveryStrategy,
}

impl ReorgHandler {
    pub fn handle_reorg(&mut self, reorg: ReorgEvent) -> Result<(), ReorgError> {
        info!("Handling reorg of depth {}", reorg.depth);
        
        // Phase 1: Rollback old chain
        self.rollback_old_chain(&reorg.old_chain)?;
        
        // Phase 2: Apply new chain
        self.apply_new_chain(&reorg.new_chain)?;
        
        // Phase 3: Update transaction pool
        self.update_transaction_pool(&reorg)?;
        
        // Phase 4: Notify subscribers
        self.notify_reorg_subscribers(&reorg)?;
        
        // Phase 5: Update indices
        self.update_indices(&reorg)?;
        
        Ok(())
    }
    
    fn rollback_old_chain(&mut self, old_chain: &[Block]) -> Result<(), ReorgError> {
        for block in old_chain.iter().rev() {
            // Revert state changes
            self.state_manager.revert_block(block)?;
            
            // Remove block from storage
            self.state_manager.remove_block(block.hash())?;
            
            // Revert transaction effects
            self.revert_transaction_effects(block)?;
        }
        
        Ok(())
    }
    
    fn apply_new_chain(&mut self, new_chain: &[Block]) -> Result<(), ReorgError> {
        for block in new_chain {
            // Validate block
            self.validate_block_in_reorg_context(block)?;
            
            // Apply state changes
            self.state_manager.apply_block(block)?;
            
            // Store block
            self.state_manager.store_block(block)?;
            
            // Update head
            self.state_manager.update_head(block.hash())?;
        }
        
        Ok(())
    }
    
    fn update_transaction_pool(&self, reorg: &ReorgEvent) -> Result<(), ReorgError> {
        let mut pool = self.transaction_pool.lock().unwrap();
        
        // Re-add transactions from rolled back blocks
        for block in &reorg.old_chain {
            for tx in &block.body.transactions {
                // Only re-add if not in new chain
                if !self.transaction_in_new_chain(tx, &reorg.new_chain) {
                    pool.add_transaction(tx.clone())?;
                }
            }
        }
        
        // Remove transactions that are now mined
        for block in &reorg.new_chain {
            for tx in &block.body.transactions {
                pool.remove_transaction(tx.hash());
            }
        }
        
        Ok(())
    }
}
```

## State Recovery

```rust
pub struct StateRecovery {
    state_provider: Arc<dyn StateProvider>,
    backup_manager: BackupManager,
    recovery_checkpoints: HashMap<BlockHash, RecoveryCheckpoint>,
}

impl StateRecovery {
    pub fn create_recovery_checkpoint(&mut self, block: &Block) -> Result<(), RecoveryError> {
        let checkpoint = RecoveryCheckpoint {
            block_hash: block.hash(),
            block_number: block.number,
            state_root: block.state_root,
            timestamp: SystemTime::now(),
            backup_id: self.backup_manager.create_backup()?,
        };
        
        self.recovery_checkpoints.insert(block.hash(), checkpoint);
        
        // Clean up old checkpoints
        self.cleanup_old_checkpoints()?;
        
        Ok(())
    }
    
    pub fn recover_to_checkpoint(&mut self, checkpoint_hash: BlockHash) -> Result<(), RecoveryError> {
        let checkpoint = self.recovery_checkpoints.get(&checkpoint_hash)
            .ok_or(RecoveryError::CheckpointNotFound)?;
        
        // Restore from backup
        self.backup_manager.restore_backup(checkpoint.backup_id)?;
        
        // Verify state consistency
        self.verify_state_consistency(checkpoint)?;
        
        // Update provider state
        self.state_provider.reset_to_checkpoint(checkpoint)?;
        
        Ok(())
    }
    
    fn verify_state_consistency(&self, checkpoint: &RecoveryCheckpoint) -> Result<(), RecoveryError> {
        let current_state_root = self.state_provider.state_root()?;
        
        if current_state_root != checkpoint.state_root {
            return Err(RecoveryError::StateInconsistency {
                expected: checkpoint.state_root,
                actual: current_state_root,
            });
        }
        
        Ok(())
    }
}
```

## Fork Choice Rule

```rust
pub struct ForkChoiceRule {
    rule_type: ForkChoiceRuleType,
    confidence_threshold: u64,
    weight_calculator: WeightCalculator,
}

pub enum ForkChoiceRuleType {
    LongestChain,
    HeaviestChain,
    GHOST,
}

impl ForkChoiceRule {
    pub fn choose_fork(&self, forks: &[Fork]) -> Result<Fork, ForkChoiceError> {
        match self.rule_type {
            ForkChoiceRuleType::LongestChain => self.choose_longest_chain(forks),
            ForkChoiceRuleType::HeaviestChain => self.choose_heaviest_chain(forks),
            ForkChoiceRuleType::GHOST => self.choose_ghost_fork(forks),
        }
    }
    
    fn choose_longest_chain(&self, forks: &[Fork]) -> Result<Fork, ForkChoiceError> {
        forks.iter()
            .max_by_key(|fork| fork.length)
            .cloned()
            .ok_or(ForkChoiceError::NoValidFork)
    }
    
    fn choose_heaviest_chain(&self, forks: &[Fork]) -> Result<Fork, ForkChoiceError> {
        let mut best_fork = None;
        let mut best_weight = 0;
        
        for fork in forks {
            let weight = self.weight_calculator.calculate_weight(fork)?;
            
            if weight > best_weight {
                best_weight = weight;
                best_fork = Some(fork.clone());
            }
        }
        
        best_fork.ok_or(ForkChoiceError::NoValidFork)
    }
    
    fn choose_ghost_fork(&self, forks: &[Fork]) -> Result<Fork, ForkChoiceError> {
        // Implement GHOST (Greedy Heaviest Observed Subtree) algorithm
        let mut subtree_weights = HashMap::new();
        
        for fork in forks {
            let weight = self.calculate_subtree_weight(fork)?;
            subtree_weights.insert(fork.head_hash, weight);
        }
        
        let best_fork_hash = subtree_weights.iter()
            .max_by_key(|(_, &weight)| weight)
            .map(|(hash, _)| *hash)
            .ok_or(ForkChoiceError::NoValidFork)?;
        
        forks.iter()
            .find(|fork| fork.head_hash == best_fork_hash)
            .cloned()
            .ok_or(ForkChoiceError::NoValidFork)
    }
}
```

## Summary
Chain reorganization handling is critical for maintaining blockchain consistency. Proper reorg detection, state recovery, and fork choice rules ensure nodes stay synchronized with the canonical chain.

## Assignments
1. **Reorg Simulator**: Build chain reorganization simulation
2. **Recovery Optimizer**: Optimize state recovery procedures
3. **Fork Analyzer**: Analyze fork choice effectiveness

## Questions to Ponder
1. How do you minimize reorg disruption?
2. What's the optimal checkpoint frequency?
3. How do you handle deep reorgs?
4. What fork choice rule is most effective?
5. How do you test reorg handling?