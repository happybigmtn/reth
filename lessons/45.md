# Lesson 45: Bodies Stage

*"If you thought you understood it, then you didn't think about it hard enough." - Richard Feynman*

## Files with Inline Comments for This Lesson
- `crates/stages/stages/src/stages/bodies.rs` - Bodies stage implementation
- `crates/network/p2p/src/bodies/downloader.rs` - Body downloading logic
- `crates/storage/db-api/src/tables/blocks.rs` - Block body storage tables
- `crates/static-file/static-file/src/segments/transactions.rs` - Transaction storage
- `crates/primitives/src/transaction/mod.rs` - Transaction types

## What is the Bodies Stage?

If headers are newspaper headlines, then bodies are the actual articles with all the details. After verifying the newspaper is legitimate (headers stage), now we need to download and store all the actual content.

**Why separate headers and bodies?** Think of a massive library:
- **Headers stage:** Building the card catalog - lightweight operation that tells you what books exist
- **Bodies stage:** Actually moving the books onto shelves - heavy operation that requires lots of storage

**The validation importance:** Bodies must match their headers' "promises":
- **Transactions root:** The header claims certain transactions exist - bodies must prove it
- **Ommers hash:** The header claims certain uncle blocks exist - bodies must contain them
- **Gas usage:** The header claims a certain amount of gas was used - transaction execution must match

**Storage efficiency considerations:** Bodies contain the bulk of blockchain data. Smart storage strategies include:
- **Empty block optimization:** Many blocks have no transactions (especially on L2s) - we can skip downloading empty bodies
- **Static file storage:** Transactions never change after finalization, so they can be stored in optimized static files
- **Parallel downloads:** Different peers can provide different body chunks simultaneously

```
Block Structure:
┌─────────────────────────────────────────────────┐
│                  Block Header                   │
│  (Downloaded in Headers Stage - ~500 bytes)     │
│  - Parent Hash                                  │
│  - State Root                                   │
│  - Transactions Root ─────┐                     │
│  - Receipts Root          │                     │
│  - Ommers Hash ───────┐   │                     │
└───────────────────────┼───┼─────────────────────┘
                        │   │
┌───────────────────────▼───▼─────────────────────┐
│                  Block Body                     │
│  (Downloaded in Bodies Stage - 10KB-10MB)       │
│  - Transactions[]                               │
│  - Ommers[]                                     │
└─────────────────────────────────────────────────┘
```

## Bodies Stage Implementation

The stage downloads bodies for headers we already have:

```rust
/// Bodies stage implementation
/// Located in: crates/stages/stages/src/stages/bodies.rs

use reth_network_p2p::bodies::{BodyDownloader, BlockResponse};
use reth_db_api::{tables, transaction::DbTxMut};

/// LESSON 45: Bodies Stage
/// Downloads transaction and ommer data for blocks
#[derive(Debug)]
pub struct BodyStage<D: BodyDownloader> {
    /// Network body downloader
    downloader: D,
    /// Buffer for block responses
    buffer: Option<Vec<BlockResponse<D::Block>>>,
}

impl<D: BodyDownloader> Stage for BodyStage<D> {
    fn id(&self) -> StageId {
        StageId::Bodies
    }
    
    /// Execute bodies download
    /// LESSON 45: Bodies Download Strategy
    /// 1. Find blocks that need bodies
    /// 2. Download bodies from network
    /// 3. Store transactions and ommers
    async fn execute(
        &mut self,
        provider: &Provider,
        input: ExecInput,
    ) -> Result<ExecOutput, StageError> {
        let checkpoint = input.checkpoint();
        let target = input.target();
        
        // Ensure consistency between static files and database
        ensure_consistency(provider, None)?;
        
        // Find range of blocks needing bodies
        let (from_block, to_block) = self.get_body_range(provider, checkpoint, target)?;
        
        if from_block > to_block {
            // No bodies to download
            return Ok(ExecOutput {
                checkpoint: StageCheckpoint::new(to_block),
                done: true,
                control_flow: ControlFlow::Continue,
            });
        }
        
        info!(target: "sync::stages::bodies", 
            from_block, to_block, 
            "Downloading bodies"
        );
        
        // Start downloading bodies
        self.downloader.set_download_range(from_block..=to_block)?;
        
        let mut highest_block = from_block.saturating_sub(1);
        
        loop {
            match self.download_and_store_bodies(provider).await? {
                DownloadResult::Done(last_block) => {
                    highest_block = last_block;
                    break;
                }
                DownloadResult::Progress(block) => {
                    highest_block = block;
                    // Continue downloading
                }
            }
        }
        
        Ok(ExecOutput {
            checkpoint: StageCheckpoint::new(highest_block),
            done: true,
            control_flow: ControlFlow::Continue,
        })
    }
    
    /// Unwind bodies stage
    async fn unwind(
        &mut self,
        provider: &Provider,
        input: UnwindInput,
    ) -> Result<UnwindOutput, StageError> {
        let unwind_to = input.unwind_to;
        
        // Remove bodies above unwind point
        self.unwind_bodies(provider, unwind_to)?;
        
        Ok(UnwindOutput {
            checkpoint: StageCheckpoint::new(unwind_to),
        })
    }
}

impl<D: BodyDownloader> BodyStage<D> {
    /// Find blocks that need bodies downloaded
    /// LESSON 45: Empty Block Detection
    /// Some blocks have no transactions or ommers - skip those
    fn get_body_range(
        &self,
        provider: &Provider,
        checkpoint: StageCheckpoint,
        target: BlockNumber,
    ) -> Result<(BlockNumber, BlockNumber), StageError> {
        let mut from = checkpoint.block_number + 1;
        
        // Skip empty blocks at the start
        while from <= target {
            if self.block_needs_body(provider, from)? {
                break;
            }
            from += 1;
        }
        
        Ok((from, target))
    }
    
    /// Check if block needs body downloaded
    fn block_needs_body(
        &self,
        provider: &Provider,
        block_number: BlockNumber,
    ) -> Result<bool, StageError> {
        let header = provider
            .header_by_number(block_number)?
            .ok_or(StageError::MissingHeader(block_number))?;
        
        // LESSON 45: Empty Block Check
        // If both roots indicate empty, no body needed
        let is_empty = header.ommers_hash == EMPTY_OMMER_ROOT_HASH &&
                      header.transactions_root == EMPTY_TRANSACTIONS_ROOT_HASH;
        
        Ok(!is_empty)
    }
    
    /// Download and store block bodies
    async fn download_and_store_bodies(
        &mut self,
        provider: &Provider,
    ) -> Result<DownloadResult, StageError> {
        // Get buffered responses or download new ones
        let responses = if let Some(buffer) = self.buffer.take() {
            buffer
        } else {
            // Download next batch
            match self.downloader.try_next().await? {
                Some(responses) => responses,
                None => return Ok(DownloadResult::Done(provider.last_block_number()?)),
            }
        };
        
        // Process responses
        let result = self.process_responses(provider, responses)?;
        
        Ok(result)
    }
    
    /// Process downloaded block bodies
    /// LESSON 45: Body Processing
    /// Extract and store transactions and ommers
    fn process_responses(
        &mut self,
        provider: &Provider,
        responses: Vec<BlockResponse<D::Block>>,
    ) -> Result<DownloadResult, StageError> {
        let static_file_provider = provider.static_file_provider();
        
        // Open writers for transactions
        let mut tx_writer = static_file_provider
            .latest_writer(StaticFileSegment::Transactions)?;
        
        let tx = provider.tx_mut()?;
        let mut highest_block = 0;
        
        for response in responses {
            let block_number = response.block_number();
            highest_block = highest_block.max(block_number);
            
            // LESSON 45: Transaction Storage
            // Store each transaction with its metadata
            let body_indices = self.store_block_body(
                &tx,
                &mut tx_writer,
                block_number,
                response,
            )?;
            
            // Update block body indices
            tx.put::<tables::BlockBodyIndices>(block_number, body_indices)?;
        }
        
        // Commit static file
        tx_writer.commit()?;
        
        Ok(DownloadResult::Progress(highest_block))
    }
    
    /// Store a single block body
    fn store_block_body(
        &self,
        tx: &impl DbTxMut,
        tx_writer: &mut StaticFileWriter,
        block_number: BlockNumber,
        response: BlockResponse<D::Block>,
    ) -> Result<StoredBlockBodyIndices, StageError> {
        let BlockResponse { transactions, ommers, .. } = response;
        
        // Get current transaction number
        let first_tx_num = tx_writer.next_tx_num();
        
        // LESSON 45: Transaction Processing
        // Each transaction gets a unique sequential ID
        for transaction in transactions {
            // Write to static file
            tx_writer.append_transaction(transaction.clone())?;
            
            // Map transaction hash to ID
            let tx_id = tx_writer.tx_num() - 1;
            tx.put::<tables::TransactionBlocks>(
                tx_id,
                block_number,
            )?;
        }
        
        // Store ommers if any
        if !ommers.is_empty() {
            tx.put::<tables::BlockOmmers>(
                block_number,
                StoredBlockOmmers { ommers },
            )?;
        }
        
        // Return indices for this block
        Ok(StoredBlockBodyIndices {
            first_tx_num,
            tx_count: transactions.len() as u64,
        })
    }
    
    /// Unwind bodies to target block
    fn unwind_bodies(
        &mut self,
        provider: &Provider,
        unwind_to: BlockNumber,
    ) -> Result<(), StageError> {
        let static_file_provider = provider.static_file_provider();
        
        // Find last transaction to keep
        let last_tx_to_keep = provider
            .block_body_indices(unwind_to)?
            .map(|indices| indices.last_tx_num())
            .unwrap_or(0);
        
        // Truncate static files
        static_file_provider.truncate_transactions(last_tx_to_keep)?;
        
        // Remove database entries
        let tx = provider.tx_mut()?;
        
        // Remove block body indices
        tx.delete_range::<tables::BlockBodyIndices>(
            (unwind_to + 1)..,
        )?;
        
        // Remove ommers
        tx.delete_range::<tables::BlockOmmers>(
            (unwind_to + 1)..,
        )?;
        
        // Remove transaction mappings
        tx.delete_range::<tables::TransactionBlocks>(
            (last_tx_to_keep + 1)..,
        )?;
        
        Ok(())
    }
}

#[derive(Debug)]
enum DownloadResult {
    /// Download in progress
    Progress(BlockNumber),
    /// Download complete
    Done(BlockNumber),
}

/// Ensure consistency between static files and database
/// LESSON 45: Consistency Check
/// Static files and database must stay in sync
fn ensure_consistency<Provider>(
    provider: &Provider,
    _unwind_block: Option<u64>,
) -> Result<(), StageError>
where
    Provider: DBProvider + StaticFileProviderFactory,
{
    let next_tx_num = provider
        .tx_ref()
        .cursor_read::<tables::TransactionBlocks>()?
        .last()?
        .map(|(id, _)| id + 1)
        .unwrap_or_default();
    
    let static_file_provider = provider.static_file_provider();
    let next_static_file_tx_num = static_file_provider
        .get_highest_static_file_tx(StaticFileSegment::Transactions)
        .map(|id| id + 1)
        .unwrap_or_default();
    
    match next_static_file_tx_num.cmp(&next_tx_num) {
        Ordering::Greater => {
            // Static files ahead - need to unwind
            warn!(
                target: "sync::stages::bodies",
                "Static file ahead of database, unwinding"
            );
            static_file_provider.truncate_transactions(next_tx_num.saturating_sub(1))?;
        }
        Ordering::Less => {
            // Database ahead - this shouldn't happen
            return Err(StageError::DatabaseStaticFileMismatch);
        }
        Ordering::Equal => {
            // All good
        }
    }
    
    Ok(())
}
```

## Body Downloading Logic

The downloader fetches bodies from multiple peers:

```rust
/// Body downloading implementation
/// Located in: crates/network/p2p/src/bodies/downloader.rs

/// LESSON 45: Body Downloader
/// Downloads block bodies (transactions + ommers) from peers
#[async_trait]
pub trait BodyDownloader: Stream<Item = Result<Vec<BlockResponse>, Error>> {
    type Block: Block;
    
    /// Set range of blocks to download
    fn set_download_range(&mut self, range: RangeInclusive<BlockNumber>) -> Result<(), Error>;
}

/// Concurrent body downloader
pub struct ConcurrentBodyDownloader<Client> {
    /// Network client
    client: Arc<Client>,
    /// Download queue
    queue: DownloadQueue,
    /// Active downloads
    in_flight: HashMap<RequestId, DownloadInfo>,
    /// Downloaded bodies buffer
    buffer: Vec<BlockResponse>,
    /// Configuration
    config: DownloadConfig,
}

#[derive(Debug)]
struct DownloadQueue {
    /// Blocks to download
    pending: VecDeque<BlockNumber>,
    /// Headers for validation
    headers: HashMap<BlockNumber, Header>,
}

impl DownloadQueue {
    /// Get next batch to download
    fn next_batch(&mut self, size: usize) -> Vec<BlockNumber> {
        let mut batch = Vec::with_capacity(size);
        
        while batch.len() < size {
            if let Some(block) = self.pending.pop_front() {
                batch.push(block);
            } else {
                break;
            }
        }
        
        batch
    }
}

impl<Client: BodiesClient> ConcurrentBodyDownloader<Client> {
    /// Create download requests
    /// LESSON 45: Batch Requests
    /// Request multiple bodies at once for efficiency
    fn create_requests(&mut self) -> Result<(), Error> {
        while self.in_flight.len() < self.config.max_concurrent {
            let batch = self.queue.next_batch(self.config.batch_size);
            if batch.is_empty() {
                break;
            }
            
            // Get peer for request
            let peer = self.client.get_best_peer()?;
            
            // Create request
            let request = GetBlockBodies {
                hashes: batch.iter()
                    .filter_map(|&num| self.queue.headers.get(&num))
                    .map(|h| h.hash())
                    .collect(),
            };
            
            // Send request
            let request_id = self.client.send_bodies_request(peer, request)?;
            
            // Track request
            self.in_flight.insert(request_id, DownloadInfo {
                peer,
                blocks: batch,
                timestamp: Instant::now(),
            });
        }
        
        Ok(())
    }
    
    /// Handle bodies response
    /// LESSON 45: Response Validation
    /// Validate bodies match requested headers
    fn handle_response(
        &mut self,
        request_id: RequestId,
        bodies: Vec<BlockBody>,
    ) -> Result<(), Error> {
        let info = self.in_flight.remove(&request_id)
            .ok_or(Error::UnexpectedResponse)?;
        
        if bodies.len() != info.blocks.len() {
            return Err(Error::InvalidResponse);
        }
        
        // Match bodies with headers
        for (block_num, body) in info.blocks.iter().zip(bodies) {
            let header = self.queue.headers.get(block_num)
                .ok_or(Error::MissingHeader)?;
            
            // LESSON 45: Body Validation
            // Verify body matches header roots
            let calculated_tx_root = calculate_transaction_root(&body.transactions);
            if calculated_tx_root != header.transactions_root {
                return Err(Error::InvalidTransactionRoot {
                    expected: header.transactions_root,
                    got: calculated_tx_root,
                });
            }
            
            let calculated_ommers_hash = calculate_ommers_hash(&body.ommers);
            if calculated_ommers_hash != header.ommers_hash {
                return Err(Error::InvalidOmmersHash {
                    expected: header.ommers_hash,
                    got: calculated_ommers_hash,
                });
            }
            
            // Create block response
            self.buffer.push(BlockResponse {
                block_number: *block_num,
                transactions: body.transactions,
                ommers: body.ommers,
            });
        }
        
        Ok(())
    }
    
    /// Handle download timeout
    fn check_timeouts(&mut self) {
        let now = Instant::now();
        let timeout = self.config.request_timeout;
        
        let timed_out: Vec<_> = self.in_flight
            .iter()
            .filter(|(_, info)| now - info.timestamp > timeout)
            .map(|(id, _)| *id)
            .collect();
        
        for request_id in timed_out {
            if let Some(info) = self.in_flight.remove(&request_id) {
                // Re-queue blocks
                for block in info.blocks.into_iter().rev() {
                    self.queue.pending.push_front(block);
                }
                
                // Penalize peer
                self.client.penalize_peer(info.peer);
            }
        }
    }
}

impl<Client: BodiesClient> Stream for ConcurrentBodyDownloader<Client> {
    type Item = Result<Vec<BlockResponse>, Error>;
    
    fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
        // Check timeouts
        self.check_timeouts();
        
        // Create new requests
        if let Err(e) = self.create_requests() {
            return Poll::Ready(Some(Err(e)));
        }
        
        // Poll for responses
        while let Poll::Ready(Some(response)) = self.client.poll_response(cx) {
            if let Err(e) = self.handle_response(response.id, response.bodies) {
                return Poll::Ready(Some(Err(e)));
            }
        }
        
        // Return buffered bodies
        if !self.buffer.is_empty() {
            let bodies = std::mem::take(&mut self.buffer);
            return Poll::Ready(Some(Ok(bodies)));
        }
        
        // Check if done
        if self.queue.pending.is_empty() && self.in_flight.is_empty() {
            return Poll::Ready(None);
        }
        
        Poll::Pending
    }
}

/// Calculate merkle root of transactions
/// LESSON 45: Transaction Root
/// Verify downloaded transactions match header
fn calculate_transaction_root(transactions: &[Transaction]) -> B256 {
    if transactions.is_empty() {
        return EMPTY_TRANSACTIONS_ROOT_HASH;
    }
    
    let mut trie = PatriciaTrie::new();
    
    for (idx, tx) in transactions.iter().enumerate() {
        let key = alloy_rlp::encode(idx);
        let value = tx.encoded();
        trie.insert(&key, &value);
    }
    
    trie.root()
}
```

## Block Body Storage

Bodies are stored across multiple tables:

```rust
/// Block body storage structures
/// Located in: crates/storage/db-api/src/tables/blocks.rs

/// LESSON 45: Body Indices
/// Track where transactions are stored
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct StoredBlockBodyIndices {
    /// First transaction number in this block
    pub first_tx_num: TxNumber,
    /// Number of transactions
    pub tx_count: u64,
}

impl StoredBlockBodyIndices {
    /// Get the last transaction number
    pub fn last_tx_num(&self) -> TxNumber {
        self.first_tx_num
            .checked_add(self.tx_count)
            .map(|n| n.saturating_sub(1))
            .unwrap_or(self.first_tx_num)
    }
    
    /// Get transaction number range
    pub fn tx_num_range(&self) -> Range<TxNumber> {
        self.first_tx_num..self.first_tx_num + self.tx_count
    }
}

/// LESSON 45: Ommer Storage
/// Uncle blocks are stored separately
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct StoredBlockOmmers {
    pub ommers: Vec<Header>,
}

/// Database tables for bodies
pub mod tables {
    /// Maps block number to body indices
    table!(
        /// Block number -> Body indices
        BlockBodyIndices<BlockNumber, StoredBlockBodyIndices>
    );
    
    /// Maps block number to ommers
    table!(
        /// Block number -> Ommers
        BlockOmmers<BlockNumber, StoredBlockOmmers>
    );
    
    /// Maps transaction ID to block number
    table!(
        /// Transaction ID -> Block number
        TransactionBlocks<TxNumber, BlockNumber>
    );
}
```

## Assignments

### Assignment 1: Empty Block Optimizer (Easy)
Create an optimizer that efficiently handles ranges with many empty blocks.

**Your Task**: Implement an `EmptyBlockOptimizer` that skips downloading bodies for empty blocks.

### Assignment 2: Body Validator (Medium)
Build a comprehensive body validator that checks all constraints.

**Your Task**: Create a `BodyValidator` that validates transactions, ommers, and gas limits.

### Assignment 3: Adaptive Body Downloader (Hard)
Design a body downloader that adapts strategy based on block sizes.

**Your Task**: Implement an `AdaptiveBodyDownloader` that adjusts batch sizes based on average block size.

## Assignment Answers

### Answer 1: Empty Block Optimizer

```rust
use alloy_primitives::{B256, BlockNumber};
use std::collections::HashMap;

/// Optimizer for handling empty blocks efficiently
pub struct EmptyBlockOptimizer {
    /// Cache of known empty block ranges
    empty_ranges: Vec<Range<BlockNumber>>,
    /// Headers to check
    headers: HashMap<BlockNumber, Header>,
}

impl EmptyBlockOptimizer {
    pub fn new() -> Self {
        Self {
            empty_ranges: Vec::new(),
            headers: HashMap::new(),
        }
    }
    
    /// Analyze headers to find empty blocks
    pub fn analyze_headers<'a>(
        &mut self,
        headers: impl Iterator<Item = &'a Header>,
    ) -> EmptyBlockAnalysis {
        let mut empty_blocks = Vec::new();
        let mut non_empty_blocks = Vec::new();
        let mut current_empty_start = None;
        
        for header in headers {
            self.headers.insert(header.number, header.clone());
            
            let is_empty = self.is_empty_block(header);
            
            if is_empty {
                empty_blocks.push(header.number);
                
                if current_empty_start.is_none() {
                    current_empty_start = Some(header.number);
                }
            } else {
                non_empty_blocks.push(header.number);
                
                // Close empty range if any
                if let Some(start) = current_empty_start {
                    self.empty_ranges.push(start..header.number);
                    current_empty_start = None;
                }
            }
        }
        
        // Close final range
        if let Some(start) = current_empty_start {
            if let Some(&last) = empty_blocks.last() {
                self.empty_ranges.push(start..last + 1);
            }
        }
        
        EmptyBlockAnalysis {
            empty_blocks,
            non_empty_blocks,
            empty_percentage: (empty_blocks.len() as f64 / 
                             (empty_blocks.len() + non_empty_blocks.len()) as f64) * 100.0,
        }
    }
    
    /// Check if block is empty
    fn is_empty_block(&self, header: &Header) -> bool {
        header.transactions_root == EMPTY_TRANSACTIONS_ROOT &&
        header.ommers_hash == EMPTY_OMMERS_ROOT
    }
    
    /// Get optimized download ranges (only non-empty blocks)
    pub fn get_download_ranges(
        &self,
        from: BlockNumber,
        to: BlockNumber,
    ) -> Vec<Range<BlockNumber>> {
        let mut ranges = Vec::new();
        let mut current = from;
        
        while current <= to {
            // Skip if in empty range
            if let Some(empty_range) = self.find_empty_range(current) {
                if empty_range.end <= to {
                    current = empty_range.end;
                } else {
                    break;
                }
            }
            
            // Find end of non-empty range
            let range_end = self.find_next_empty_start(current, to)
                .map(|n| n - 1)
                .unwrap_or(to);
            
            if current <= range_end {
                ranges.push(current..range_end + 1);
            }
            
            current = range_end + 1;
        }
        
        ranges
    }
    
    fn find_empty_range(&self, block: BlockNumber) -> Option<&Range<BlockNumber>> {
        self.empty_ranges
            .iter()
            .find(|range| range.contains(&block))
    }
    
    fn find_next_empty_start(&self, from: BlockNumber, to: BlockNumber) -> Option<BlockNumber> {
        self.empty_ranges
            .iter()
            .filter(|range| range.start > from && range.start <= to)
            .map(|range| range.start)
            .min()
    }
    
    /// Create empty body indices for empty blocks
    pub fn create_empty_indices(&self, block: BlockNumber) -> Option<StoredBlockBodyIndices> {
        let header = self.headers.get(&block)?;
        
        if !self.is_empty_block(header) {
            return None;
        }
        
        // Empty blocks have no transactions
        Some(StoredBlockBodyIndices {
            first_tx_num: 0, // Will be updated by stage
            tx_count: 0,
        })
    }
}

#[derive(Debug)]
pub struct EmptyBlockAnalysis {
    pub empty_blocks: Vec<BlockNumber>,
    pub non_empty_blocks: Vec<BlockNumber>,
    pub empty_percentage: f64,
}

// Constants for empty roots
const EMPTY_TRANSACTIONS_ROOT: B256 = B256::from_slice(&hex!(
    "56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421"
));
const EMPTY_OMMERS_ROOT: B256 = B256::from_slice(&hex!(
    "1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347"
));

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_empty_block_detection() {
        let mut optimizer = EmptyBlockOptimizer::new();
        
        let headers = vec![
            create_header(1, false), // Non-empty
            create_header(2, true),  // Empty
            create_header(3, true),  // Empty
            create_header(4, true),  // Empty
            create_header(5, false), // Non-empty
            create_header(6, true),  // Empty
            create_header(7, false), // Non-empty
        ];
        
        let analysis = optimizer.analyze_headers(headers.iter());
        
        assert_eq!(analysis.empty_blocks, vec![2, 3, 4, 6]);
        assert_eq!(analysis.non_empty_blocks, vec![1, 5, 7]);
        assert!((analysis.empty_percentage - 57.14).abs() < 0.01);
        
        // Test download ranges
        let ranges = optimizer.get_download_ranges(1, 7);
        assert_eq!(ranges, vec![1..2, 5..6, 7..8]);
    }
    
    fn create_header(number: BlockNumber, is_empty: bool) -> Header {
        Header {
            number,
            transactions_root: if is_empty {
                EMPTY_TRANSACTIONS_ROOT
            } else {
                B256::from_low_u64_be(number)
            },
            ommers_hash: if is_empty {
                EMPTY_OMMERS_ROOT
            } else {
                B256::from_low_u64_be(number * 2)
            },
            ..Default::default()
        }
    }
}

use std::ops::Range;
use hex_literal::hex;
```

### Answer 2: Body Validator

```rust
use alloy_primitives::{U256, B256};
use alloy_consensus::TxType;

/// Comprehensive body validator
pub struct BodyValidator {
    /// Chain specification for validation rules
    chain_spec: Arc<ChainSpec>,
    /// Gas limit tolerance (for ommer validation)
    gas_limit_tolerance: u64,
}

impl BodyValidator {
    pub fn new(chain_spec: Arc<ChainSpec>) -> Self {
        Self {
            chain_spec,
            gas_limit_tolerance: 1024, // Standard tolerance
        }
    }
    
    /// Validate a complete block body
    pub fn validate_body(
        &self,
        header: &Header,
        body: &BlockBody,
    ) -> Result<(), ValidationError> {
        // Validate transaction root
        self.validate_transaction_root(header, &body.transactions)?;
        
        // Validate ommer hash
        self.validate_ommer_hash(header, &body.ommers)?;
        
        // Validate gas usage
        self.validate_gas_usage(header, &body.transactions)?;
        
        // Validate ommers
        self.validate_ommers(header, &body.ommers)?;
        
        // Validate transaction types
        self.validate_transaction_types(header, &body.transactions)?;
        
        Ok(())
    }
    
    /// Validate transaction root matches header
    fn validate_transaction_root(
        &self,
        header: &Header,
        transactions: &[Transaction],
    ) -> Result<(), ValidationError> {
        let calculated = calculate_transaction_root(transactions);
        
        if calculated != header.transactions_root {
            return Err(ValidationError::InvalidTransactionRoot {
                expected: header.transactions_root,
                calculated,
            });
        }
        
        Ok(())
    }
    
    /// Validate ommer hash matches header
    fn validate_ommer_hash(
        &self,
        header: &Header,
        ommers: &[Header],
    ) -> Result<(), ValidationError> {
        let calculated = if ommers.is_empty() {
            EMPTY_OMMERS_ROOT
        } else {
            keccak256(alloy_rlp::encode(ommers))
        };
        
        if calculated != header.ommers_hash {
            return Err(ValidationError::InvalidOmmerHash {
                expected: header.ommers_hash,
                calculated,
            });
        }
        
        Ok(())
    }
    
    /// Validate gas usage doesn't exceed limit
    fn validate_gas_usage(
        &self,
        header: &Header,
        transactions: &[Transaction],
    ) -> Result<(), ValidationError> {
        let mut total_gas_used = 0u64;
        
        for (idx, tx) in transactions.iter().enumerate() {
            total_gas_used = total_gas_used
                .checked_add(tx.gas_limit())
                .ok_or(ValidationError::GasOverflow)?;
            
            if total_gas_used > header.gas_limit {
                return Err(ValidationError::GasLimitExceeded {
                    transaction_index: idx,
                    total_gas_used,
                    gas_limit: header.gas_limit,
                });
            }
        }
        
        // Check gas used matches
        if total_gas_used > header.gas_used {
            return Err(ValidationError::GasUsedMismatch {
                expected: header.gas_used,
                calculated: total_gas_used,
            });
        }
        
        Ok(())
    }
    
    /// Validate ommers (uncle blocks)
    fn validate_ommers(
        &self,
        header: &Header,
        ommers: &[Header],
    ) -> Result<(), ValidationError> {
        // Maximum 2 ommers per block
        if ommers.len() > 2 {
            return Err(ValidationError::TooManyOmmers {
                count: ommers.len(),
            });
        }
        
        let mut seen_hashes = HashSet::new();
        
        for (idx, ommer) in ommers.iter().enumerate() {
            // No duplicate ommers
            if !seen_hashes.insert(ommer.hash()) {
                return Err(ValidationError::DuplicateOmmer {
                    index: idx,
                });
            }
            
            // Ommer must be ancestor but not direct parent
            if ommer.number >= header.number {
                return Err(ValidationError::OmmerTooNew {
                    index: idx,
                    ommer_number: ommer.number,
                    block_number: header.number,
                });
            }
            
            // Maximum uncle depth is 7
            if header.number.saturating_sub(ommer.number) > 7 {
                return Err(ValidationError::OmmerTooOld {
                    index: idx,
                    ommer_number: ommer.number,
                    block_number: header.number,
                });
            }
            
            // Validate ommer difficulty/gas limit
            self.validate_ommer_gas_limit(header, ommer, idx)?;
        }
        
        Ok(())
    }
    
    /// Validate ommer gas limit
    fn validate_ommer_gas_limit(
        &self,
        _header: &Header,
        ommer: &Header,
        index: usize,
    ) -> Result<(), ValidationError> {
        // Simple validation - in practice would check against parent
        if ommer.gas_limit == 0 {
            return Err(ValidationError::InvalidOmmerGasLimit {
                index,
                gas_limit: ommer.gas_limit,
            });
        }
        
        Ok(())
    }
    
    /// Validate transaction types are allowed at this height
    fn validate_transaction_types(
        &self,
        header: &Header,
        transactions: &[Transaction],
    ) -> Result<(), ValidationError> {
        for (idx, tx) in transactions.iter().enumerate() {
            let tx_type = tx.tx_type();
            
            // Check if transaction type is supported
            match tx_type {
                TxType::Legacy => {
                    // Always supported
                }
                TxType::Eip2930 => {
                    if !self.chain_spec.is_berlin_active_at_block(header.number) {
                        return Err(ValidationError::UnsupportedTransactionType {
                            index: idx,
                            tx_type,
                            block_number: header.number,
                        });
                    }
                }
                TxType::Eip1559 => {
                    if !self.chain_spec.is_london_active_at_block(header.number) {
                        return Err(ValidationError::UnsupportedTransactionType {
                            index: idx,
                            tx_type,
                            block_number: header.number,
                        });
                    }
                }
                TxType::Eip4844 => {
                    if !self.chain_spec.is_cancun_active_at_block(header.number) {
                        return Err(ValidationError::UnsupportedTransactionType {
                            index: idx,
                            tx_type,
                            block_number: header.number,
                        });
                    }
                }
                _ => {
                    // Unknown type
                    return Err(ValidationError::UnknownTransactionType {
                        index: idx,
                        tx_type,
                    });
                }
            }
        }
        
        Ok(())
    }
}

#[derive(Debug, thiserror::Error)]
pub enum ValidationError {
    #[error("Invalid transaction root: expected {expected}, calculated {calculated}")]
    InvalidTransactionRoot { expected: B256, calculated: B256 },
    
    #[error("Invalid ommer hash: expected {expected}, calculated {calculated}")]
    InvalidOmmerHash { expected: B256, calculated: B256 },
    
    #[error("Gas limit exceeded at transaction {transaction_index}: total {total_gas_used}, limit {gas_limit}")]
    GasLimitExceeded {
        transaction_index: usize,
        total_gas_used: u64,
        gas_limit: u64,
    },
    
    #[error("Gas used mismatch: expected {expected}, calculated {calculated}")]
    GasUsedMismatch { expected: u64, calculated: u64 },
    
    #[error("Gas overflow")]
    GasOverflow,
    
    #[error("Too many ommers: {count} (max 2)")]
    TooManyOmmers { count: usize },
    
    #[error("Duplicate ommer at index {index}")]
    DuplicateOmmer { index: usize },
    
    #[error("Ommer too new at index {index}: ommer {ommer_number}, block {block_number}")]
    OmmerTooNew {
        index: usize,
        ommer_number: u64,
        block_number: u64,
    },
    
    #[error("Ommer too old at index {index}: ommer {ommer_number}, block {block_number}")]
    OmmerTooOld {
        index: usize,
        ommer_number: u64,
        block_number: u64,
    },
    
    #[error("Invalid ommer gas limit at index {index}: {gas_limit}")]
    InvalidOmmerGasLimit { index: usize, gas_limit: u64 },
    
    #[error("Unsupported transaction type at index {index}: {tx_type:?} at block {block_number}")]
    UnsupportedTransactionType {
        index: usize,
        tx_type: TxType,
        block_number: u64,
    },
    
    #[error("Unknown transaction type at index {index}: {tx_type:?}")]
    UnknownTransactionType { index: usize, tx_type: TxType },
}

use std::collections::HashSet;
use std::sync::Arc;
```

### Answer 3: Adaptive Body Downloader

```rust
use std::time::{Duration, Instant};
use std::collections::VecDeque;

/// Adaptive body downloader that adjusts strategy
pub struct AdaptiveBodyDownloader<Client> {
    client: Arc<Client>,
    strategy: DownloadStrategy,
    metrics: DownloadMetrics,
    config: AdaptiveConfig,
}

#[derive(Debug, Clone)]
struct DownloadStrategy {
    /// Current batch size
    batch_size: usize,
    /// Maximum concurrent requests
    concurrent_requests: usize,
    /// Peer selection strategy
    peer_strategy: PeerStrategy,
    /// Request timeout
    timeout: Duration,
}

#[derive(Debug, Clone)]
enum PeerStrategy {
    /// Use fastest responding peers
    FastestPeers,
    /// Round-robin across all peers
    RoundRobin,
    /// Prefer peers with lowest latency
    LowestLatency,
    /// Prefer peers that have served large blocks
    LargeBlockPeers,
}

#[derive(Default)]
struct DownloadMetrics {
    /// Recent download samples
    samples: VecDeque<DownloadSample>,
    /// Peer performance
    peer_stats: HashMap<PeerId, PeerStats>,
    /// Block size statistics
    block_sizes: BlockSizeStats,
}

#[derive(Debug)]
struct DownloadSample {
    timestamp: Instant,
    block_range: Range<BlockNumber>,
    total_size: usize,
    download_time: Duration,
    peer: PeerId,
    success: bool,
}

#[derive(Debug, Default)]
struct PeerStats {
    total_downloads: u64,
    successful_downloads: u64,
    total_bytes: usize,
    average_latency: Duration,
    large_blocks_served: u64,
}

#[derive(Debug, Default)]
struct BlockSizeStats {
    total_blocks: u64,
    total_size: usize,
    size_histogram: HashMap<SizeCategory, u64>,
    recent_average: f64,
}

#[derive(Debug, Clone, Copy, Hash, Eq, PartialEq)]
enum SizeCategory {
    Empty,      // 0 bytes
    Small,      // < 10 KB
    Medium,     // 10-100 KB
    Large,      // 100 KB - 1 MB
    VeryLarge,  // > 1 MB
}

impl BlockSizeStats {
    fn categorize(size: usize) -> SizeCategory {
        match size {
            0 => SizeCategory::Empty,
            1..=10_000 => SizeCategory::Small,
            10_001..=100_000 => SizeCategory::Medium,
            100_001..=1_000_000 => SizeCategory::Large,
            _ => SizeCategory::VeryLarge,
        }
    }
    
    fn update(&mut self, size: usize) {
        self.total_blocks += 1;
        self.total_size += size;
        
        let category = Self::categorize(size);
        *self.size_histogram.entry(category).or_insert(0) += 1;
        
        // Update recent average (exponential moving average)
        let alpha = 0.1;
        self.recent_average = alpha * size as f64 + (1.0 - alpha) * self.recent_average;
    }
    
    fn average_size(&self) -> usize {
        if self.total_blocks == 0 {
            30_000 // Default estimate
        } else {
            (self.total_size / self.total_blocks as usize).max(1)
        }
    }
}

#[derive(Debug, Clone)]
struct AdaptiveConfig {
    /// Minimum batch size
    min_batch_size: usize,
    /// Maximum batch size
    max_batch_size: usize,
    /// Target download time per batch
    target_batch_time: Duration,
    /// Sample window size
    sample_window: usize,
    /// Adaptation interval
    adapt_interval: Duration,
}

impl Default for AdaptiveConfig {
    fn default() -> Self {
        Self {
            min_batch_size: 10,
            max_batch_size: 128,
            target_batch_time: Duration::from_secs(5),
            sample_window: 100,
            adapt_interval: Duration::from_secs(30),
        }
    }
}

impl<Client: BodiesClient> AdaptiveBodyDownloader<Client> {
    pub fn new(client: Arc<Client>, config: AdaptiveConfig) -> Self {
        Self {
            client,
            strategy: DownloadStrategy {
                batch_size: 64, // Start with medium batch
                concurrent_requests: 5,
                peer_strategy: PeerStrategy::FastestPeers,
                timeout: Duration::from_secs(10),
            },
            metrics: DownloadMetrics::default(),
            config,
        }
    }
    
    /// Download bodies for block range
    pub async fn download_range(
        &mut self,
        from: BlockNumber,
        to: BlockNumber,
        headers: &HashMap<BlockNumber, Header>,
    ) -> Result<Vec<BlockBody>, Error> {
        let mut bodies = Vec::new();
        let mut current = from;
        let mut last_adapt = Instant::now();
        
        while current <= to {
            // Adapt strategy periodically
            if last_adapt.elapsed() > self.config.adapt_interval {
                self.adapt_strategy();
                last_adapt = Instant::now();
            }
            
            // Calculate batch size
            let batch_end = (current + self.strategy.batch_size as u64 - 1).min(to);
            let batch_range = current..=batch_end;
            
            // Download batch
            let batch_bodies = self.download_batch(batch_range.clone(), headers).await?;
            
            // Update metrics
            for (block_num, body) in batch_range.clone().zip(&batch_bodies) {
                let size = calculate_body_size(body);
                self.metrics.block_sizes.update(size);
            }
            
            bodies.extend(batch_bodies);
            current = batch_end + 1;
        }
        
        Ok(bodies)
    }
    
    /// Download a batch of bodies
    async fn download_batch(
        &mut self,
        range: RangeInclusive<BlockNumber>,
        headers: &HashMap<BlockNumber, Header>,
    ) -> Result<Vec<BlockBody>, Error> {
        let start = Instant::now();
        let peer = self.select_peer()?;
        
        // Create request
        let hashes: Vec<_> = range.clone()
            .filter_map(|num| headers.get(&num).map(|h| h.hash()))
            .collect();
        
        let request = GetBlockBodies { hashes: hashes.clone() };
        
        // Send request with timeout
        let bodies = tokio::time::timeout(
            self.strategy.timeout,
            self.client.get_block_bodies(peer, request),
        ).await??;
        
        let download_time = start.elapsed();
        let total_size: usize = bodies.iter().map(calculate_body_size).sum();
        
        // Record sample
        self.metrics.samples.push_back(DownloadSample {
            timestamp: start,
            block_range: *range.start()..*range.end() + 1,
            total_size,
            download_time,
            peer,
            success: bodies.len() == hashes.len(),
        });
        
        // Trim old samples
        while self.metrics.samples.len() > self.config.sample_window {
            self.metrics.samples.pop_front();
        }
        
        // Update peer stats
        let stats = self.metrics.peer_stats.entry(peer).or_default();
        stats.total_downloads += 1;
        if bodies.len() == hashes.len() {
            stats.successful_downloads += 1;
        }
        stats.total_bytes += total_size;
        stats.average_latency = Duration::from_secs_f64(
            (stats.average_latency.as_secs_f64() * (stats.total_downloads - 1) as f64 
             + download_time.as_secs_f64()) / stats.total_downloads as f64
        );
        
        // Track large blocks
        let large_blocks = bodies.iter()
            .filter(|b| calculate_body_size(b) > 100_000)
            .count() as u64;
        stats.large_blocks_served += large_blocks;
        
        Ok(bodies)
    }
    
    /// Select peer based on current strategy
    fn select_peer(&self) -> Result<PeerId, Error> {
        let peers = self.client.get_peers();
        if peers.is_empty() {
            return Err(Error::NoPeers);
        }
        
        match self.strategy.peer_strategy {
            PeerStrategy::FastestPeers => {
                // Select peer with best success rate
                peers.into_iter()
                    .max_by_key(|peer| {
                        self.metrics.peer_stats.get(peer)
                            .map(|s| (s.successful_downloads * 1000 / s.total_downloads.max(1)))
                            .unwrap_or(500) // 50% for unknown peers
                    })
                    .ok_or(Error::NoPeers)
            }
            PeerStrategy::RoundRobin => {
                // Simple round-robin
                Ok(peers[rand::random::<usize>() % peers.len()])
            }
            PeerStrategy::LowestLatency => {
                // Select peer with lowest average latency
                peers.into_iter()
                    .min_by_key(|peer| {
                        self.metrics.peer_stats.get(peer)
                            .map(|s| s.average_latency)
                            .unwrap_or(Duration::from_secs(10))
                    })
                    .ok_or(Error::NoPeers)
            }
            PeerStrategy::LargeBlockPeers => {
                // Prefer peers that have served large blocks
                peers.into_iter()
                    .max_by_key(|peer| {
                        self.metrics.peer_stats.get(peer)
                            .map(|s| s.large_blocks_served)
                            .unwrap_or(0)
                    })
                    .ok_or(Error::NoPeers)
            }
        }
    }
    
    /// Adapt download strategy based on metrics
    fn adapt_strategy(&mut self) {
        // Adapt batch size based on download times
        if let Some(avg_time) = self.average_download_time() {
            if avg_time < self.config.target_batch_time * 70 / 100 {
                // Too fast, increase batch size
                self.strategy.batch_size = (self.strategy.batch_size * 125 / 100)
                    .min(self.config.max_batch_size);
            } else if avg_time > self.config.target_batch_time * 130 / 100 {
                // Too slow, decrease batch size
                self.strategy.batch_size = (self.strategy.batch_size * 80 / 100)
                    .max(self.config.min_batch_size);
            }
        }
        
        // Adapt concurrent requests based on success rate
        let success_rate = self.overall_success_rate();
        if success_rate < 0.8 {
            // Too many failures, reduce concurrency
            self.strategy.concurrent_requests = self.strategy.concurrent_requests.saturating_sub(1).max(1);
        } else if success_rate > 0.95 {
            // Very successful, try more concurrency
            self.strategy.concurrent_requests = (self.strategy.concurrent_requests + 1).min(10);
        }
        
        // Adapt peer strategy based on block sizes
        let size_distribution = self.metrics.block_sizes.size_histogram.clone();
        let large_block_ratio = (*size_distribution.get(&SizeCategory::Large).unwrap_or(&0) 
            + *size_distribution.get(&SizeCategory::VeryLarge).unwrap_or(&0)) as f64
            / self.metrics.block_sizes.total_blocks.max(1) as f64;
        
        if large_block_ratio > 0.3 {
            // Many large blocks, use peers good with large blocks
            self.strategy.peer_strategy = PeerStrategy::LargeBlockPeers;
        } else if success_rate < 0.9 {
            // Some failures, try fastest peers
            self.strategy.peer_strategy = PeerStrategy::FastestPeers;
        } else {
            // Good performance, use low latency
            self.strategy.peer_strategy = PeerStrategy::LowestLatency;
        }
        
        // Adapt timeout based on block sizes and latency
        let avg_size = self.metrics.block_sizes.average_size();
        let base_timeout = Duration::from_millis((avg_size / 1000).max(1000) as u64);
        self.strategy.timeout = base_timeout * 3; // 3x average for safety
    }
    
    fn average_download_time(&self) -> Option<Duration> {
        if self.metrics.samples.is_empty() {
            return None;
        }
        
        let total: Duration = self.metrics.samples.iter()
            .map(|s| s.download_time)
            .sum();
            
        Some(total / self.metrics.samples.len() as u32)
    }
    
    fn overall_success_rate(&self) -> f64 {
        let successful = self.metrics.samples.iter()
            .filter(|s| s.success)
            .count();
            
        if self.metrics.samples.is_empty() {
            1.0
        } else {
            successful as f64 / self.metrics.samples.len() as f64
        }
    }
}

/// Calculate body size in bytes
fn calculate_body_size(body: &BlockBody) -> usize {
    let tx_size: usize = body.transactions.iter()
        .map(|tx| tx.encoded_len())
        .sum();
        
    let ommer_size: usize = body.ommers.iter()
        .map(|h| h.encoded_len())
        .sum();
        
    tx_size + ommer_size
}

#[derive(Debug)]
enum Error {
    NoPeers,
    Timeout,
    NetworkError(String),
}

// Mock types
#[derive(Debug, Clone, Copy, Hash, Eq, PartialEq)]
struct PeerId(u64);

#[async_trait]
trait BodiesClient: Send + Sync {
    async fn get_block_bodies(
        &self,
        peer: PeerId,
        request: GetBlockBodies,
    ) -> Result<Vec<BlockBody>, Error>;
    
    fn get_peers(&self) -> Vec<PeerId>;
}

struct GetBlockBodies {
    hashes: Vec<B256>,
}

use std::ops::{Range, RangeInclusive};
use std::collections::HashMap;
use async_trait::async_trait;
```

## Questions to Ponder

1. Why separate headers and bodies into different stages?
2. How do we handle blocks with very large transaction counts?
3. What's the optimal batch size for body downloads?
4. How do we verify body integrity without executing transactions?
5. Should empty blocks be stored differently for space efficiency?

Remember: Bodies are the meat of the blockchain. Headers give structure, bodies give substance!