# Lesson 56: Metrics and Monitoring - The Node's Vital Signs

*"To measure is to know." - Richard Feynman*

## Overview - WHY Monitoring Is Critical

**Flying Blind vs. Instrument Panel**: Running a blockchain node without metrics is like flying a plane without instruments. You might notice when you crash, but you won't see the engine overheating, fuel running low, or turbulence ahead.

**The Production Reality**: In production, "it seems to be working" isn't good enough. You need to know:
- Is sync keeping up with the network?
- Are peers connecting and staying connected?
- Is memory usage growing dangerously?
- Are RPC responses getting slower?

**WHY Prometheus?** Like choosing a common language for international airports, Prometheus is the lingua franca of infrastructure monitoring. It integrates with everything and scales from laptops to data centers.

## Key Files
- `crates/metrics/src/lib.rs` - Core metrics framework
- `crates/node/metrics/src/recorder.rs` - Metrics recording
- `crates/rpc/rpc/src/metrics.rs` - RPC metrics
- `crates/network/src/metrics.rs` - Network metrics
- `crates/blockchain-tree/src/metrics.rs` - Blockchain metrics

## Metrics Collection

```rust
/// Core metrics collection system
pub struct MetricsCollector {
    registry: Registry,
    recorders: Vec<Box<dyn MetricRecorder>>,
}

impl MetricsCollector {
    /// Record blockchain metrics
    pub fn record_block_processed(&self, block: &Block, processing_time: Duration) {
        metrics::counter!("reth_blocks_processed_total").increment(1);
        metrics::histogram!("reth_block_processing_time_seconds")
            .record(processing_time.as_secs_f64());
        metrics::gauge!("reth_latest_block_number").set(block.number as f64);
    }
    
    /// Record network metrics
    pub fn record_peer_connected(&self, peer_id: PeerId) {
        metrics::counter!("reth_peer_connections_total").increment(1);
        metrics::gauge!("reth_active_peers").increment(1.0);
    }
    
    /// Record RPC metrics
    pub fn record_rpc_request(&self, method: &str, duration: Duration, success: bool) {
        let status = if success { "success" } else { "error" };
        metrics::counter!("reth_rpc_requests_total", "method" => method, "status" => status)
            .increment(1);
        metrics::histogram!("reth_rpc_request_duration_seconds", "method" => method)
            .record(duration.as_secs_f64());
    }
}
```

## Performance Monitoring

```rust
/// Performance monitoring system
pub struct PerformanceMonitor {
    sync_metrics: SyncMetrics,
    execution_metrics: ExecutionMetrics,
    memory_metrics: MemoryMetrics,
}

impl PerformanceMonitor {
    pub fn track_sync_performance(&mut self, sync_info: &SyncInfo) {
        self.sync_metrics.update(sync_info);
        
        // Track sync speed
        let blocks_per_second = sync_info.blocks_processed as f64 / 
                               sync_info.elapsed.as_secs_f64();
        metrics::gauge!("reth_sync_blocks_per_second").set(blocks_per_second);
        
        // Track sync progress
        let progress = if sync_info.target_block > 0 {
            sync_info.current_block as f64 / sync_info.target_block as f64
        } else {
            0.0
        };
        metrics::gauge!("reth_sync_progress").set(progress);
    }
}
```

## Alerting System

```rust
/// Alerting system for critical metrics
pub struct AlertingSystem {
    alerts: Vec<Alert>,
    notification_channels: Vec<NotificationChannel>,
}

impl AlertingSystem {
    pub fn check_alerts(&self, metrics: &MetricsSnapshot) {
        for alert in &self.alerts {
            if alert.should_fire(metrics) {
                self.send_alert(alert);
            }
        }
    }
    
    fn send_alert(&self, alert: &Alert) {
        for channel in &self.notification_channels {
            channel.send_alert(alert);
        }
    }
}

pub struct Alert {
    pub name: String,
    pub condition: AlertCondition,
    pub severity: AlertSeverity,
    pub message: String,
}

pub enum AlertCondition {
    MetricThreshold { metric: String, threshold: f64, operator: Operator },
    RateChange { metric: String, rate: f64, duration: Duration },
    ServiceDown { service: String },
}
```

## Summary

Effective monitoring requires comprehensive metrics collection, real-time alerting, and performance tracking. This enables proactive issue resolution and optimal node operation.

## Assignments

1. **Metrics Dashboard**: Create a Grafana dashboard for Reth metrics
2. **Alert Rules**: Design alert rules for critical node conditions  
3. **Performance Profiler**: Build a performance profiling tool

## Questions to Ponder

1. What metrics are most critical for node operators?
2. How do you balance monitoring overhead with observability?
3. What alert conditions prevent false positives?
4. How do you monitor across different deployment environments?
5. What metrics help optimize node performance?