# Lesson 30: Pruning and State Management

*"A scientist looking at nonscientific problems is just as dumb as the next guy." - Richard Feynman*

## Files with Inline Comments for This Lesson
- `crates/prune/types/src/mode.rs` - Pruning mode configurations and strategies
- `crates/prune/prune/src/pruner.rs` - Main pruning engine implementation
- `crates/prune/types/src/segment.rs` - Different data segments that can be pruned
- `crates/static-file/static-file/src/static_file_producer.rs` - Static file management

## Why Pruning Matters: The Digital Decluttering Revolution

**WHY Pruning Is Essential**: Imagine if your house accumulated everything you've ever touched, bought, or seen - every receipt, every newspaper, every piece of mail. Within years, you'd be buried alive in your own history. Ethereum nodes face the exact same problem with blockchain data.

**Real-world analogy**: Pruning is like being a professional organizer for blockchain data. Just as Marie Kondo asks "Does this spark joy?", pruning asks "Does this data serve a current purpose?" The key insight is that most historical data is rarely accessed but takes up precious space.

**The Storage Crisis Is Real**:
```
Ethereum Data Growth (the exponential nightmare):
┌─────────────────────────────────────────────────────┐
│ Year    │ Chain Size  │ State Size  │ Daily Growth  │
├─────────────────────────────────────────────────────┤
│ 2015    │ 500 MB      │ 10 MB       │ 50 MB        │
│ 2018    │ 150 GB      │ 4 GB        │ 200 MB       │
│ 2021    │ 400 GB      │ 8 GB        │ 300 MB       │
│ 2024    │ 1000+ GB    │ 100+ GB     │ 500+ MB      │
│ 2027*   │ 2500+ GB    │ 250+ GB     │ 800+ MB      │
└─────────────────────────────────────────────────────┘

The Pruning Transformation:
Without pruning: ~15TB+ for full archive node (like hoarding everything)
With pruning: ~500GB for full functionality (like keeping only what matters)

*Projected based on current trends
```

**CRITICAL INSIGHT**: Pruning isn't just about saving disk space - it's about making blockchain nodes economically viable for normal people. Without pruning, only data centers could afford to run Ethereum nodes, which would centralize the network.

**The Three Pillars of Smart Pruning**:
1. **Safety First**: Never delete data needed for consensus or reorganizations
2. **Functionality Preservation**: Keep data that applications actually use
3. **Economic Efficiency**: Optimize the cost/benefit ratio of storage

## Pruning Modes

Reth supports different pruning strategies based on user needs:

```rust
/// Different strategies for data retention
/// Located in: crates/prune/types/src/mode.rs

#[derive(Debug, PartialEq, Eq, Clone, Copy)]
pub enum PruneMode {
    /// Remove all possible data while maintaining functionality
    /// Most aggressive pruning for minimal storage
    Full,
    
    /// Keep the last N blocks of data
    /// Good balance between functionality and storage
    Distance(u64),
    
    /// Keep all data before a specific block
    /// Useful for maintaining data until a certain point
    Before(BlockNumber),
}

impl PruneMode {
    /// Determine what block to prune up to
    pub fn prune_target_block(
        &self,
        tip: BlockNumber,
        segment: PruneSegment,
        purpose: PrunePurpose,
    ) -> Result<Option<(BlockNumber, Self)>, PruneSegmentError> {
        match self {
            // Full pruning: prune everything possible
            Self::Full if segment.min_blocks(purpose) == 0 => {
                Ok(Some((tip, *self)))
            }
            
            // Distance pruning: keep last N blocks
            Self::Distance(distance) => {
                if *distance > tip {
                    Ok(None) // Nothing to prune yet
                } else if *distance >= segment.min_blocks(purpose) {
                    Ok(Some((tip - distance, *self)))
                } else {
                    Err(PruneSegmentError::Configuration(segment))
                }
            }
            
            // Before pruning: prune up to specific block
            Self::Before(target_block) => {
                if *target_block > tip {
                    Ok(None) // Target not reached yet
                } else {
                    let safe_target = (*target_block).saturating_sub(1);
                    Ok(Some((safe_target, *self)))
                }
            }
            
            _ => Err(PruneSegmentError::Configuration(segment))
        }
    }
    
    /// Check if a specific block should be pruned
    pub const fn should_prune(&self, block: BlockNumber, tip: BlockNumber) -> bool {
        match self {
            Self::Full => true,
            Self::Distance(distance) => {
                if *distance > tip {
                    false
                } else {
                    block < tip - *distance
                }
            }
            Self::Before(target) => *target > block,
        }
    }
}
```

## Prunable Data Segments

Different types of blockchain data have different retention requirements:

```rust
/// Data segments that can be independently pruned
/// Located in: crates/prune/types/src/segment.rs

#[derive(Debug, Clone, Copy, Eq, PartialEq)]
pub enum PruneSegment {
    /// Transaction sender recovery data
    /// Can be fully pruned since senders can be re-computed
    SenderRecovery,
    
    /// Transaction hash to number lookup
    /// Enables tx_hash -> block_number queries
    TransactionLookup,
    
    /// Transaction receipts with logs and gas usage
    /// Required for some RPC calls and log filtering
    Receipts,
    
    /// Specific contract logs (filtered receipts)
    /// Useful for DApps that only need specific events
    ContractLogs,
    
    /// Account state change history
    /// Required for historical state queries
    AccountHistory,
    
    /// Storage slot change history
    /// Required for historical storage queries  
    StorageHistory,
    
    /// Block headers and metadata
    /// Required for chain navigation and consensus
    Headers,
    
    /// Transaction bodies and signatures
    /// Core transaction data
    Transactions,
}

impl PruneSegment {
    /// Minimum blocks that must be preserved for safety
    pub const fn min_blocks(&self, purpose: PrunePurpose) -> u64 {
        match self {
            // These can be fully pruned or reconstructed
            Self::SenderRecovery | Self::TransactionLookup | 
            Self::Headers | Self::Transactions => 0,
            
            // Receipts can be pruned if moved to static files
            Self::Receipts if purpose.is_static_file() => 0,
            
            // History segments need minimum distance for reorg safety
            Self::ContractLogs | Self::AccountHistory | 
            Self::StorageHistory | Self::Receipts => MINIMUM_PRUNING_DISTANCE,
        }
    }
}

/// Minimum blocks to keep for reorganization safety
const MINIMUM_PRUNING_DISTANCE: u64 = 256;
```

## The Pruning Engine

The main pruner coordinates the removal of old data across all segments:

```rust
/// Main pruning coordinator
/// Located in: crates/prune/prune/src/pruner.rs

#[derive(Debug)]
pub struct Pruner<Provider, PF> {
    /// Factory for database providers
    provider_factory: PF,
    
    /// List of data segments to prune
    segments: Vec<Box<dyn Segment<Provider>>>,
    
    /// Minimum blocks between pruning runs
    min_block_interval: usize,
    
    /// Last block number when pruner ran
    previous_tip_block_number: Option<BlockNumber>,
    
    /// Maximum entries to delete per run (rate limiting)
    delete_limit: usize,
    
    /// Maximum time for one pruning run
    timeout: Option<Duration>,
    
    /// ExEx height to respect (don't prune data ExExs need)
    finished_exex_height: watch::Receiver<FinishedExExHeight>,
    
    /// Metrics for monitoring
    metrics: Metrics,
    
    /// Event notifications
    event_sender: EventSender<PrunerEvent>,
}

impl<Provider, S> Pruner<Provider, S>
where
    Provider: PruneCheckpointReader + PruneCheckpointWriter,
{
    /// Main pruning execution
    pub fn run_with_provider(
        &mut self,
        provider: &Provider,
        tip_block_number: BlockNumber,
    ) -> PrunerResult {
        // Respect ExEx requirements
        let Some(tip_block_number) = 
            self.adjust_tip_block_number_to_finished_exex_height(tip_block_number)
        else {
            return Ok(PruneProgress::Finished.into());
        };
        
        if tip_block_number == 0 {
            return Ok(PruneProgress::Finished.into());
        }
        
        // Check if enough blocks have passed
        if !self.should_run(tip_block_number) {
            return Ok(PruneProgress::Finished.into());
        }
        
        self.event_sender.notify(PrunerEvent::Started { tip_block_number });
        let start = Instant::now();
        
        // Set up rate limiting
        let mut limiter = PruneLimiter::default()
            .set_deleted_entries_limit(self.delete_limit);
        
        if let Some(timeout) = self.timeout {
            limiter = limiter.set_time_limit(timeout);
        }
        
        // Prune each segment
        let (stats, deleted_entries, output) = 
            self.prune_segments(provider, tip_block_number, &mut limiter)?;
        
        let elapsed = start.elapsed();
        self.previous_tip_block_number = Some(tip_block_number);
        
        // Update metrics
        self.metrics.last_duration_seconds.set(elapsed.as_secs_f64());
        self.metrics.pruned_entries_total.increment(deleted_entries as u64);
        
        self.event_sender.notify(PrunerEvent::Finished {
            tip_block_number,
            elapsed,
            deleted_entries,
            stats,
        });
        
        Ok(output)
    }
    
    fn should_run(&self, tip_block_number: BlockNumber) -> bool {
        if let Some(previous_tip) = self.previous_tip_block_number {
            tip_block_number.saturating_sub(previous_tip) >= self.min_block_interval as u64
        } else {
            true // First run
        }
    }
    
    fn prune_segments(
        &mut self,
        provider: &Provider,
        tip_block_number: BlockNumber,
        limiter: &mut PruneLimiter,
    ) -> Result<(SegmentStats, usize, PrunerOutput), PrunerError> {
        let mut total_deleted = 0;
        let mut segment_stats = Vec::new();
        let mut progress = PruneProgress::Finished;
        
        for segment in &mut self.segments {
            if limiter.is_limit_reached() {
                progress = PruneProgress::HasMoreData;
                break;
            }
            
            // Get pruning input for this segment
            let input = PruneInput {
                previous_checkpoint: provider.get_prune_checkpoint(segment.segment())?,
                tip_block_number,
                limiter: limiter.clone(),
            };
            
            // Execute pruning for this segment
            let segment_output = segment.prune(provider, input)?;
            
            // Update checkpoint
            if let Some(checkpoint) = segment_output.checkpoint {
                provider.save_prune_checkpoint(segment.segment(), checkpoint)?;
            }
            
            total_deleted += segment_output.deleted;
            limiter.increment_deleted_entries_count_by(segment_output.deleted);
            
            segment_stats.push(PrunedSegmentInfo {
                segment: segment.segment(),
                deleted: segment_output.deleted,
                from_block: segment_output.from_block,
                to_block: segment_output.to_block,
            });
            
            if segment_output.progress.is_finished() {
                continue;
            } else {
                progress = PruneProgress::HasMoreData;
                break;
            }
        }
        
        Ok((segment_stats, total_deleted, PrunerOutput { progress, deleted: total_deleted }))
    }
}
```

## Static File Management

For efficiency, Reth moves old data to compressed static files rather than deleting it:

```rust
/// Manages static file creation and maintenance
/// Located in: crates/static-file/static-file/src/static_file_producer.rs

pub struct StaticFileProducer<SF> {
    /// Static file provider for reading existing files
    static_file_provider: SF,
    
    /// Maximum entries to process in one run
    block_range_limit: u64,
}

impl<SF> StaticFileProducer<SF>
where
    SF: StaticFileProvider,
{
    /// Move data from database to static files
    pub fn create_static_files<Provider>(
        &self,
        provider: &Provider,
        segment: StaticFileSegment,
        block_range: RangeInclusive<BlockNumber>,
    ) -> Result<(), StaticFileProducerError>
    where
        Provider: DatabaseProvider,
    {
        let start_block = *block_range.start();
        let end_block = *block_range.end();
        
        match segment {
            StaticFileSegment::Headers => {
                self.create_headers_static_file(provider, start_block, end_block)?;
            }
            StaticFileSegment::Transactions => {
                self.create_transactions_static_file(provider, start_block, end_block)?;
            }
            StaticFileSegment::Receipts => {
                self.create_receipts_static_file(provider, start_block, end_block)?;
            }
        }
        
        Ok(())
    }
    
    fn create_headers_static_file<Provider>(
        &self,
        provider: &Provider,
        start_block: BlockNumber,
        end_block: BlockNumber,
    ) -> Result<(), StaticFileProducerError>
    where
        Provider: DatabaseProvider,
    {
        let mut static_file_writer = self.static_file_provider
            .get_writer(start_block, StaticFileSegment::Headers)?;
        
        // Copy headers from database to static file
        for block_number in start_block..=end_block {
            if let Some(header) = provider.header(block_number)? {
                static_file_writer.append_header(&header, header.difficulty)?;
            }
        }
        
        // Finalize and commit static file
        static_file_writer.commit()?;
        
        Ok(())
    }
    
    fn create_transactions_static_file<Provider>(
        &self,
        provider: &Provider,
        start_block: BlockNumber,
        end_block: BlockNumber,
    ) -> Result<(), StaticFileProducerError>
    where
        Provider: DatabaseProvider,
    {
        let mut static_file_writer = self.static_file_provider
            .get_writer(start_block, StaticFileSegment::Transactions)?;
        
        // Process blocks in batches for efficiency
        for block_number in start_block..=end_block {
            if let Some(block_body) = provider.block_body_indices(block_number)? {
                let tx_range = block_body.tx_num_range();
                
                // Copy all transactions in this block
                for tx_number in tx_range {
                    if let Some(transaction) = provider.transaction(tx_number)? {
                        static_file_writer.append_transaction(tx_number, &transaction)?;
                    }
                }
            }
        }
        
        static_file_writer.commit()?;
        Ok(())
    }
}
```

## Pruning Strategies for Different Node Types

### 1. Archive Node (No Pruning)

```rust
/// Configuration for archive nodes
fn archive_node_config() -> PruneModes {
    PruneModes {
        // Keep everything forever
        sender_recovery: None,
        transaction_lookup: None,
        receipts: None,
        account_history: None,
        storage_history: None,
    }
}
```

### 2. Full Node (Conservative Pruning)

```rust
/// Configuration for full nodes
fn full_node_config() -> PruneModes {
    PruneModes {
        // Keep recent data for RPC functionality
        sender_recovery: Some(PruneMode::Distance(10_000)),
        transaction_lookup: Some(PruneMode::Distance(100_000)),
        receipts: Some(PruneMode::Distance(100_000)),
        account_history: Some(PruneMode::Distance(100_000)),
        storage_history: Some(PruneMode::Distance(100_000)),
    }
}
```

### 3. Light Node (Aggressive Pruning)

```rust
/// Configuration for resource-constrained nodes
fn light_node_config() -> PruneModes {
    PruneModes {
        // Minimal data retention
        sender_recovery: Some(PruneMode::Distance(1_000)),
        transaction_lookup: Some(PruneMode::Distance(10_000)),
        receipts: Some(PruneMode::Distance(10_000)),
        account_history: Some(PruneMode::Distance(1_000)),
        storage_history: Some(PruneMode::Distance(1_000)),
    }
}
```

## Smart Pruning with Access Patterns

Advanced pruning strategies consider data access patterns:

```rust
/// Intelligent pruning based on usage statistics
struct SmartPruner {
    access_tracker: AccessTracker,
    base_config: PruneModes,
}

struct AccessTracker {
    /// Track which blocks are accessed frequently
    block_access_count: HashMap<BlockNumber, u64>,
    
    /// Track access patterns over time
    access_window: Duration,
    
    /// Recently accessed data
    hot_data: HashSet<BlockNumber>,
}

impl SmartPruner {
    /// Adjust pruning based on access patterns
    fn adaptive_prune_config(&self, segment: PruneSegment) -> PruneMode {
        let base_mode = self.base_config.get_mode(segment);
        
        match base_mode {
            Some(PruneMode::Distance(distance)) => {
                // Extend retention for frequently accessed data
                let hot_factor = self.calculate_hot_factor(segment);
                let adjusted_distance = distance + (distance * hot_factor / 100);
                PruneMode::Distance(adjusted_distance)
            }
            other => other.unwrap_or(PruneMode::Distance(1000)),
        }
    }
    
    fn calculate_hot_factor(&self, segment: PruneSegment) -> u64 {
        // Calculate how "hot" this data segment is based on access patterns
        let recent_accesses = self.access_tracker.get_recent_accesses(segment);
        
        if recent_accesses > 1000 {
            50 // Extend retention by 50%
        } else if recent_accesses > 100 {
            25 // Extend retention by 25%
        } else {
            0  // Use base retention
        }
    }
}
```

## Pruning Safety and Recovery

Ensuring pruning doesn't break node functionality:

```rust
/// Safety checks before pruning
struct PruningSafetyChecker {
    chain_config: ChainConfig,
    consensus: Arc<dyn Consensus>,
}

impl PruningSafetyChecker {
    /// Verify it's safe to prune up to the target block
    fn check_pruning_safety(
        &self,
        segment: PruneSegment,
        target_block: BlockNumber,
        current_tip: BlockNumber,
    ) -> Result<(), PruningSafetyError> {
        // Check minimum distance for reorg safety
        let min_distance = segment.min_blocks(PrunePurpose::User);
        if current_tip - target_block < min_distance {
            return Err(PruningSafetyError::InsufficientDistance {
                segment,
                required: min_distance,
                actual: current_tip - target_block,
            });
        }
        
        // Check finalization status
        if let Some(finalized_block) = self.get_finalized_block()? {
            if target_block > finalized_block {
                return Err(PruningSafetyError::PruningUnfinalizedData {
                    target: target_block,
                    finalized: finalized_block,
                });
            }
        }
        
        // Check consensus requirements
        if segment == PruneSegment::Headers {
            // Never prune headers needed for weak subjectivity
            let checkpoint_distance = self.chain_config.weak_subjectivity_period();
            if current_tip - target_block < checkpoint_distance {
                return Err(PruningSafetyError::WeakSubjectivityViolation);
            }
        }
        
        Ok(())
    }
    
    /// Emergency recovery if pruning went wrong
    fn emergency_recovery(
        &self,
        segment: PruneSegment,
        from_static_files: bool,
    ) -> Result<(), RecoveryError> {
        if from_static_files {
            // Restore data from static files
            self.restore_from_static_files(segment)?;
        } else {
            // Re-sync from network
            self.trigger_resync(segment)?;
        }
        
        Ok(())
    }
}

#[derive(Debug, thiserror::Error)]
enum PruningSafetyError {
    #[error("Insufficient distance for {segment:?}: need {required}, have {actual}")]
    InsufficientDistance {
        segment: PruneSegment,
        required: u64,
        actual: u64,
    },
    
    #[error("Attempting to prune unfinalized data: target {target}, finalized {finalized}")]
    PruningUnfinalizedData {
        target: BlockNumber,
        finalized: BlockNumber,
    },
    
    #[error("Pruning would violate weak subjectivity requirements")]
    WeakSubjectivityViolation,
}
```

## Assignments

### Assignment 1: Basic Pruning Strategy
Implement a simple pruning strategy for a specific use case:

```rust
struct CustomPruningStrategy {
    node_type: NodeType,
    storage_limit: u64, // GB
    performance_priority: bool,
}

enum NodeType {
    Archive,
    Full,
    Light,
    RpcOnly,
}

impl CustomPruningStrategy {
    fn generate_config(&self) -> PruneModes {
        // Generate appropriate pruning configuration
        // based on node type and constraints
    }
    
    fn calculate_storage_savings(&self, config: &PruneModes) -> u64 {
        // Estimate storage savings in GB
    }
    
    fn assess_functionality_impact(&self, config: &PruneModes) -> FunctionalityReport {
        // Assess what RPC methods might be affected
    }
}

struct FunctionalityReport {
    affected_rpc_methods: Vec<String>,
    historical_query_limit: Option<BlockNumber>,
    log_filtering_limit: Option<BlockNumber>,
}
```

### Assignment 2: Pruning Monitor
Create a monitoring system for pruning operations:

```rust
struct PruningMonitor {
    metrics: PruningMetrics,
    alerts: AlertManager,
}

struct PruningMetrics {
    total_deleted_entries: u64,
    storage_freed: u64,
    last_run_duration: Duration,
    segments_processed: HashMap<PruneSegment, SegmentMetrics>,
}

struct SegmentMetrics {
    entries_deleted: u64,
    deletion_rate: f64, // entries per second
    errors: u64,
}

impl PruningMonitor {
    fn track_pruning_run(&mut self, event: PrunerEvent) {
        // Update metrics based on pruning events
    }
    
    fn check_health(&self) -> HealthStatus {
        // Assess if pruning is working correctly
    }
    
    fn suggest_optimizations(&self) -> Vec<OptimizationSuggestion> {
        // Suggest configuration improvements
    }
}

enum HealthStatus {
    Healthy,
    Warning(String),
    Critical(String),
}

enum OptimizationSuggestion {
    IncreaseDeleteLimit,
    AdjustInterval,
    ChangeStrategy(PruneMode),
}
```

### Assignment 3: Dynamic Pruning Controller
Build a system that adjusts pruning based on storage and performance:

```rust
struct DynamicPruningController {
    current_config: PruneModes,
    storage_monitor: StorageMonitor,
    performance_monitor: PerformanceMonitor,
    adjustment_strategy: AdjustmentStrategy,
}

struct StorageMonitor {
    total_space: u64,
    used_space: u64,
    growth_rate: f64, // GB per day
}

struct PerformanceMonitor {
    query_latency: HashMap<String, Duration>, // RPC method -> latency
    sync_speed: f64, // blocks per second
    pruning_overhead: f64, // percentage of CPU time
}

enum AdjustmentStrategy {
    Conservative, // Prefer functionality over storage
    Aggressive,   // Prefer storage savings over functionality
    Balanced,     // Balance between both
}

impl DynamicPruningController {
    fn evaluate_and_adjust(&mut self) -> Result<PruneModes, ControllerError> {
        // Analyze current state and adjust pruning config
    }
    
    fn predict_storage_usage(&self, config: &PruneModes) -> StoragePrediction {
        // Predict future storage requirements
    }
    
    fn assess_performance_impact(&self, config: &PruneModes) -> PerformanceImpact {
        // Assess how changes will affect performance
    }
}

struct StoragePrediction {
    days_until_full: Option<u32>,
    projected_size_in_30_days: u64,
}

struct PerformanceImpact {
    query_degradation: HashMap<String, f64>, // percentage slowdown
    sync_impact: f64,
}
```

## Answers to Assignments

### Answer 1: Basic Pruning Strategy Implementation

```rust
use std::collections::HashMap;

struct CustomPruningStrategy {
    node_type: NodeType,
    storage_limit: u64, // GB
    performance_priority: bool,
}

#[derive(Debug, Clone)]
enum NodeType {
    Archive,    // Keep everything
    Full,       // Standard full node
    Light,      // Minimal storage
    RpcOnly,    // Optimized for RPC serving
}

#[derive(Debug, Clone)]
struct PruneModes {
    sender_recovery: Option<PruneMode>,
    transaction_lookup: Option<PruneMode>,
    receipts: Option<PruneMode>,
    account_history: Option<PruneMode>,
    storage_history: Option<PruneMode>,
}

struct FunctionalityReport {
    affected_rpc_methods: Vec<String>,
    historical_query_limit: Option<BlockNumber>,
    log_filtering_limit: Option<BlockNumber>,
    estimated_functionality_loss: f64, // 0.0 to 1.0
}

impl CustomPruningStrategy {
    fn new(node_type: NodeType, storage_limit_gb: u64, performance_priority: bool) -> Self {
        Self {
            node_type,
            storage_limit: storage_limit_gb,
            performance_priority,
        }
    }
    
    fn generate_config(&self) -> PruneModes {
        match self.node_type {
            NodeType::Archive => self.archive_config(),
            NodeType::Full => self.full_config(),
            NodeType::Light => self.light_config(),
            NodeType::RpcOnly => self.rpc_optimized_config(),
        }
    }
    
    fn archive_config(&self) -> PruneModes {
        // Archive nodes keep everything
        PruneModes {
            sender_recovery: None,
            transaction_lookup: None,
            receipts: None,
            account_history: None,
            storage_history: None,
        }
    }
    
    fn full_config(&self) -> PruneModes {
        let base_distance = if self.storage_limit < 500 {
            50_000  // Aggressive for small storage
        } else if self.storage_limit < 1000 {
            100_000 // Standard
        } else {
            200_000 // Conservative for large storage
        };
        
        PruneModes {
            sender_recovery: Some(PruneMode::Distance(base_distance / 10)),
            transaction_lookup: Some(PruneMode::Distance(base_distance)),
            receipts: Some(PruneMode::Distance(base_distance)),
            account_history: Some(PruneMode::Distance(base_distance / 2)),
            storage_history: Some(PruneMode::Distance(base_distance / 2)),
        }
    }
    
    fn light_config(&self) -> PruneModes {
        // Aggressive pruning for minimal storage
        PruneModes {
            sender_recovery: Some(PruneMode::Distance(1_000)),
            transaction_lookup: Some(PruneMode::Distance(10_000)),
            receipts: Some(PruneMode::Distance(5_000)),
            account_history: Some(PruneMode::Distance(5_000)),
            storage_history: Some(PruneMode::Distance(5_000)),
        }
    }
    
    fn rpc_optimized_config(&self) -> PruneModes {
        // Optimize for RPC performance
        let lookup_distance = if self.performance_priority {
            100_000 // Keep more for faster queries
        } else {
            50_000  // Balance performance and storage
        };
        
        PruneModes {
            sender_recovery: Some(PruneMode::Distance(5_000)),   // Can recompute
            transaction_lookup: Some(PruneMode::Distance(lookup_distance)), // Important for RPC
            receipts: Some(PruneMode::Distance(lookup_distance)),           // Important for logs
            account_history: Some(PruneMode::Distance(20_000)),             // Some historical queries
            storage_history: Some(PruneMode::Distance(10_000)),             // Less critical
        }
    }
    
    fn calculate_storage_savings(&self, config: &PruneModes) -> u64 {
        // Estimated storage usage per segment (GB per 100k blocks)
        let base_sizes = HashMap::from([
            ("sender_recovery", 0.1),
            ("transaction_lookup", 2.0),
            ("receipts", 15.0),
            ("account_history", 5.0),
            ("storage_history", 8.0),
        ]);
        
        let current_blocks = 18_000_000u64; // Approximate current Ethereum height
        let mut total_savings = 0.0;
        
        // Calculate savings for each segment
        if let Some(mode) = &config.sender_recovery {
            let kept_blocks = self.calculate_kept_blocks(mode, current_blocks);
            let pruned_blocks = current_blocks - kept_blocks;
            total_savings += (pruned_blocks as f64 / 100_000.0) * base_sizes["sender_recovery"];
        }
        
        if let Some(mode) = &config.transaction_lookup {
            let kept_blocks = self.calculate_kept_blocks(mode, current_blocks);
            let pruned_blocks = current_blocks - kept_blocks;
            total_savings += (pruned_blocks as f64 / 100_000.0) * base_sizes["transaction_lookup"];
        }
        
        if let Some(mode) = &config.receipts {
            let kept_blocks = self.calculate_kept_blocks(mode, current_blocks);
            let pruned_blocks = current_blocks - kept_blocks;
            total_savings += (pruned_blocks as f64 / 100_000.0) * base_sizes["receipts"];
        }
        
        if let Some(mode) = &config.account_history {
            let kept_blocks = self.calculate_kept_blocks(mode, current_blocks);
            let pruned_blocks = current_blocks - kept_blocks;
            total_savings += (pruned_blocks as f64 / 100_000.0) * base_sizes["account_history"];
        }
        
        if let Some(mode) = &config.storage_history {
            let kept_blocks = self.calculate_kept_blocks(mode, current_blocks);
            let pruned_blocks = current_blocks - kept_blocks;
            total_savings += (pruned_blocks as f64 / 100_000.0) * base_sizes["storage_history"];
        }
        
        total_savings as u64
    }
    
    fn calculate_kept_blocks(&self, mode: &PruneMode, current_blocks: u64) -> u64 {
        match mode {
            PruneMode::Full => 0,
            PruneMode::Distance(distance) => (*distance).min(current_blocks),
            PruneMode::Before(block) => current_blocks.saturating_sub(*block),
        }
    }
    
    fn assess_functionality_impact(&self, config: &PruneModes) -> FunctionalityReport {
        let mut affected_methods = Vec::new();
        let mut historical_limit = None;
        let mut log_limit = None;
        let mut functionality_loss = 0.0;
        
        // Assess transaction lookup impact
        if let Some(PruneMode::Distance(distance)) = config.transaction_lookup {
            if distance < 100_000 {
                affected_methods.push("eth_getTransactionByHash".to_string());
                affected_methods.push("eth_getTransactionReceipt".to_string());
                functionality_loss += 0.1;
            }
            historical_limit = Some(distance);
        }
        
        // Assess receipts impact
        if let Some(PruneMode::Distance(distance)) = config.receipts {
            if distance < 50_000 {
                affected_methods.push("eth_getLogs".to_string());
                affected_methods.push("eth_getFilterLogs".to_string());
                functionality_loss += 0.2;
            }
            log_limit = Some(distance);
        }
        
        // Assess history impact
        if let Some(PruneMode::Distance(distance)) = config.account_history {
            if distance < 10_000 {
                affected_methods.push("eth_getBalance".to_string());
                affected_methods.push("eth_getCode".to_string());
                affected_methods.push("eth_getStorageAt".to_string());
                functionality_loss += 0.15;
            }
        }
        
        // Full pruning has major impact
        if matches!(config.receipts, Some(PruneMode::Full)) {
            functionality_loss += 0.3;
        }
        
        FunctionalityReport {
            affected_rpc_methods: affected_methods,
            historical_query_limit: historical_limit,
            log_filtering_limit: log_limit,
            estimated_functionality_loss: functionality_loss.min(1.0),
        }
    }
}

#[test]
fn test_pruning_strategy() {
    // Test light node configuration
    let light_strategy = CustomPruningStrategy::new(
        NodeType::Light,
        200, // 200 GB limit
        false
    );
    
    let config = light_strategy.generate_config();
    let savings = light_strategy.calculate_storage_savings(&config);
    let impact = light_strategy.assess_functionality_impact(&config);
    
    // Light node should have significant savings
    assert!(savings > 500); // Should save 500+ GB
    
    // Should have some functionality impact
    assert!(impact.estimated_functionality_loss > 0.0);
    assert!(!impact.affected_rpc_methods.is_empty());
    
    // Test archive node
    let archive_strategy = CustomPruningStrategy::new(
        NodeType::Archive,
        5000, // 5TB limit
        true
    );
    
    let archive_config = archive_strategy.generate_config();
    let archive_savings = archive_strategy.calculate_storage_savings(&archive_config);
    let archive_impact = archive_strategy.assess_functionality_impact(&archive_config);
    
    // Archive should have no savings and no impact
    assert_eq!(archive_savings, 0);
    assert_eq!(archive_impact.estimated_functionality_loss, 0.0);
}
```

**Analysis**: This implementation provides a practical framework for configuring pruning based on node requirements. It demonstrates how to balance storage constraints with functionality needs, providing quantitative estimates of trade-offs.

### Answer 2: Pruning Monitor Implementation

```rust
use std::collections::{HashMap, VecDeque};
use std::time::{Duration, Instant, SystemTime, UNIX_EPOCH};

struct PruningMonitor {
    metrics: PruningMetrics,
    alerts: AlertManager,
    history: PruningHistory,
}

struct PruningMetrics {
    total_deleted_entries: u64,
    storage_freed: u64,
    last_run_duration: Duration,
    segments_processed: HashMap<PruneSegment, SegmentMetrics>,
    runs_completed: u64,
    errors_encountered: u64,
}

struct SegmentMetrics {
    entries_deleted: u64,
    deletion_rate: f64, // entries per second
    errors: u64,
    last_processed_block: BlockNumber,
    avg_processing_time: Duration,
}

struct AlertManager {
    thresholds: AlertThresholds,
    active_alerts: Vec<Alert>,
}

struct AlertThresholds {
    max_run_duration: Duration,
    min_deletion_rate: f64,
    max_error_rate: f64,
    storage_warning_gb: u64,
}

#[derive(Debug, Clone)]
struct Alert {
    severity: AlertSeverity,
    message: String,
    timestamp: SystemTime,
    segment: Option<PruneSegment>,
}

#[derive(Debug, Clone)]
enum AlertSeverity {
    Info,
    Warning,
    Critical,
}

struct PruningHistory {
    recent_runs: VecDeque<PruningRunRecord>,
    max_history: usize,
}

struct PruningRunRecord {
    timestamp: SystemTime,
    duration: Duration,
    deleted_entries: usize,
    segments_processed: Vec<PruneSegment>,
    success: bool,
}

#[derive(Debug)]
enum HealthStatus {
    Healthy,
    Warning(String),
    Critical(String),
}

#[derive(Debug)]
enum OptimizationSuggestion {
    IncreaseDeleteLimit { current: usize, suggested: usize },
    AdjustInterval { current: Duration, suggested: Duration },
    ChangeStrategy { segment: PruneSegment, suggested: PruneMode },
    ReduceTimeout { current: Duration, suggested: Duration },
    ParallelizeSegments,
}

impl PruningMonitor {
    fn new() -> Self {
        Self {
            metrics: PruningMetrics {
                total_deleted_entries: 0,
                storage_freed: 0,
                last_run_duration: Duration::ZERO,
                segments_processed: HashMap::new(),
                runs_completed: 0,
                errors_encountered: 0,
            },
            alerts: AlertManager {
                thresholds: AlertThresholds {
                    max_run_duration: Duration::from_secs(300), // 5 minutes
                    min_deletion_rate: 1000.0, // entries per second
                    max_error_rate: 0.05, // 5%
                    storage_warning_gb: 100, // Warn if less than 100GB free
                },
                active_alerts: Vec::new(),
            },
            history: PruningHistory {
                recent_runs: VecDeque::new(),
                max_history: 100,
            },
        }
    }
    
    fn track_pruning_run(&mut self, event: PrunerEvent) {
        match event {
            PrunerEvent::Started { tip_block_number } => {
                self.handle_run_started(tip_block_number);
            }
            
            PrunerEvent::Finished {
                tip_block_number,
                elapsed,
                deleted_entries,
                stats,
            } => {
                self.handle_run_finished(tip_block_number, elapsed, deleted_entries, stats);
            }
            
            PrunerEvent::Error { error, segment } => {
                self.handle_error(error, segment);
            }
        }
    }
    
    fn handle_run_started(&mut self, _tip_block_number: BlockNumber) {
        // Clear old alerts for new run
        self.alerts.active_alerts.retain(|alert| {
            alert.timestamp.elapsed().unwrap_or(Duration::ZERO) < Duration::from_secs(3600)
        });
    }
    
    fn handle_run_finished(
        &mut self,
        _tip_block_number: BlockNumber,
        elapsed: Duration,
        deleted_entries: usize,
        stats: Vec<PrunedSegmentInfo>,
    ) {
        // Update global metrics
        self.metrics.last_run_duration = elapsed;
        self.metrics.total_deleted_entries += deleted_entries as u64;
        self.metrics.runs_completed += 1;
        
        // Update segment metrics
        for stat in stats {
            let segment_metric = self.metrics.segments_processed
                .entry(stat.segment)
                .or_insert(SegmentMetrics {
                    entries_deleted: 0,
                    deletion_rate: 0.0,
                    errors: 0,
                    last_processed_block: 0,
                    avg_processing_time: Duration::ZERO,
                });
            
            segment_metric.entries_deleted += stat.deleted as u64;
            segment_metric.deletion_rate = stat.deleted as f64 / elapsed.as_secs_f64();
            segment_metric.last_processed_block = stat.to_block.unwrap_or(0);
            segment_metric.avg_processing_time = elapsed; // Simplified
        }
        
        // Record run in history
        let run_record = PruningRunRecord {
            timestamp: SystemTime::now(),
            duration: elapsed,
            deleted_entries,
            segments_processed: stats.iter().map(|s| s.segment).collect(),
            success: true,
        };
        
        self.history.recent_runs.push_back(run_record);
        if self.history.recent_runs.len() > self.history.max_history {
            self.history.recent_runs.pop_front();
        }
        
        // Check for alerts
        self.check_performance_alerts(elapsed, deleted_entries);
    }
    
    fn handle_error(&mut self, error: String, segment: Option<PruneSegment>) {
        self.metrics.errors_encountered += 1;
        
        if let Some(seg) = segment {
            if let Some(metric) = self.metrics.segments_processed.get_mut(&seg) {
                metric.errors += 1;
            }
        }
        
        let alert = Alert {
            severity: AlertSeverity::Critical,
            message: format!("Pruning error: {}", error),
            timestamp: SystemTime::now(),
            segment,
        };
        
        self.alerts.active_alerts.push(alert);
    }
    
    fn check_performance_alerts(&mut self, duration: Duration, deleted_entries: usize) {
        // Check run duration
        if duration > self.alerts.thresholds.max_run_duration {
            let alert = Alert {
                severity: AlertSeverity::Warning,
                message: format!(
                    "Pruning run took {}s, exceeds threshold of {}s",
                    duration.as_secs(),
                    self.alerts.thresholds.max_run_duration.as_secs()
                ),
                timestamp: SystemTime::now(),
                segment: None,
            };
            self.alerts.active_alerts.push(alert);
        }
        
        // Check deletion rate
        let deletion_rate = deleted_entries as f64 / duration.as_secs_f64();
        if deletion_rate < self.alerts.thresholds.min_deletion_rate {
            let alert = Alert {
                severity: AlertSeverity::Warning,
                message: format!(
                    "Low deletion rate: {:.0} entries/sec, threshold: {:.0}",
                    deletion_rate,
                    self.alerts.thresholds.min_deletion_rate
                ),
                timestamp: SystemTime::now(),
                segment: None,
            };
            self.alerts.active_alerts.push(alert);
        }
        
        // Check error rate
        let error_rate = self.metrics.errors_encountered as f64 / self.metrics.runs_completed as f64;
        if error_rate > self.alerts.thresholds.max_error_rate {
            let alert = Alert {
                severity: AlertSeverity::Critical,
                message: format!(
                    "High error rate: {:.1}%, threshold: {:.1}%",
                    error_rate * 100.0,
                    self.alerts.thresholds.max_error_rate * 100.0
                ),
                timestamp: SystemTime::now(),
                segment: None,
            };
            self.alerts.active_alerts.push(alert);
        }
    }
    
    fn check_health(&self) -> HealthStatus {
        // Check for critical alerts
        let critical_alerts: Vec<_> = self.alerts.active_alerts.iter()
            .filter(|a| matches!(a.severity, AlertSeverity::Critical))
            .collect();
        
        if !critical_alerts.is_empty() {
            return HealthStatus::Critical(
                format!("{} critical alerts active", critical_alerts.len())
            );
        }
        
        // Check for warnings
        let warning_alerts: Vec<_> = self.alerts.active_alerts.iter()
            .filter(|a| matches!(a.severity, AlertSeverity::Warning))
            .collect();
        
        if !warning_alerts.is_empty() {
            return HealthStatus::Warning(
                format!("{} warnings active", warning_alerts.len())
            );
        }
        
        // Check recent performance
        if let Some(last_run) = self.history.recent_runs.back() {
            if last_run.duration > Duration::from_secs(600) { // 10 minutes
                return HealthStatus::Warning(
                    "Recent pruning run was very slow".to_string()
                );
            }
        }
        
        HealthStatus::Healthy
    }
    
    fn suggest_optimizations(&self) -> Vec<OptimizationSuggestion> {
        let mut suggestions = Vec::new();
        
        // Analyze recent performance
        if self.history.recent_runs.len() >= 5 {
            let recent_avg_duration: Duration = self.history.recent_runs.iter()
                .rev()
                .take(5)
                .map(|r| r.duration)
                .sum::<Duration>() / 5;
            
            let recent_avg_deletions: f64 = self.history.recent_runs.iter()
                .rev()
                .take(5)
                .map(|r| r.deleted_entries as f64)
                .sum::<f64>() / 5.0;
            
            // Suggest increasing delete limit if consistently slow with low deletions
            if recent_avg_duration > Duration::from_secs(120) && recent_avg_deletions < 10000.0 {
                suggestions.push(OptimizationSuggestion::IncreaseDeleteLimit {
                    current: recent_avg_deletions as usize,
                    suggested: (recent_avg_deletions * 2.0) as usize,
                });
            }
            
            // Suggest reducing timeout if runs are quick
            if recent_avg_duration < Duration::from_secs(30) {
                suggestions.push(OptimizationSuggestion::ReduceTimeout {
                    current: Duration::from_secs(300),
                    suggested: Duration::from_secs(60),
                });
            }
        }
        
        // Analyze segment performance
        for (segment, metrics) in &self.metrics.segments_processed {
            if metrics.deletion_rate < 500.0 && metrics.errors == 0 {
                // Slow but error-free segment might benefit from more aggressive pruning
                suggestions.push(OptimizationSuggestion::ChangeStrategy {
                    segment: *segment,
                    suggested: PruneMode::Distance(50_000), // More aggressive
                });
            }
            
            if metrics.errors > 0 {
                // Segments with errors might need less aggressive pruning
                suggestions.push(OptimizationSuggestion::ChangeStrategy {
                    segment: *segment,
                    suggested: PruneMode::Distance(200_000), // Less aggressive
                });
            }
        }
        
        // Suggest parallelization if we have multiple slow segments
        let slow_segments = self.metrics.segments_processed.iter()
            .filter(|(_, m)| m.avg_processing_time > Duration::from_secs(60))
            .count();
        
        if slow_segments > 2 {
            suggestions.push(OptimizationSuggestion::ParallelizeSegments);
        }
        
        suggestions
    }
    
    fn get_summary_report(&self) -> String {
        format!(
            "Pruning Monitor Summary:\n\
             Total runs: {}\n\
             Total deleted entries: {}\n\
             Total storage freed: {} GB\n\
             Average run duration: {:.1}s\n\
             Error rate: {:.1}%\n\
             Active alerts: {}\n\
             Health status: {:?}",
            self.metrics.runs_completed,
            self.metrics.total_deleted_entries,
            self.metrics.storage_freed,
            self.history.recent_runs.iter()
                .map(|r| r.duration.as_secs_f64())
                .sum::<f64>() / self.history.recent_runs.len() as f64,
            (self.metrics.errors_encountered as f64 / self.metrics.runs_completed as f64) * 100.0,
            self.alerts.active_alerts.len(),
            self.check_health()
        )
    }
}

// Mock types for the example
#[derive(Debug)]
enum PrunerEvent {
    Started { tip_block_number: BlockNumber },
    Finished {
        tip_block_number: BlockNumber,
        elapsed: Duration,
        deleted_entries: usize,
        stats: Vec<PrunedSegmentInfo>,
    },
    Error { error: String, segment: Option<PruneSegment> },
}

#[derive(Debug)]
struct PrunedSegmentInfo {
    segment: PruneSegment,
    deleted: usize,
    from_block: Option<BlockNumber>,
    to_block: Option<BlockNumber>,
}

#[test]
fn test_pruning_monitor() {
    let mut monitor = PruningMonitor::new();
    
    // Simulate a successful run
    monitor.track_pruning_run(PrunerEvent::Started { tip_block_number: 1000 });
    
    let stats = vec![
        PrunedSegmentInfo {
            segment: PruneSegment::Receipts,
            deleted: 5000,
            from_block: Some(900),
            to_block: Some(950),
        }
    ];
    
    monitor.track_pruning_run(PrunerEvent::Finished {
        tip_block_number: 1000,
        elapsed: Duration::from_secs(30),
        deleted_entries: 5000,
        stats,
    });
    
    // Should be healthy after successful run
    assert!(matches!(monitor.check_health(), HealthStatus::Healthy));
    
    // Simulate an error
    monitor.track_pruning_run(PrunerEvent::Error {
        error: "Database connection failed".to_string(),
        segment: Some(PruneSegment::Receipts),
    });
    
    // Should now have alerts
    assert!(!monitor.alerts.active_alerts.is_empty());
    assert!(matches!(monitor.check_health(), HealthStatus::Critical(_)));
}
```

**Analysis**: This monitoring system provides comprehensive tracking of pruning operations with alerting and optimization suggestions. It demonstrates how to build observability into complex maintenance operations, enabling proactive optimization and issue detection.

### Answer 3: Dynamic Pruning Controller Implementation

```rust
use std::collections::HashMap;
use std::time::{Duration, SystemTime};

struct DynamicPruningController {
    current_config: PruneModes,
    storage_monitor: StorageMonitor,
    performance_monitor: PerformanceMonitor,
    adjustment_strategy: AdjustmentStrategy,
    last_adjustment: SystemTime,
    adjustment_cooldown: Duration,
}

struct StorageMonitor {
    total_space: u64,
    used_space: u64,
    growth_rate: f64, // GB per day
    blockchain_size: u64,
    last_measurement: SystemTime,
}

struct PerformanceMonitor {
    query_latency: HashMap<String, Duration>,
    sync_speed: f64, // blocks per second
    pruning_overhead: f64, // percentage of CPU time
    rpc_error_rate: f64,
    memory_usage: u64, // GB
}

#[derive(Debug, Clone)]
enum AdjustmentStrategy {
    Conservative, // Prefer functionality over storage
    Aggressive,   // Prefer storage savings over functionality
    Balanced,     // Balance between both
}

struct StoragePrediction {
    days_until_full: Option<u32>,
    projected_size_in_30_days: u64,
    weekly_growth_trend: f64,
}

struct PerformanceImpact {
    query_degradation: HashMap<String, f64>, // percentage slowdown
    sync_impact: f64,
    memory_impact: f64,
}

#[derive(Debug)]
enum ControllerError {
    InsufficientData,
    StorageMonitoringFailed,
    PerformanceDataStale,
    ConfigurationInvalid,
}

impl DynamicPruningController {
    fn new(initial_config: PruneModes, strategy: AdjustmentStrategy) -> Self {
        Self {
            current_config: initial_config,
            storage_monitor: StorageMonitor {
                total_space: 1000, // 1TB default
                used_space: 500,   // 500GB used
                growth_rate: 10.0, // 10GB per day
                blockchain_size: 400, // 400GB blockchain
                last_measurement: SystemTime::now(),
            },
            performance_monitor: PerformanceMonitor {
                query_latency: HashMap::new(),
                sync_speed: 50.0, // 50 blocks/sec
                pruning_overhead: 5.0, // 5% CPU
                rpc_error_rate: 0.01, // 1% error rate
                memory_usage: 8, // 8GB
            },
            adjustment_strategy: strategy,
            last_adjustment: SystemTime::now(),
            adjustment_cooldown: Duration::from_secs(3600), // 1 hour
        }
    }
    
    fn evaluate_and_adjust(&mut self) -> Result<PruneModes, ControllerError> {
        // Check if enough time has passed since last adjustment
        if self.last_adjustment.elapsed().unwrap_or(Duration::ZERO) < self.adjustment_cooldown {
            return Ok(self.current_config.clone());
        }
        
        // Update monitoring data
        self.update_storage_data()?;
        self.update_performance_data()?;
        
        // Analyze current situation
        let storage_pressure = self.calculate_storage_pressure();
        let performance_impact = self.calculate_performance_impact();
        let stability_score = self.calculate_stability_score();
        
        // Determine if adjustment is needed
        let adjustment_needed = self.should_adjust(storage_pressure, performance_impact, stability_score);
        
        if adjustment_needed {
            let new_config = self.generate_adjusted_config(storage_pressure, performance_impact)?;
            
            // Validate the new configuration
            self.validate_config(&new_config)?;
            
            // Apply the new configuration
            self.current_config = new_config.clone();
            self.last_adjustment = SystemTime::now();
            
            Ok(new_config)
        } else {
            Ok(self.current_config.clone())
        }
    }
    
    fn update_storage_data(&mut self) -> Result<(), ControllerError> {
        // Simulate reading current storage usage
        let current_time = SystemTime::now();
        let time_diff = current_time.duration_since(self.storage_monitor.last_measurement)
            .map_err(|_| ControllerError::StorageMonitoringFailed)?;
        
        if time_diff > Duration::from_secs(3600) { // Update if data is > 1 hour old
            // Simulate new measurements
            let old_used = self.storage_monitor.used_space;
            self.storage_monitor.used_space = old_used + (self.storage_monitor.growth_rate * time_diff.as_secs_f64() / 86400.0) as u64;
            
            // Update growth rate based on recent changes
            let daily_growth = (self.storage_monitor.used_space - old_used) as f64 * 86400.0 / time_diff.as_secs_f64();
            self.storage_monitor.growth_rate = (self.storage_monitor.growth_rate * 0.7) + (daily_growth * 0.3); // EMA
            
            self.storage_monitor.last_measurement = current_time;
        }
        
        Ok(())
    }
    
    fn update_performance_data(&mut self) -> Result<(), ControllerError> {
        // Simulate performance monitoring updates
        self.performance_monitor.query_latency.insert(
            "eth_getBalance".to_string(),
            Duration::from_millis(50 + (self.storage_monitor.used_space / 10) as u64)
        );
        
        self.performance_monitor.query_latency.insert(
            "eth_getLogs".to_string(),
            Duration::from_millis(200 + (self.storage_monitor.used_space / 5) as u64)
        );
        
        // Adjust sync speed based on storage pressure
        let storage_ratio = self.storage_monitor.used_space as f64 / self.storage_monitor.total_space as f64;
        self.performance_monitor.sync_speed = 50.0 * (1.0 - storage_ratio * 0.3);
        
        Ok(())
    }
    
    fn calculate_storage_pressure(&self) -> f64 {
        let usage_ratio = self.storage_monitor.used_space as f64 / self.storage_monitor.total_space as f64;
        let growth_pressure = self.storage_monitor.growth_rate / 50.0; // Normalize against 50GB/day baseline
        
        (usage_ratio * 0.7 + growth_pressure * 0.3).min(1.0)
    }
    
    fn calculate_performance_impact(&self) -> f64 {
        let avg_latency = self.performance_monitor.query_latency.values()
            .map(|d| d.as_millis() as f64)
            .sum::<f64>() / self.performance_monitor.query_latency.len() as f64;
        
        let latency_score = (avg_latency / 1000.0).min(1.0); // Normalize against 1 second
        let sync_score = (50.0 - self.performance_monitor.sync_speed) / 50.0; // Lower sync speed = higher impact
        let error_score = self.performance_monitor.rpc_error_rate * 100.0; // Error rate as percentage
        
        ((latency_score + sync_score + error_score) / 3.0).min(1.0)
    }
    
    fn calculate_stability_score(&self) -> f64 {
        // Higher score = more stable, less need for changes
        let low_error_score = (1.0 - self.performance_monitor.rpc_error_rate * 10.0).max(0.0);
        let consistent_sync_score = if self.performance_monitor.sync_speed > 30.0 { 0.8 } else { 0.3 };
        let low_overhead_score = (1.0 - self.performance_monitor.pruning_overhead / 20.0).max(0.0);
        
        (low_error_score + consistent_sync_score + low_overhead_score) / 3.0
    }
    
    fn should_adjust(&self, storage_pressure: f64, performance_impact: f64, stability_score: f64) -> bool {
        match self.adjustment_strategy {
            AdjustmentStrategy::Conservative => {
                // Only adjust if storage pressure is very high and stability is good
                storage_pressure > 0.8 && stability_score > 0.7
            }
            AdjustmentStrategy::Aggressive => {
                // Adjust more frequently for optimization
                storage_pressure > 0.5 || performance_impact > 0.6
            }
            AdjustmentStrategy::Balanced => {
                // Balance storage and performance concerns
                (storage_pressure > 0.7 && stability_score > 0.5) || 
                (performance_impact > 0.7 && storage_pressure > 0.4)
            }
        }
    }
    
    fn generate_adjusted_config(
        &self,
        storage_pressure: f64,
        performance_impact: f64,
    ) -> Result<PruneModes, ControllerError> {
        let mut new_config = self.current_config.clone();
        
        match self.adjustment_strategy {
            AdjustmentStrategy::Aggressive if storage_pressure > 0.6 => {
                // Increase pruning aggressiveness
                new_config = self.make_more_aggressive(new_config);
            }
            AdjustmentStrategy::Conservative if performance_impact > 0.7 => {
                // Reduce pruning to improve performance
                new_config = self.make_less_aggressive(new_config);
            }
            AdjustmentStrategy::Balanced => {
                if storage_pressure > performance_impact + 0.2 {
                    new_config = self.make_more_aggressive(new_config);
                } else if performance_impact > storage_pressure + 0.2 {
                    new_config = self.make_less_aggressive(new_config);
                }
            }
            _ => {} // No adjustment needed
        }
        
        Ok(new_config)
    }
    
    fn make_more_aggressive(&self, mut config: PruneModes) -> PruneModes {
        // Reduce retention distances by 25%
        if let Some(PruneMode::Distance(d)) = config.transaction_lookup {
            config.transaction_lookup = Some(PruneMode::Distance((d as f64 * 0.75) as u64));
        }
        
        if let Some(PruneMode::Distance(d)) = config.receipts {
            config.receipts = Some(PruneMode::Distance((d as f64 * 0.75) as u64));
        }
        
        if let Some(PruneMode::Distance(d)) = config.account_history {
            config.account_history = Some(PruneMode::Distance((d as f64 * 0.75) as u64));
        }
        
        if let Some(PruneMode::Distance(d)) = config.storage_history {
            config.storage_history = Some(PruneMode::Distance((d as f64 * 0.75) as u64));
        }
        
        config
    }
    
    fn make_less_aggressive(&self, mut config: PruneModes) -> PruneModes {
        // Increase retention distances by 50%
        if let Some(PruneMode::Distance(d)) = config.transaction_lookup {
            config.transaction_lookup = Some(PruneMode::Distance((d as f64 * 1.5) as u64));
        }
        
        if let Some(PruneMode::Distance(d)) = config.receipts {
            config.receipts = Some(PruneMode::Distance((d as f64 * 1.5) as u64));
        }
        
        if let Some(PruneMode::Distance(d)) = config.account_history {
            config.account_history = Some(PruneMode::Distance((d as f64 * 1.5) as u64));
        }
        
        if let Some(PruneMode::Distance(d)) = config.storage_history {
            config.storage_history = Some(PruneMode::Distance((d as f64 * 1.5) as u64));
        }
        
        config
    }
    
    fn validate_config(&self, config: &PruneModes) -> Result<(), ControllerError> {
        // Ensure minimum safety distances
        if let Some(PruneMode::Distance(d)) = config.account_history {
            if d < 1000 {
                return Err(ControllerError::ConfigurationInvalid);
            }
        }
        
        if let Some(PruneMode::Distance(d)) = config.storage_history {
            if d < 1000 {
                return Err(ControllerError::ConfigurationInvalid);
            }
        }
        
        Ok(())
    }
    
    fn predict_storage_usage(&self, config: &PruneModes) -> StoragePrediction {
        // Calculate expected storage savings from config
        let base_daily_growth = self.storage_monitor.growth_rate;
        
        // Estimate pruning effectiveness
        let pruning_factor = self.estimate_pruning_effectiveness(config);
        let adjusted_growth = base_daily_growth * (1.0 - pruning_factor);
        
        let available_space = self.storage_monitor.total_space - self.storage_monitor.used_space;
        let days_until_full = if adjusted_growth > 0.0 {
            Some((available_space as f64 / adjusted_growth) as u32)
        } else {
            None
        };
        
        let projected_size = self.storage_monitor.used_space + (adjusted_growth * 30.0) as u64;
        
        StoragePrediction {
            days_until_full,
            projected_size_in_30_days: projected_size,
            weekly_growth_trend: adjusted_growth * 7.0,
        }
    }
    
    fn estimate_pruning_effectiveness(&self, config: &PruneModes) -> f64 {
        let mut effectiveness = 0.0;
        
        // Simplified calculation based on typical segment sizes
        if let Some(PruneMode::Distance(d)) = config.receipts {
            effectiveness += 0.4 * (1.0 - (d as f64 / 200_000.0).min(1.0));
        }
        
        if let Some(PruneMode::Distance(d)) = config.transaction_lookup {
            effectiveness += 0.2 * (1.0 - (d as f64 / 200_000.0).min(1.0));
        }
        
        if let Some(PruneMode::Distance(d)) = config.account_history {
            effectiveness += 0.2 * (1.0 - (d as f64 / 200_000.0).min(1.0));
        }
        
        if let Some(PruneMode::Distance(d)) = config.storage_history {
            effectiveness += 0.2 * (1.0 - (d as f64 / 200_000.0).min(1.0));
        }
        
        effectiveness.min(0.8) // Cap at 80% effectiveness
    }
    
    fn assess_performance_impact(&self, config: &PruneModes) -> PerformanceImpact {
        let mut query_degradation = HashMap::new();
        
        // Estimate impact on specific RPC methods
        if let Some(PruneMode::Distance(d)) = config.transaction_lookup {
            let impact = if d < 50_000 { 0.3 } else if d < 100_000 { 0.1 } else { 0.0 };
            query_degradation.insert("eth_getTransactionByHash".to_string(), impact);
        }
        
        if let Some(PruneMode::Distance(d)) = config.receipts {
            let impact = if d < 20_000 { 0.5 } else if d < 50_000 { 0.2 } else { 0.0 };
            query_degradation.insert("eth_getLogs".to_string(), impact);
        }
        
        // Estimate sync impact
        let sync_impact = if matches!(config.account_history, Some(PruneMode::Distance(d)) if d < 10_000) {
            0.15 // 15% sync slowdown
        } else {
            0.0
        };
        
        // Estimate memory impact (aggressive pruning can increase memory usage due to more frequent operations)
        let memory_impact = self.estimate_pruning_effectiveness(config) * 0.1; // 10% of effectiveness
        
        PerformanceImpact {
            query_degradation,
            sync_impact,
            memory_impact,
        }
    }
}

#[test]
fn test_dynamic_controller() {
    let initial_config = PruneModes {
        sender_recovery: Some(PruneMode::Distance(10_000)),
        transaction_lookup: Some(PruneMode::Distance(100_000)),
        receipts: Some(PruneMode::Distance(100_000)),
        account_history: Some(PruneMode::Distance(50_000)),
        storage_history: Some(PruneMode::Distance(50_000)),
    };
    
    let mut controller = DynamicPruningController::new(
        initial_config,
        AdjustmentStrategy::Balanced
    );
    
    // Simulate high storage pressure
    controller.storage_monitor.used_space = 900; // 90% full
    controller.storage_monitor.growth_rate = 20.0; // High growth
    
    // Force adjustment by setting last adjustment time to past
    controller.last_adjustment = SystemTime::now() - Duration::from_secs(7200);
    
    let result = controller.evaluate_and_adjust();
    assert!(result.is_ok());
    
    // Should have adjusted to more aggressive pruning
    let new_config = result.unwrap();
    if let (Some(PruneMode::Distance(old)), Some(PruneMode::Distance(new))) = 
        (controller.current_config.receipts, new_config.receipts) {
        assert!(new < 100_000); // Should be more aggressive
    }
    
    // Test prediction
    let prediction = controller.predict_storage_usage(&new_config);
    assert!(prediction.days_until_full.is_some());
    
    // Test performance impact assessment
    let impact = controller.assess_performance_impact(&new_config);
    assert!(!impact.query_degradation.is_empty());
}
```

**Analysis**: This dynamic controller demonstrates sophisticated pruning management that adapts to real-world conditions. It balances storage constraints with performance requirements, providing predictive analytics and automated optimization. This approach is essential for maintaining optimal node performance as blockchain data grows and usage patterns change.

## Questions to Ponder

1. **How would you design a pruning strategy for a node that needs to serve both recent and historical data efficiently?**

2. **What are the trade-offs between moving data to static files vs. deleting it entirely?**

3. **How could machine learning be used to predict optimal pruning configurations based on usage patterns?**

4. **What happens to network security if too many nodes use aggressive pruning strategies?**

5. **How would you implement cross-client pruning coordination to ensure the network maintains sufficient data redundancy?**

Think about these questions as you explore state management strategies. The answers reveal the delicate balance between individual node optimization and network-wide data availability that's crucial for blockchain scalability.

## Congratulations! 🎉

You've completed the Reth Learning Curriculum (Lessons 22-30)! This advanced section covered:

- **Gas mechanics and optimization strategies**
- **Receipt structure and event processing** 
- **State root calculation and Merkle Patricia Tries**
- **Execution outcomes and state management**
- **Revert handling for blockchain reorganizations**
- **Block execution and transaction processing**
- **Hardfork management and protocol upgrades**
- **Storage proofs and stateless execution**
- **Pruning strategies and data lifecycle management**

You now have a deep understanding of Reth's advanced internals and the sophisticated systems that enable Ethereum's functionality at scale. These concepts form the foundation for building high-performance blockchain infrastructure and contribute to the future of decentralized systems.