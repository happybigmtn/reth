# Lesson 37: The Blockchain Tree

*"Everything that living things do can be understood in terms of the jigglings and wigglings of atoms." - Richard Feynman*

## Files with Inline Comments for This Lesson
- `crates/engine/tree/src/tree/mod.rs` - Main tree implementation and fork management
- `crates/engine/tree/src/tree/state.rs` - Tree state tracking for forks
- `crates/engine/tree/src/tree/block_buffer.rs` - Block buffering for out-of-order blocks
- `crates/chain-state/src/in_memory.rs` - In-memory canonical state tracking
- `crates/engine/tree/src/tree/error.rs` - Tree-specific error types

## What is the Blockchain Tree?

The blockchain tree is Reth's data structure for managing multiple competing blockchain forks simultaneously. It's essential for handling chain reorganizations, managing consensus updates from the beacon chain, and maintaining the canonical chain while keeping track of alternative branches.

```
Blockchain Tree Structure:
┌─────────────────────────────────────────────────┐
│              Finalized Block                    │
│               Block #1000                       │
└─────────────────┬───────────────────────────────┘
                  │
┌─────────────────┴───────────────────────────────┐
│           Tree State Root                       │
│         Canonical: #1100                        │
│                                                │
│  ┌──────────────┐  ┌──────────────┐            │
│  │ Block #1101A │  │ Block #1101B │ ← Forks    │
│  │ Parent: 1100 │  │ Parent: 1100 │            │
│  └──────┬───────┘  └──────┬───────┘            │
│         │                  │                     │
│  ┌──────┴───────┐  ┌──────┴───────┐            │
│  │ Block #1102A │  │ Block #1102B │            │
│  │ Parent: 1101A│  │ Parent: 1101B│            │
│  └──────┬───────┘  └──────────────┘            │
│         │                                        │
│  ┌──────┴───────┐                              │
│  │ Block #1103A │ ← Canonical head             │
│  │ Parent: 1102A│                              │
│  └──────────────┘                              │
└─────────────────────────────────────────────────┘
```

## Tree State Management

The tree maintains state for all connected blocks:

```rust
/// Tree state tracking
/// Located in: crates/engine/tree/src/tree/state.rs

use alloy_primitives::{BlockNumber, B256};
use reth_chain_state::ExecutedBlockWithTrieUpdates;
use std::collections::{BTreeMap, HashMap, HashSet};

/// Keeps track of the state of the tree
/// LESSON 37: Tree State Invariants
/// - Only stores blocks connected to the canonical chain
/// - All blocks are valid and have been executed
/// - Tracks parent-child relationships for reorg handling
#[derive(Debug, Default)]
pub struct TreeState<N: NodePrimitives = EthPrimitives> {
    /// All unique executed blocks by hash connected to canonical chain
    /// This includes blocks from all forks
    pub(crate) blocks_by_hash: HashMap<B256, ExecutedBlockWithTrieUpdates<N>>,
    
    /// Executed blocks grouped by block number
    /// Multiple blocks can exist at the same height due to forks
    pub(crate) blocks_by_number: BTreeMap<BlockNumber, Vec<ExecutedBlockWithTrieUpdates<N>>>,
    
    /// Parent hash -> children hashes mapping
    /// Essential for traversing forks and finding descendant blocks
    pub(crate) parent_to_child: HashMap<B256, HashSet<B256>>,
    
    /// Persisted but not finalized trie updates
    /// Kept for potential reorgs until finalization
    pub(crate) persisted_trie_updates: HashMap<B256, (BlockNumber, Arc<TrieUpdates>)>,
    
    /// Currently tracked canonical head
    pub(crate) current_canonical_head: BlockNumHash,
}

impl<N: NodePrimitives> TreeState<N> {
    /// Insert a new executed block into the tree
    pub(crate) fn insert_executed_block(
        &mut self,
        block: ExecutedBlockWithTrieUpdates<N>,
    ) -> Option<ExecutedBlockWithTrieUpdates<N>> {
        let block_num_hash = block.recovered_block().block_num_hash();
        let parent_hash = block.recovered_block().header().parent_hash();
        
        // LESSON 37: Parent-Child Tracking
        // We maintain bidirectional links between blocks
        // This allows efficient fork traversal in both directions
        self.parent_to_child
            .entry(parent_hash)
            .or_default()
            .insert(block_num_hash.hash);
        
        // Add to blocks by number (multiple blocks can have same number)
        self.blocks_by_number
            .entry(block_num_hash.number)
            .or_default()
            .push(block.clone());
        
        // Add to blocks by hash (unique)
        self.blocks_by_hash.insert(block_num_hash.hash, block)
    }
    
    /// Find the lowest common ancestor of two blocks
    pub(crate) fn find_common_ancestor(
        &self,
        block1: B256,
        block2: B256,
    ) -> Option<B256> {
        // Build ancestor chain for block1
        let mut ancestors1 = HashSet::new();
        let mut current = Some(block1);
        
        while let Some(hash) = current {
            ancestors1.insert(hash);
            current = self.blocks_by_hash
                .get(&hash)
                .map(|b| b.recovered_block().header().parent_hash());
        }
        
        // Walk block2's ancestors until we find common one
        current = Some(block2);
        while let Some(hash) = current {
            if ancestors1.contains(&hash) {
                return Some(hash);
            }
            current = self.blocks_by_hash
                .get(&hash)
                .map(|b| b.recovered_block().header().parent_hash());
        }
        
        None
    }
    
    /// Get all blocks that would be reorganized
    pub(crate) fn get_reorg_blocks(
        &self,
        from: B256,
        to: B256,
    ) -> (Vec<ExecutedBlockWithTrieUpdates<N>>, Vec<ExecutedBlockWithTrieUpdates<N>>) {
        let common_ancestor = self.find_common_ancestor(from, to)
            .expect("Blocks must have common ancestor");
        
        // Blocks to remove (current chain back to common ancestor)
        let mut to_remove = Vec::new();
        let mut current = from;
        while current != common_ancestor {
            if let Some(block) = self.blocks_by_hash.get(&current) {
                to_remove.push(block.clone());
                current = block.recovered_block().header().parent_hash();
            } else {
                break;
            }
        }
        
        // Blocks to add (new chain from common ancestor)
        let mut to_add = Vec::new();
        current = to;
        while current != common_ancestor {
            if let Some(block) = self.blocks_by_hash.get(&current) {
                to_add.push(block.clone());
                current = block.recovered_block().header().parent_hash();
            } else {
                break;
            }
        }
        
        // Reverse to_add so it's in forward order
        to_add.reverse();
        
        (to_remove, to_add)
    }
}
```

## Block Buffering

The tree buffers blocks that arrive out of order:

```rust
/// Block buffer for handling out-of-order blocks
/// Located in: crates/engine/tree/src/tree/block_buffer.rs

use alloy_primitives::{BlockNumber, B256};
use std::collections::{HashMap, VecDeque};

/// Buffers blocks that cannot be executed yet
#[derive(Debug, Default)]
pub struct BlockBuffer<B> {
    /// Blocks by hash for quick lookup
    pub(crate) blocks: HashMap<B256, B>,
    /// Blocks by parent hash for connecting chains
    pub(crate) by_parent: HashMap<B256, VecDeque<B>>,
    /// Earliest block number in buffer
    pub(crate) earliest_block_number: Option<BlockNumber>,
}

impl<B: Block> BlockBuffer<B> {
    /// Insert a block into the buffer
    /// LESSON 37: Out-of-Order Block Handling
    /// Blocks can arrive before their parents due to network delays
    /// We buffer them until the parent arrives and is executed
    pub(crate) fn insert(&mut self, block: B) -> BufferInsertResult {
        let hash = block.hash();
        let parent = block.parent_hash();
        let number = block.number();
        
        // Check if we already have this block
        if self.blocks.contains_key(&hash) {
            return BufferInsertResult::AlreadyExists;
        }
        
        // Update earliest block number
        match self.earliest_block_number {
            Some(earliest) if number < earliest => {
                self.earliest_block_number = Some(number);
            }
            None => {
                self.earliest_block_number = Some(number);
            }
            _ => {}
        }
        
        // Add to parent mapping
        self.by_parent
            .entry(parent)
            .or_default()
            .push_back(block.clone());
        
        // Add to hash mapping
        self.blocks.insert(hash, block);
        
        BufferInsertResult::Inserted
    }
    
    /// Get all blocks that can be connected to the given parent
    pub(crate) fn pop_children(&mut self, parent: B256) -> Vec<B> {
        self.by_parent
            .remove(&parent)
            .unwrap_or_default()
            .into_iter()
            .map(|block| {
                let hash = block.hash();
                self.blocks.remove(&hash);
                block
            })
            .collect()
    }
    
    /// Remove blocks below a certain height
    pub(crate) fn remove_old_blocks(&mut self, height: BlockNumber) {
        // Remove blocks below height
        self.blocks.retain(|_, block| block.number() > height);
        
        // Clean up parent mappings
        self.by_parent.retain(|_, children| {
            children.retain(|block| block.number() > height);
            !children.is_empty()
        });
        
        // Update earliest block number
        self.earliest_block_number = self.blocks
            .values()
            .map(|b| b.number())
            .min();
    }
}

#[derive(Debug, PartialEq)]
pub enum BufferInsertResult {
    Inserted,
    AlreadyExists,
}
```

## Fork Choice and Reorg Handling

```rust
/// Fork choice and reorganization logic
/// Located in: crates/engine/tree/src/tree/mod.rs

impl<Provider, Executor> EngineTree<Provider, Executor> {
    /// Process a fork choice update from consensus layer
    /// LESSON 37: Fork Choice Integration
    /// The beacon chain tells us which fork to follow through
    /// forkchoiceUpdated messages. This can trigger reorgs.
    fn on_forkchoice_updated(
        &mut self,
        state: ForkchoiceState,
        attrs: Option<PayloadAttributes>,
    ) -> Result<OnForkChoiceUpdated, InsertBlockError> {
        // Update fork choice tracker
        self.state.forkchoice_state_tracker.set_latest(state);
        
        let head = state.head_block_hash;
        let safe = state.safe_block_hash;
        let finalized = state.finalized_block_hash;
        
        // Check if we need to change the canonical chain
        if self.state.tree_state.current_canonical_head.hash != head {
            // Need to perform a reorg
            self.reorg_to_block(head)?;
        }
        
        // Update safe and finalized blocks
        self.update_safe_and_finalized(safe, finalized)?;
        
        // Handle payload attributes if building a block
        if let Some(attrs) = attrs {
            self.prepare_payload(attrs)?;
        }
        
        Ok(OnForkChoiceUpdated {
            payload_status: PayloadStatus::valid(),
            payload_id: self.payload_builder.current_id(),
        })
    }
    
    /// Perform a reorganization to the specified block
    fn reorg_to_block(&mut self, target: B256) -> Result<(), InsertBlockError> {
        let current = self.state.tree_state.current_canonical_head.hash;
        
        // Get blocks to remove and add
        let (to_remove, to_add) = self.state.tree_state.get_reorg_blocks(current, target);
        
        info!(
            target: "engine::tree",
            from = ?current,
            to = ?target,
            depth = to_remove.len(),
            "Performing reorg"
        );
        
        // LESSON 37: Reorg Execution
        // 1. Revert state changes from removed blocks
        // 2. Apply state changes from new blocks
        // 3. Update canonical head
        // 4. Notify listeners of the reorg
        
        // Revert removed blocks
        for block in to_remove.iter().rev() {
            self.revert_block_state(block)?;
        }
        
        // Apply new blocks
        for block in &to_add {
            self.apply_block_state(block)?;
        }
        
        // Update canonical head
        if let Some(new_head) = to_add.last() {
            self.state.tree_state.set_canonical_head(new_head.block_num_hash());
            self.canonical_in_memory_state.update_chain(NewCanonicalChain {
                new_blocks: to_add,
                removed_blocks: to_remove,
            });
        }
        
        Ok(())
    }
    
    /// Make a block canonical (extend the chain)
    fn make_canonical(&mut self, block_hash: B256) -> Result<(), InsertBlockError> {
        // This is simpler than reorg - just extending the chain
        let block = self.state.tree_state
            .executed_block_by_hash(block_hash)
            .ok_or(InsertBlockError::BlockNotFound)?
            .clone();
        
        // Update canonical head
        self.state.tree_state.set_canonical_head(block.block_num_hash());
        
        // Update in-memory state
        self.canonical_in_memory_state.extend_chain(vec![block]);
        
        // Notify listeners
        self.emit_event(BeaconConsensusEngineEvent::CanonicalChainCommitted {
            head: self.state.tree_state.current_canonical_head,
        });
        
        Ok(())
    }
}
```

## Invalid Block Handling

```rust
/// Invalid block tracking
/// Located in: crates/engine/tree/src/tree/invalid_headers.rs

use alloy_primitives::B256;
use std::collections::HashSet;

/// Cache for tracking invalid block headers
#[derive(Debug, Default)]
pub struct InvalidHeaderCache {
    /// Set of block hashes known to be invalid
    headers: HashSet<B256>,
}

impl InvalidHeaderCache {
    /// Check if a block is invalid
    pub fn contains(&self, hash: &B256) -> bool {
        self.headers.contains(hash)
    }
    
    /// Mark a block as invalid
    /// LESSON 37: Invalid Block Propagation
    /// When we discover an invalid block, we mark it and all
    /// its descendants as invalid to prevent wasted computation
    pub fn insert(&mut self, hash: B256) {
        self.headers.insert(hash);
    }
    
    /// Check if any ancestor is invalid
    pub fn is_descendant_invalid(
        &self,
        block: &impl Block,
        ancestor_lookup: impl Fn(B256) -> Option<B256>,
    ) -> bool {
        let mut current = block.parent_hash();
        
        // Walk up the ancestor chain
        while !current.is_zero() {
            if self.contains(&current) {
                return true;
            }
            
            // Get parent of current
            match ancestor_lookup(current) {
                Some(parent) => current = parent,
                None => break,
            }
        }
        
        false
    }
}
```

## Assignment 1: Fork Detection

Implement a system to detect and classify different types of forks.

```rust
/// Fork detection and classification
pub struct ForkDetector {
    canonical_chain: Vec<BlockNumHash>,
    known_forks: HashMap<B256, ForkInfo>,
}

#[derive(Debug, Clone)]
pub struct ForkInfo {
    pub fork_point: BlockNumHash,
    pub fork_head: B256,
    pub length: u64,
    pub total_difficulty: U256,
}

#[derive(Debug, PartialEq)]
pub enum ForkType {
    /// Short fork (1-2 blocks)
    MicroFork,
    /// Medium fork (3-10 blocks)  
    MinorFork,
    /// Long fork (>10 blocks)
    MajorFork,
}

impl ForkDetector {
    pub fn new(canonical_head: BlockNumHash) -> Self {
        // Your implementation here
        todo!()
    }
    
    /// Detect if a new block creates a fork
    pub fn detect_fork(&mut self, block: &SealedBlock, tree_state: &TreeState) -> Option<ForkInfo> {
        // Your implementation here
        todo!()
    }
    
    /// Classify a fork by its characteristics
    pub fn classify_fork(&self, fork_info: &ForkInfo) -> ForkType {
        // Your implementation here
        todo!()
    }
    
    /// Get competing forks at a given height
    pub fn get_forks_at_height(&self, height: BlockNumber) -> Vec<&ForkInfo> {
        // Your implementation here
        todo!()
    }
}
```

## Assignment 2: Reorg Metrics

Create a system to track and analyze reorganization patterns.

```rust
/// Track and analyze blockchain reorganizations
pub struct ReorgAnalyzer {
    reorg_history: VecDeque<ReorgEvent>,
    max_history: usize,
}

#[derive(Debug, Clone)]
pub struct ReorgEvent {
    pub timestamp: Instant,
    pub from_block: BlockNumHash,
    pub to_block: BlockNumHash,
    pub common_ancestor: BlockNumHash,
    pub depth: usize,
    pub blocks_removed: Vec<B256>,
    pub blocks_added: Vec<B256>,
}

#[derive(Debug)]
pub struct ReorgStats {
    pub total_reorgs: usize,
    pub average_depth: f64,
    pub max_depth: usize,
    pub reorgs_per_hour: f64,
    pub most_common_depth: usize,
}

impl ReorgAnalyzer {
    pub fn new(max_history: usize) -> Self {
        // Your implementation here
        todo!()
    }
    
    /// Record a new reorg event
    pub fn record_reorg(&mut self, event: ReorgEvent) {
        // Your implementation here
        todo!()
    }
    
    /// Calculate reorg statistics
    pub fn calculate_stats(&self, time_window: Duration) -> ReorgStats {
        // Your implementation here
        todo!()
    }
    
    /// Detect unusual reorg patterns
    pub fn detect_anomalies(&self) -> Vec<ReorgAnomaly> {
        // Your implementation here
        todo!()
    }
}

#[derive(Debug)]
pub enum ReorgAnomaly {
    DeepReorg { depth: usize },
    FrequentReorgs { count: usize, duration: Duration },
    RepeatedTarget { block: B256, count: usize },
}
```

## Assignment 3: Tree Pruning Strategy

Design a system to efficiently prune old forks from the tree.

```rust
/// Manage tree pruning to prevent unbounded growth
pub struct TreePruner {
    finalized_block: BlockNumHash,
    retention_distance: u64,
    fork_retention_time: Duration,
}

impl TreePruner {
    pub fn new(finalized: BlockNumHash, retention: u64, fork_time: Duration) -> Self {
        // Your implementation here
        todo!()
    }
    
    /// Determine which blocks can be pruned
    pub fn get_prunable_blocks(&self, tree_state: &TreeState) -> Vec<B256> {
        // Your implementation here
        todo!()
    }
    
    /// Prune blocks while preserving tree integrity
    pub fn prune_tree(&self, tree_state: &mut TreeState) -> PruneResult {
        // Your implementation here
        todo!()
    }
    
    /// Update finalized block and trigger pruning
    pub fn update_finalized(&mut self, finalized: BlockNumHash, tree_state: &mut TreeState) {
        // Your implementation here
        todo!()
    }
}

#[derive(Debug)]
pub struct PruneResult {
    pub blocks_removed: usize,
    pub space_reclaimed: usize,
    pub forks_removed: usize,
}
```

## Assignment Answers

### Assignment 1: Fork Detection

```rust
use alloy_primitives::{BlockNumber, B256, U256};
use std::collections::{HashMap, VecDeque};

/// Fork detection and classification
pub struct ForkDetector {
    canonical_chain: Vec<BlockNumHash>,
    known_forks: HashMap<B256, ForkInfo>,
}

#[derive(Debug, Clone)]
pub struct ForkInfo {
    pub fork_point: BlockNumHash,
    pub fork_head: B256,
    pub length: u64,
    pub total_difficulty: U256,
    pub created_at: Instant,
}

#[derive(Debug, PartialEq)]
pub enum ForkType {
    /// Short fork (1-2 blocks)
    MicroFork,
    /// Medium fork (3-10 blocks)  
    MinorFork,
    /// Long fork (>10 blocks)
    MajorFork,
}

impl ForkDetector {
    pub fn new(canonical_head: BlockNumHash) -> Self {
        Self {
            canonical_chain: vec![canonical_head],
            known_forks: HashMap::new(),
        }
    }
    
    /// Detect if a new block creates a fork
    pub fn detect_fork(&mut self, block: &SealedBlock, tree_state: &TreeState) -> Option<ForkInfo> {
        let block_hash = block.hash();
        let parent_hash = block.header.parent_hash;
        
        // Check if parent is not the canonical head
        let canonical_head = self.canonical_chain.last()?;
        
        if parent_hash != canonical_head.hash {
            // This creates a fork - find the fork point
            let fork_point = self.find_fork_point(parent_hash, tree_state)?;
            
            // Calculate fork length
            let mut length = 1;
            let mut current = parent_hash;
            
            while current != fork_point.hash {
                if let Some(parent_block) = tree_state.block_by_hash(current) {
                    current = parent_block.header.parent_hash;
                    length += 1;
                } else {
                    break;
                }
            }
            
            let fork_info = ForkInfo {
                fork_point,
                fork_head: block_hash,
                length,
                total_difficulty: U256::from(block.difficulty),
                created_at: Instant::now(),
            };
            
            self.known_forks.insert(block_hash, fork_info.clone());
            
            return Some(fork_info);
        }
        
        // Check if this extends a known fork
        if let Some(fork) = self.known_forks.get_mut(&parent_hash) {
            fork.fork_head = block_hash;
            fork.length += 1;
            fork.total_difficulty += U256::from(block.difficulty);
            
            let updated_fork = fork.clone();
            self.known_forks.insert(block_hash, updated_fork.clone());
            self.known_forks.remove(&parent_hash);
            
            return Some(updated_fork);
        }
        
        None
    }
    
    /// Find the common ancestor between a block and canonical chain
    fn find_fork_point(&self, mut block_hash: B256, tree_state: &TreeState) -> Option<BlockNumHash> {
        let canonical_hashes: HashMap<B256, BlockNumHash> = self.canonical_chain
            .iter()
            .map(|b| (b.hash, *b))
            .collect();
        
        // Walk up from the block until we find canonical chain
        while !block_hash.is_zero() {
            if let Some(&canonical) = canonical_hashes.get(&block_hash) {
                return Some(canonical);
            }
            
            // Get parent
            block_hash = tree_state.block_by_hash(block_hash)?
                .header
                .parent_hash;
        }
        
        None
    }
    
    /// Classify a fork by its characteristics
    pub fn classify_fork(&self, fork_info: &ForkInfo) -> ForkType {
        match fork_info.length {
            1..=2 => ForkType::MicroFork,
            3..=10 => ForkType::MinorFork,
            _ => ForkType::MajorFork,
        }
    }
    
    /// Get competing forks at a given height
    pub fn get_forks_at_height(&self, height: BlockNumber) -> Vec<&ForkInfo> {
        self.known_forks
            .values()
            .filter(|fork| {
                // Check if fork spans this height
                let fork_start = fork.fork_point.number;
                let fork_end = fork_start + fork.length;
                height > fork_start && height <= fork_end
            })
            .collect()
    }
    
    /// Update canonical chain on reorg
    pub fn update_canonical_chain(&mut self, new_chain: Vec<BlockNumHash>) {
        self.canonical_chain = new_chain;
        
        // Remove forks that are now canonical
        self.known_forks.retain(|hash, _| {
            !self.canonical_chain.iter().any(|b| &b.hash == hash)
        });
    }
    
    /// Clean up old forks
    pub fn cleanup_old_forks(&mut self, max_age: Duration) {
        let now = Instant::now();
        self.known_forks.retain(|_, fork| {
            now.duration_since(fork.created_at) < max_age
        });
    }
}
```

### Assignment 2: Reorg Metrics

```rust
use std::collections::{HashMap, VecDeque};
use std::time::{Duration, Instant};

/// Track and analyze blockchain reorganizations
pub struct ReorgAnalyzer {
    reorg_history: VecDeque<ReorgEvent>,
    max_history: usize,
    depth_histogram: HashMap<usize, usize>,
}

#[derive(Debug, Clone)]
pub struct ReorgEvent {
    pub timestamp: Instant,
    pub from_block: BlockNumHash,
    pub to_block: BlockNumHash,
    pub common_ancestor: BlockNumHash,
    pub depth: usize,
    pub blocks_removed: Vec<B256>,
    pub blocks_added: Vec<B256>,
}

#[derive(Debug)]
pub struct ReorgStats {
    pub total_reorgs: usize,
    pub average_depth: f64,
    pub max_depth: usize,
    pub reorgs_per_hour: f64,
    pub most_common_depth: usize,
    pub depth_distribution: HashMap<usize, usize>,
}

impl ReorgAnalyzer {
    pub fn new(max_history: usize) -> Self {
        Self {
            reorg_history: VecDeque::with_capacity(max_history),
            max_history,
            depth_histogram: HashMap::new(),
        }
    }
    
    /// Record a new reorg event
    pub fn record_reorg(&mut self, event: ReorgEvent) {
        // Update depth histogram
        *self.depth_histogram.entry(event.depth).or_insert(0) += 1;
        
        // Add to history
        self.reorg_history.push_back(event);
        
        // Maintain max history size
        while self.reorg_history.len() > self.max_history {
            if let Some(old_event) = self.reorg_history.pop_front() {
                // Decrement histogram
                if let Some(count) = self.depth_histogram.get_mut(&old_event.depth) {
                    *count = count.saturating_sub(1);
                    if *count == 0 {
                        self.depth_histogram.remove(&old_event.depth);
                    }
                }
            }
        }
    }
    
    /// Calculate reorg statistics
    pub fn calculate_stats(&self, time_window: Duration) -> ReorgStats {
        let now = Instant::now();
        
        // Filter events within time window
        let recent_events: Vec<_> = self.reorg_history
            .iter()
            .filter(|event| now.duration_since(event.timestamp) <= time_window)
            .collect();
        
        let total_reorgs = recent_events.len();
        
        // Calculate average depth
        let average_depth = if total_reorgs > 0 {
            recent_events.iter().map(|e| e.depth as f64).sum::<f64>() / total_reorgs as f64
        } else {
            0.0
        };
        
        // Find max depth
        let max_depth = recent_events
            .iter()
            .map(|e| e.depth)
            .max()
            .unwrap_or(0);
        
        // Calculate reorgs per hour
        let hours = time_window.as_secs_f64() / 3600.0;
        let reorgs_per_hour = if hours > 0.0 {
            total_reorgs as f64 / hours
        } else {
            0.0
        };
        
        // Find most common depth
        let most_common_depth = self.depth_histogram
            .iter()
            .max_by_key(|(_, count)| *count)
            .map(|(depth, _)| *depth)
            .unwrap_or(0);
        
        ReorgStats {
            total_reorgs,
            average_depth,
            max_depth,
            reorgs_per_hour,
            most_common_depth,
            depth_distribution: self.depth_histogram.clone(),
        }
    }
    
    /// Detect unusual reorg patterns
    pub fn detect_anomalies(&self) -> Vec<ReorgAnomaly> {
        let mut anomalies = Vec::new();
        let now = Instant::now();
        
        // Check for deep reorgs
        for event in &self.reorg_history {
            if event.depth > 6 {
                anomalies.push(ReorgAnomaly::DeepReorg { 
                    depth: event.depth 
                });
            }
        }
        
        // Check for frequent reorgs
        let one_hour_ago = now - Duration::from_secs(3600);
        let recent_count = self.reorg_history
            .iter()
            .filter(|e| e.timestamp > one_hour_ago)
            .count();
        
        if recent_count > 10 {
            anomalies.push(ReorgAnomaly::FrequentReorgs {
                count: recent_count,
                duration: Duration::from_secs(3600),
            });
        }
        
        // Check for repeated reorg targets
        let mut target_counts: HashMap<B256, usize> = HashMap::new();
        for event in &self.reorg_history {
            *target_counts.entry(event.to_block.hash).or_insert(0) += 1;
        }
        
        for (block, count) in target_counts {
            if count > 3 {
                anomalies.push(ReorgAnomaly::RepeatedTarget { block, count });
            }
        }
        
        anomalies
    }
    
    /// Get reorg pattern analysis
    pub fn analyze_patterns(&self) -> ReorgPatternAnalysis {
        let stats = self.calculate_stats(Duration::from_secs(86400)); // 24 hours
        
        // Analyze time patterns
        let mut hourly_distribution = [0usize; 24];
        for event in &self.reorg_history {
            let hour = (event.timestamp.elapsed().as_secs() / 3600) % 24;
            hourly_distribution[hour as usize] += 1;
        }
        
        // Find correlation between depth and blocks added/removed
        let depth_vs_changes: Vec<(usize, usize)> = self.reorg_history
            .iter()
            .map(|e| (e.depth, e.blocks_added.len() + e.blocks_removed.len()))
            .collect();
        
        ReorgPatternAnalysis {
            stats,
            hourly_distribution,
            depth_vs_changes,
            anomalies: self.detect_anomalies(),
        }
    }
}

#[derive(Debug)]
pub enum ReorgAnomaly {
    DeepReorg { depth: usize },
    FrequentReorgs { count: usize, duration: Duration },
    RepeatedTarget { block: B256, count: usize },
}

#[derive(Debug)]
pub struct ReorgPatternAnalysis {
    pub stats: ReorgStats,
    pub hourly_distribution: [usize; 24],
    pub depth_vs_changes: Vec<(usize, usize)>,
    pub anomalies: Vec<ReorgAnomaly>,
}
```

### Assignment 3: Tree Pruning Strategy

```rust
use alloy_primitives::{BlockNumber, B256};
use std::collections::{HashMap, HashSet};
use std::time::{Duration, Instant};

/// Manage tree pruning to prevent unbounded growth
pub struct TreePruner {
    finalized_block: BlockNumHash,
    retention_distance: u64,
    fork_retention_time: Duration,
    fork_timestamps: HashMap<B256, Instant>,
}

impl TreePruner {
    pub fn new(finalized: BlockNumHash, retention: u64, fork_time: Duration) -> Self {
        Self {
            finalized_block: finalized,
            retention_distance: retention,
            fork_retention_time: fork_time,
            fork_timestamps: HashMap::new(),
        }
    }
    
    /// Determine which blocks can be pruned
    pub fn get_prunable_blocks(&self, tree_state: &TreeState) -> Vec<B256> {
        let mut prunable = Vec::new();
        let now = Instant::now();
        
        // Blocks to keep: canonical chain and recent forks
        let mut keep = HashSet::new();
        
        // Keep canonical chain blocks
        let canonical_head = tree_state.current_canonical_head;
        let mut current = canonical_head.hash;
        let mut blocks_back = 0;
        
        while !current.is_zero() && blocks_back < self.retention_distance * 2 {
            keep.insert(current);
            
            if let Some(block) = tree_state.block_by_hash(current) {
                current = block.header.parent_hash;
                blocks_back += 1;
            } else {
                break;
            }
        }
        
        // Keep finalized block and ancestors
        current = self.finalized_block.hash;
        while !current.is_zero() {
            keep.insert(current);
            
            if let Some(block) = tree_state.block_by_hash(current) {
                current = block.header.parent_hash;
            } else {
                break;
            }
        }
        
        // Check each block in tree
        for (hash, block) in &tree_state.blocks_by_hash {
            // Skip if we should keep it
            if keep.contains(hash) {
                continue;
            }
            
            // Prune if below finalized
            if block.block_number() < self.finalized_block.number {
                prunable.push(*hash);
                continue;
            }
            
            // Prune if too far from canonical head
            if canonical_head.number.saturating_sub(block.block_number()) > self.retention_distance {
                prunable.push(*hash);
                continue;
            }
            
            // Prune old forks
            if let Some(&timestamp) = self.fork_timestamps.get(hash) {
                if now.duration_since(timestamp) > self.fork_retention_time {
                    prunable.push(*hash);
                }
            }
        }
        
        prunable
    }
    
    /// Prune blocks while preserving tree integrity
    pub fn prune_tree(&self, tree_state: &mut TreeState) -> PruneResult {
        let prunable = self.get_prunable_blocks(tree_state);
        let mut result = PruneResult {
            blocks_removed: 0,
            space_reclaimed: 0,
            forks_removed: 0,
        };
        
        // Track which forks we're removing
        let mut removed_fork_heads = HashSet::new();
        
        for hash in prunable {
            if let Some(block) = tree_state.blocks_by_hash.remove(&hash) {
                result.blocks_removed += 1;
                
                // Estimate space (block + trie updates)
                result.space_reclaimed += std::mem::size_of_val(&block);
                
                // Remove from blocks by number
                if let Some(blocks) = tree_state.blocks_by_number.get_mut(&block.block_number()) {
                    blocks.retain(|b| b.block_hash() != hash);
                    if blocks.is_empty() {
                        tree_state.blocks_by_number.remove(&block.block_number());
                    }
                }
                
                // Remove from parent-child mapping
                let parent = block.header().parent_hash;
                if let Some(children) = tree_state.parent_to_child.get_mut(&parent) {
                    children.remove(&hash);
                    if children.is_empty() {
                        tree_state.parent_to_child.remove(&parent);
                    }
                }
                
                // Check if this was a fork head
                if tree_state.parent_to_child.get(&hash).map(|c| c.is_empty()).unwrap_or(true) {
                    removed_fork_heads.insert(hash);
                }
                
                // Remove persisted trie updates
                if let Some((_, trie_updates)) = tree_state.persisted_trie_updates.remove(&hash) {
                    result.space_reclaimed += std::mem::size_of_val(&*trie_updates);
                }
            }
        }
        
        result.forks_removed = removed_fork_heads.len();
        result
    }
    
    /// Update finalized block and trigger pruning
    pub fn update_finalized(&mut self, finalized: BlockNumHash, tree_state: &mut TreeState) {
        let old_finalized = self.finalized_block;
        self.finalized_block = finalized;
        
        // Prune if finalized advanced
        if finalized.number > old_finalized.number {
            let result = self.prune_tree(tree_state);
            
            info!(
                target: "tree::pruner",
                finalized = finalized.number,
                blocks_removed = result.blocks_removed,
                space_reclaimed = result.space_reclaimed,
                forks_removed = result.forks_removed,
                "Pruned tree state"
            );
        }
        
        // Update fork timestamps for new forks
        let canonical = tree_state.current_canonical_head;
        for (hash, _) in &tree_state.blocks_by_hash {
            if !self.is_canonical(*hash, canonical, tree_state) {
                self.fork_timestamps.entry(*hash).or_insert_with(Instant::now);
            }
        }
        
        // Clean up timestamps for pruned blocks
        self.fork_timestamps.retain(|hash, _| {
            tree_state.blocks_by_hash.contains_key(hash)
        });
    }
    
    /// Check if a block is on the canonical chain
    fn is_canonical(&self, hash: B256, canonical_head: BlockNumHash, tree_state: &TreeState) -> bool {
        let mut current = canonical_head.hash;
        
        while !current.is_zero() {
            if current == hash {
                return true;
            }
            
            if let Some(block) = tree_state.block_by_hash(current) {
                current = block.header.parent_hash;
            } else {
                break;
            }
        }
        
        false
    }
}

#[derive(Debug, Default)]
pub struct PruneResult {
    pub blocks_removed: usize,
    pub space_reclaimed: usize,
    pub forks_removed: usize,
}
```

## Questions to Ponder

1. **Fork Resolution**: How does the consensus layer decide which fork to follow? What role does attestation weight play?

2. **Tree Growth**: What strategies can prevent unbounded tree growth while maintaining enough history for reorgs?

3. **Invalid Block Handling**: How should the tree handle blocks that pass initial validation but fail execution?

4. **Performance Trade-offs**: What's the optimal balance between keeping fork history and memory usage?

5. **Finality Impact**: How does finality change tree management? Can we be more aggressive with pruning finalized forks?

Understanding the blockchain tree is crucial for grasping how Ethereum handles competing chains and maintains consensus in a distributed system.