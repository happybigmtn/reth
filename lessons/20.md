# Lesson 20: Chain Reorgs and Fork Choice

*"The worthwhile problems are the ones you can really solve or help solve, the ones you can really contribute something to." - Richard Feynman*

## Files with Inline Comments for This Lesson
- `crates/blockchain-tree/src/blockchain_tree.rs` - Blockchain tree implementation
- `crates/engine/tree/src/tree/mod.rs` - Engine tree for fork choice
- `crates/consensus/beacon/src/engine/forkchoice.rs` - Fork choice implementation
- `crates/stages/api/src/pipeline/ctrl.rs` - Pipeline control flow

## Understanding Chain Reorganizations

Chain reorganizations (reorgs) occur when a different chain becomes the canonical chain:

```
Original Chain:
A → B → C → D

New Chain (longer/heavier):
A → B → E → F → G

Result: Reorg from C→D back to B, then forward to E→F→G
```

## Blockchain Tree Structure

### Core Architecture

```rust
/// The blockchain tree maintains multiple competing chains
pub struct BlockchainTree {
    /// The canonical chain (finalized blocks)
    canonical_chain: Arc<Chain>,
    /// Pending chains that may become canonical
    pending_chains: HashMap<BlockHash, Chain>,
    /// Configuration for the tree
    config: BlockchainTreeConfig,
    /// Fork choice rule (heaviest chain, etc.)
    fork_choice: ForkChoice,
}

/// Represents a chain of blocks
#[derive(Debug, Clone)]
pub struct Chain {
    /// Chain of blocks from fork point to tip
    blocks: Vec<SealedBlock>,
    /// Execution outcome for this chain
    execution_outcome: ExecutionOutcome,
    /// Total difficulty or weight
    total_difficulty: U256,
}

impl Chain {
    /// Add a new block to the chain
    pub fn append_block(
        &mut self,
        block: SealedBlock,
        execution_outcome: ExecutionOutcome,
    ) -> Result<(), ChainError> {
        // Validate block connects to chain tip
        if block.parent_hash != self.tip().hash() {
            return Err(ChainError::InvalidParent);
        }
        
        // Update total difficulty
        self.total_difficulty += block.difficulty;
        
        // Add block and execution result
        self.blocks.push(block);
        self.execution_outcome.extend(execution_outcome);
        
        Ok(())
    }
    
    /// Get the tip of the chain
    pub fn tip(&self) -> &SealedBlock {
        self.blocks.last().expect("Chain cannot be empty")
    }
    
    /// Get the fork point where this chain diverged
    pub fn fork_point(&self) -> BlockNumber {
        self.blocks.first()
            .map(|b| b.number - 1)
            .unwrap_or_default()
    }
}
```

## Fork Choice Implementation

### Heaviest Chain Rule

```rust
/// Implements fork choice rule for determining canonical chain
pub struct ForkChoice {
    /// The rule to use (weight, difficulty, etc.)
    rule: ForkChoiceRule,
}

#[derive(Debug, Clone)]
pub enum ForkChoiceRule {
    /// Longest chain (most blocks)
    LongestChain,
    /// Heaviest chain (most total difficulty)
    HeaviestChain,
    /// Proof of Stake (based on validators)
    ProofOfStake { finalized_block: BlockNumber },
}

impl ForkChoice {
    /// Determine which chain should be canonical
    pub fn select_canonical_chain(
        &self,
        current: &Chain,
        alternative: &Chain,
    ) -> CanonicalChoice {
        match self.rule {
            ForkChoiceRule::HeaviestChain => {
                if alternative.total_difficulty > current.total_difficulty {
                    CanonicalChoice::Alternative
                } else {
                    CanonicalChoice::Current
                }
            }
            ForkChoiceRule::LongestChain => {
                match alternative.blocks.len().cmp(&current.blocks.len()) {
                    Ordering::Greater => CanonicalChoice::Alternative,
                    Ordering::Less => CanonicalChoice::Current,
                    Ordering::Equal => {
                        // Tie-breaker: choose chain with lower hash
                        if alternative.tip().hash() < current.tip().hash() {
                            CanonicalChoice::Alternative
                        } else {
                            CanonicalChoice::Current
                        }
                    }
                }
            }
            ForkChoiceRule::ProofOfStake { finalized_block } => {
                // In PoS, we follow the beacon chain's finality
                // This is more complex and involves validator attestations
                self.pos_fork_choice(current, alternative, finalized_block)
            }
        }
    }
}

#[derive(Debug, PartialEq)]
pub enum CanonicalChoice {
    /// Keep current chain as canonical
    Current,
    /// Switch to alternative chain
    Alternative,
}
```

## Engine Tree for Consensus Integration

### Beacon Chain Integration

```rust
/// The engine tree manages the interaction between execution and consensus
pub struct EngineTree {
    /// The blockchain tree
    blockchain_tree: BlockchainTree,
    /// Payload store for pending payloads
    payload_store: PayloadStore,
    /// Configuration
    config: EngineConfig,
}

impl EngineTree {
    /// Handle a new payload from the beacon chain
    pub async fn new_payload(
        &mut self,
        payload: ExecutionPayload,
        versioned_hashes: Vec<B256>,
    ) -> Result<PayloadStatus, EngineError> {
        // Validate the payload
        let block = self.validate_payload(&payload, &versioned_hashes)?;
        
        // Execute the block
        let execution_outcome = self.execute_block(&block).await?;
        
        // Store the payload for potential finalization
        self.payload_store.insert(payload.block_hash(), payload);
        
        // Add to blockchain tree
        match self.blockchain_tree.insert_block(block, execution_outcome) {
            Ok(InsertResult::Canonical) => {
                Ok(PayloadStatus::Valid { latest_valid_hash: Some(block.hash()) })
            }
            Ok(InsertResult::SideChain) => {
                Ok(PayloadStatus::Valid { latest_valid_hash: Some(block.hash()) })
            }
            Err(BlockchainTreeError::InvalidBlock(err)) => {
                Ok(PayloadStatus::Invalid { 
                    latest_valid_hash: Some(block.parent_hash),
                    validation_error: err.to_string(),
                })
            }
            Err(err) => Err(EngineError::Tree(err)),
        }
    }
    
    /// Handle forkchoice update from beacon chain
    pub async fn forkchoice_updated(
        &mut self,
        update: ForkchoiceState,
        payload_attributes: Option<PayloadAttributes>,
    ) -> Result<ForkchoiceUpdateResult, EngineError> {
        // Find the chain containing the new head
        let target_chain = self.blockchain_tree
            .find_chain_by_hash(update.head_block_hash)
            .ok_or(EngineError::UnknownBlock)?;
            
        // Check if we need to reorg
        if target_chain.tip().hash() != self.blockchain_tree.canonical_tip().hash() {
            // Trigger reorg
            self.reorg_to_chain(target_chain).await?;
        }
        
        // Update finalized block
        if let Some(finalized_hash) = update.finalized_block_hash {
            self.finalize_block(finalized_hash)?;
        }
        
        // Start building new payload if requested
        let payload_id = if let Some(attributes) = payload_attributes {
            Some(self.start_payload_building(attributes).await?)
        } else {
            None
        };
        
        Ok(ForkchoiceUpdateResult {
            payload_status: PayloadStatus::Valid { 
                latest_valid_hash: Some(update.head_block_hash) 
            },
            payload_id,
        })
    }
}
```

## Reorg Processing

### Step-by-Step Reorg

```rust
impl BlockchainTree {
    /// Perform a reorganization to make the target chain canonical
    pub async fn reorg_to_chain(
        &mut self,
        target_chain: &Chain,
    ) -> Result<ReorgOutcome, ReorgError> {
        let current_tip = self.canonical_chain.tip();
        let target_tip = target_chain.tip();
        
        info!(
            "Starting reorg from block {} to block {}",
            current_tip.number,
            target_tip.number
        );
        
        // 1. Find the common ancestor (fork point)
        let fork_point = self.find_fork_point(&self.canonical_chain, target_chain)?;
        
        // 2. Unwind canonical chain to fork point
        let unwound_blocks = self.unwind_to_block(fork_point).await?;
        
        // 3. Apply the target chain from fork point
        let applied_blocks = self.apply_chain_from_fork(target_chain, fork_point).await?;
        
        // 4. Update canonical chain
        self.canonical_chain = target_chain.clone();
        
        // 5. Emit reorg event
        self.emit_reorg_event(ReorgEvent {
            old_chain: unwound_blocks,
            new_chain: applied_blocks,
            fork_point,
            depth: current_tip.number - fork_point,
        });
        
        Ok(ReorgOutcome {
            unwound_blocks: unwound_blocks.len(),
            applied_blocks: applied_blocks.len(),
            fork_point,
        })
    }
    
    /// Find the common ancestor of two chains
    fn find_fork_point(
        &self,
        chain_a: &Chain,
        chain_b: &Chain,
    ) -> Result<BlockNumber, ReorgError> {
        // Walk back through both chains until we find a common block
        let mut a_blocks = chain_a.blocks.iter().rev();
        let mut b_blocks = chain_b.blocks.iter().rev();
        
        loop {
            match (a_blocks.next(), b_blocks.next()) {
                (Some(a_block), Some(b_block)) => {
                    // Check if blocks share a parent
                    if a_block.parent_hash == b_block.parent_hash {
                        return Ok(a_block.parent_number());
                    }
                    // If blocks are the same, this is the fork point
                    if a_block.hash() == b_block.hash() {
                        return Ok(a_block.number);
                    }
                }
                _ => break,
            }
        }
        
        // If no common point found in memory, search database
        self.find_fork_point_in_database(chain_a, chain_b)
    }
    
    /// Unwind the canonical chain to a specific block
    async fn unwind_to_block(
        &mut self,
        target_block: BlockNumber,
    ) -> Result<Vec<SealedBlock>, ReorgError> {
        let mut unwound_blocks = Vec::new();
        let current_tip = self.canonical_chain.tip().number;
        
        if target_block >= current_tip {
            return Ok(unwound_blocks); // Nothing to unwind
        }
        
        // Trigger pipeline unwind
        self.pipeline.unwind(target_block, None).await?;
        
        // Collect unwound blocks for event
        for block_num in (target_block + 1)..=current_tip {
            if let Some(block) = self.get_block_by_number(block_num)? {
                unwound_blocks.push(block);
            }
        }
        
        Ok(unwound_blocks)
    }
}
```

## Pipeline Integration

### Handling Reorgs in Staged Sync

```rust
/// Control flow for pipeline execution
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum ControlFlow {
    /// Continue with next stage
    Continue { block_number: BlockNumber },
    /// No progress made
    NoProgress { block_number: Option<BlockNumber> },
    /// Unwind required
    Unwind { target: BlockNumber, bad_block: BlockErrorKind },
}

impl ControlFlow {
    /// Check if this is an unwind operation
    pub fn is_unwind(&self) -> bool {
        matches!(self, ControlFlow::Unwind { .. })
    }
    
    /// Should the pipeline continue running?
    pub fn should_continue(&self) -> bool {
        !matches!(self, ControlFlow::NoProgress { block_number: None })
    }
}

/// Pipeline integration with blockchain tree
impl Pipeline {
    /// Handle a reorg notification from the blockchain tree
    pub async fn handle_reorg(
        &mut self,
        reorg: ReorgNotification,
    ) -> Result<(), PipelineError> {
        match reorg {
            ReorgNotification::Unwind { target, reason } => {
                info!("Pipeline unwinding to block {} due to {}", target, reason);
                
                // Unwind all stages to the target block
                self.unwind(target, None).await?;
                
                // Reset progress tracking
                self.progress.reset_to(target);
                
                Ok(())
            }
            ReorgNotification::Finalize { block_number } => {
                info!("Finalizing block {}", block_number);
                
                // Update finalized block in database
                self.finalize_block(block_number)?;
                
                Ok(())
            }
        }
    }
}

#[derive(Debug, Clone)]
pub enum ReorgNotification {
    /// Unwind to a specific block
    Unwind { target: BlockNumber, reason: String },
    /// Finalize a block (can't be reorged anymore)
    Finalize { block_number: BlockNumber },
}
```

## Fork Detection and Validation

### Detecting Invalid Forks

```rust
/// Validates incoming blocks and detects potential forks
pub struct ForkValidator {
    /// Consensus rules
    consensus: Arc<dyn Consensus>,
    /// Maximum allowed reorg depth
    max_reorg_depth: u64,
}

impl ForkValidator {
    /// Validate a potential fork
    pub fn validate_fork(
        &self,
        current_chain: &Chain,
        fork_chain: &Chain,
    ) -> Result<ForkValidation, ValidationError> {
        // Check reorg depth
        let fork_point = self.find_fork_point(current_chain, fork_chain)?;
        let reorg_depth = current_chain.tip().number - fork_point;
        
        if reorg_depth > self.max_reorg_depth {
            return Err(ValidationError::ReorgTooDeep {
                depth: reorg_depth,
                max_allowed: self.max_reorg_depth,
            });
        }
        
        // Validate each block in the fork
        for window in fork_chain.blocks.windows(2) {
            let parent = &window[0];
            let child = &window[1];
            
            // Validate block header
            self.consensus.validate_header_with_parent(&child.header, &parent.header)?;
            
            // Validate block body
            self.consensus.validate_block_pre_execution(&child)?;
        }
        
        // Check if fork has enough weight to be canonical
        let weight_valid = match self.consensus.fork_choice_rule() {
            ForkChoiceRule::HeaviestChain => {
                fork_chain.total_difficulty > current_chain.total_difficulty
            }
            ForkChoiceRule::LongestChain => {
                fork_chain.blocks.len() > current_chain.blocks.len()
            }
            _ => true, // PoS validation is more complex
        };
        
        Ok(ForkValidation {
            is_valid: true,
            should_reorg: weight_valid,
            fork_point,
            reorg_depth,
        })
    }
}

#[derive(Debug)]
pub struct ForkValidation {
    pub is_valid: bool,
    pub should_reorg: bool,
    pub fork_point: BlockNumber,
    pub reorg_depth: u64,
}
```

## Assignments

### Assignment 1: Simple Fork Choice Implementation

Create a basic fork choice mechanism:

```rust
use std::collections::HashMap;
use alloy_primitives::{BlockHash, BlockNumber, U256};

#[derive(Debug, Clone)]
pub struct SimpleBlock {
    pub number: BlockNumber,
    pub hash: BlockHash,
    pub parent_hash: BlockHash,
    pub total_difficulty: U256,
    pub timestamp: u64,
}

pub struct SimpleForkChoice {
    /// All known blocks
    blocks: HashMap<BlockHash, SimpleBlock>,
    /// Current canonical head
    canonical_head: Option<BlockHash>,
}

impl SimpleForkChoice {
    pub fn new() -> Self {
        Self {
            blocks: HashMap::new(),
            canonical_head: None,
        }
    }
    
    /// Add a new block and potentially update canonical head
    pub fn add_block(&mut self, block: SimpleBlock) -> Result<bool, ForkChoiceError> {
        let block_hash = block.hash;
        
        // Validate parent exists (except for genesis)
        if block.number > 0 && !self.blocks.contains_key(&block.parent_hash) {
            return Err(ForkChoiceError::MissingParent(block.parent_hash));
        }
        
        // Store the block
        self.blocks.insert(block_hash, block.clone());
        
        // Check if this should be the new canonical head
        let should_reorg = match self.canonical_head {
            None => true, // First block
            Some(current_head) => {
                let current_block = &self.blocks[&current_head];
                
                // Use total difficulty for fork choice
                if block.total_difficulty > current_block.total_difficulty {
                    true
                } else if block.total_difficulty == current_block.total_difficulty {
                    // Tie-breaker: prefer block with earlier timestamp
                    block.timestamp < current_block.timestamp
                } else {
                    false
                }
            }
        };
        
        if should_reorg {
            self.canonical_head = Some(block_hash);
        }
        
        Ok(should_reorg)
    }
    
    /// Get the canonical chain from genesis to head
    pub fn get_canonical_chain(&self) -> Result<Vec<SimpleBlock>, ForkChoiceError> {
        let head_hash = self.canonical_head
            .ok_or(ForkChoiceError::NoCanonicalHead)?;
            
        let mut chain = Vec::new();
        let mut current_hash = head_hash;
        
        // Walk back to genesis
        loop {
            let block = self.blocks.get(&current_hash)
                .ok_or(ForkChoiceError::MissingBlock(current_hash))?;
                
            chain.push(block.clone());
            
            if block.number == 0 {
                break; // Genesis reached
            }
            
            current_hash = block.parent_hash;
        }
        
        // Reverse to get genesis-to-head order
        chain.reverse();
        Ok(chain)
    }
    
    /// Find all blocks that would be orphaned by a reorg to the given block
    pub fn find_orphaned_blocks(&self, new_head: BlockHash) -> Result<Vec<SimpleBlock>, ForkChoiceError> {
        let current_chain = self.get_canonical_chain()?;
        let new_chain = self.get_chain_to_block(new_head)?;
        
        // Find fork point
        let fork_point = self.find_fork_point(&current_chain, &new_chain)?;
        
        // Blocks after fork point in current chain become orphaned
        let orphaned = current_chain.into_iter()
            .filter(|block| block.number > fork_point)
            .collect();
            
        Ok(orphaned)
    }
    
    /// Get chain from genesis to a specific block
    fn get_chain_to_block(&self, target: BlockHash) -> Result<Vec<SimpleBlock>, ForkChoiceError> {
        let mut chain = Vec::new();
        let mut current_hash = target;
        
        loop {
            let block = self.blocks.get(&current_hash)
                .ok_or(ForkChoiceError::MissingBlock(current_hash))?;
                
            chain.push(block.clone());
            
            if block.number == 0 {
                break;
            }
            
            current_hash = block.parent_hash;
        }
        
        chain.reverse();
        Ok(chain)
    }
    
    /// Find the fork point between two chains
    fn find_fork_point(
        &self,
        chain_a: &[SimpleBlock],
        chain_b: &[SimpleBlock],
    ) -> Result<BlockNumber, ForkChoiceError> {
        let mut fork_point = 0;
        
        for (block_a, block_b) in chain_a.iter().zip(chain_b.iter()) {
            if block_a.hash == block_b.hash {
                fork_point = block_a.number;
            } else {
                break;
            }
        }
        
        Ok(fork_point)
    }
}

#[derive(Debug, thiserror::Error)]
pub enum ForkChoiceError {
    #[error("Missing parent block: {0}")]
    MissingParent(BlockHash),
    #[error("Missing block: {0}")]
    MissingBlock(BlockHash),
    #[error("No canonical head set")]
    NoCanonicalHead,
}

// Usage example
fn main() -> Result<(), ForkChoiceError> {
    let mut fork_choice = SimpleForkChoice::new();
    
    // Add genesis block
    let genesis = SimpleBlock {
        number: 0,
        hash: BlockHash::from([1; 32]),
        parent_hash: BlockHash::ZERO,
        total_difficulty: U256::from(1000),
        timestamp: 1000000,
    };
    fork_choice.add_block(genesis)?;
    
    // Add block 1
    let block1 = SimpleBlock {
        number: 1,
        hash: BlockHash::from([2; 32]),
        parent_hash: BlockHash::from([1; 32]),
        total_difficulty: U256::from(2000),
        timestamp: 1000010,
    };
    fork_choice.add_block(block1)?;
    
    // Add competing block 1 with higher difficulty
    let block1_alt = SimpleBlock {
        number: 1,
        hash: BlockHash::from([3; 32]),
        parent_hash: BlockHash::from([1; 32]),
        total_difficulty: U256::from(2500),
        timestamp: 1000015,
    };
    let reorg_happened = fork_choice.add_block(block1_alt)?;
    
    println!("Reorg happened: {}", reorg_happened);
    
    let canonical_chain = fork_choice.get_canonical_chain()?;
    println!("Canonical chain length: {}", canonical_chain.len());
    
    Ok(())
}
```

### Assignment 2: Reorg Event System

Implement an event system for tracking reorgs:

```rust
use std::sync::{Arc, Mutex};
use std::collections::VecDeque;
use tokio::sync::broadcast;

#[derive(Debug, Clone)]
pub struct ReorgEvent {
    /// Blocks that were removed from canonical chain
    pub removed_blocks: Vec<BlockHash>,
    /// Blocks that were added to canonical chain
    pub added_blocks: Vec<BlockHash>,
    /// The fork point where the reorg occurred
    pub fork_point: BlockNumber,
    /// Depth of the reorg (how many blocks were rewound)
    pub depth: u64,
    /// Timestamp when reorg was detected
    pub timestamp: u64,
}

#[derive(Debug, Clone)]
pub struct BlockchainEvent {
    pub event_type: BlockchainEventType,
    pub block_hash: BlockHash,
    pub block_number: BlockNumber,
    pub timestamp: u64,
}

#[derive(Debug, Clone)]
pub enum BlockchainEventType {
    /// New block added to canonical chain
    NewBlock,
    /// Block removed from canonical chain due to reorg
    RemovedBlock,
    /// Block finalized (can't be reorged)
    Finalized,
}

pub struct ReorgTracker {
    /// Event broadcaster
    event_sender: broadcast::Sender<ReorgEvent>,
    /// Recent reorg history
    reorg_history: Arc<Mutex<VecDeque<ReorgEvent>>>,
    /// Maximum history to keep
    max_history: usize,
    /// Statistics
    stats: Arc<Mutex<ReorgStats>>,
}

#[derive(Debug, Default)]
pub struct ReorgStats {
    pub total_reorgs: u64,
    pub deepest_reorg: u64,
    pub total_blocks_reorged: u64,
    pub avg_reorg_depth: f64,
}

impl ReorgTracker {
    pub fn new(max_history: usize) -> Self {
        let (event_sender, _) = broadcast::channel(1000);
        
        Self {
            event_sender,
            reorg_history: Arc::new(Mutex::new(VecDeque::new())),
            max_history,
            stats: Arc::new(Mutex::new(ReorgStats::default())),
        }
    }
    
    /// Subscribe to reorg events
    pub fn subscribe(&self) -> broadcast::Receiver<ReorgEvent> {
        self.event_sender.subscribe()
    }
    
    /// Record a reorg event
    pub fn record_reorg(&self, event: ReorgEvent) {
        // Update statistics
        {
            let mut stats = self.stats.lock().unwrap();
            stats.total_reorgs += 1;
            stats.deepest_reorg = stats.deepest_reorg.max(event.depth);
            stats.total_blocks_reorged += event.depth;
            stats.avg_reorg_depth = stats.total_blocks_reorged as f64 / stats.total_reorgs as f64;
        }
        
        // Add to history
        {
            let mut history = self.reorg_history.lock().unwrap();
            history.push_back(event.clone());
            
            // Trim history if needed
            while history.len() > self.max_history {
                history.pop_front();
            }
        }
        
        // Broadcast event
        let _ = self.event_sender.send(event);
    }
    
    /// Get recent reorg history
    pub fn get_recent_reorgs(&self, count: usize) -> Vec<ReorgEvent> {
        let history = self.reorg_history.lock().unwrap();
        history.iter().rev().take(count).cloned().collect()
    }
    
    /// Get reorg statistics
    pub fn get_stats(&self) -> ReorgStats {
        self.stats.lock().unwrap().clone()
    }
    
    /// Check if block was recently reorged
    pub fn was_block_reorged(&self, block_hash: BlockHash, lookback_depth: usize) -> bool {
        let history = self.reorg_history.lock().unwrap();
        
        history.iter().rev().take(lookback_depth).any(|reorg| {
            reorg.removed_blocks.contains(&block_hash)
        })
    }
}

/// Enhanced blockchain tree with event tracking
pub struct EventTrackingBlockchainTree {
    /// Core blockchain tree
    tree: BlockchainTree,
    /// Reorg tracker
    reorg_tracker: ReorgTracker,
}

impl EventTrackingBlockchainTree {
    pub fn new(tree: BlockchainTree) -> Self {
        Self {
            tree,
            reorg_tracker: ReorgTracker::new(100), // Keep last 100 reorgs
        }
    }
    
    /// Subscribe to reorg events
    pub fn subscribe_to_reorgs(&self) -> broadcast::Receiver<ReorgEvent> {
        self.reorg_tracker.subscribe()
    }
    
    /// Insert block with event tracking
    pub async fn insert_block_with_events(
        &mut self,
        block: SealedBlock,
        execution_outcome: ExecutionOutcome,
    ) -> Result<InsertResult, BlockchainTreeError> {
        let result = self.tree.insert_block(block.clone(), execution_outcome).await?;
        
        match &result {
            InsertResult::Canonical => {
                // New canonical block - no reorg
                self.emit_block_event(BlockchainEventType::NewBlock, &block);
            }
            InsertResult::Reorg { removed_blocks, added_blocks, fork_point } => {
                // Reorg occurred
                let reorg_event = ReorgEvent {
                    removed_blocks: removed_blocks.iter().map(|b| b.hash()).collect(),
                    added_blocks: added_blocks.iter().map(|b| b.hash()).collect(),
                    fork_point: *fork_point,
                    depth: removed_blocks.len() as u64,
                    timestamp: std::time::SystemTime::now()
                        .duration_since(std::time::UNIX_EPOCH)
                        .unwrap()
                        .as_secs(),
                };
                
                self.reorg_tracker.record_reorg(reorg_event);
                
                // Emit events for removed blocks
                for removed_block in removed_blocks {
                    self.emit_block_event(BlockchainEventType::RemovedBlock, removed_block);
                }
                
                // Emit events for added blocks
                for added_block in added_blocks {
                    self.emit_block_event(BlockchainEventType::NewBlock, added_block);
                }
            }
            InsertResult::SideChain => {
                // Block added to side chain - no canonical change
            }
        }
        
        Ok(result)
    }
    
    fn emit_block_event(&self, event_type: BlockchainEventType, block: &SealedBlock) {
        let event = BlockchainEvent {
            event_type,
            block_hash: block.hash(),
            block_number: block.number,
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs(),
        };
        
        // In a real implementation, you'd broadcast these events too
        println!("Blockchain event: {:?}", event);
    }
    
    /// Get comprehensive reorg analysis
    pub fn analyze_reorg_patterns(&self) -> ReorgAnalysis {
        let stats = self.reorg_tracker.get_stats();
        let recent_reorgs = self.reorg_tracker.get_recent_reorgs(10);
        
        let mut depth_distribution = std::collections::HashMap::new();
        for reorg in &recent_reorgs {
            *depth_distribution.entry(reorg.depth).or_insert(0) += 1;
        }
        
        ReorgAnalysis {
            total_reorgs: stats.total_reorgs,
            average_depth: stats.avg_reorg_depth,
            deepest_reorg: stats.deepest_reorg,
            recent_reorg_count: recent_reorgs.len(),
            depth_distribution,
        }
    }
}

#[derive(Debug)]
pub struct ReorgAnalysis {
    pub total_reorgs: u64,
    pub average_depth: f64,
    pub deepest_reorg: u64,
    pub recent_reorg_count: usize,
    pub depth_distribution: std::collections::HashMap<u64, usize>,
}

// Usage example
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let tree = BlockchainTree::new(/* config */);
    let mut event_tree = EventTrackingBlockchainTree::new(tree);
    
    // Subscribe to reorg events
    let mut reorg_receiver = event_tree.subscribe_to_reorgs();
    
    // Spawn task to handle reorg events
    tokio::spawn(async move {
        while let Ok(reorg_event) = reorg_receiver.recv().await {
            println!("Reorg detected!");
            println!("  Depth: {}", reorg_event.depth);
            println!("  Fork point: {}", reorg_event.fork_point);
            println!("  Removed blocks: {}", reorg_event.removed_blocks.len());
            println!("  Added blocks: {}", reorg_event.added_blocks.len());
        }
    });
    
    // Simulate adding blocks...
    // let block = create_test_block();
    // event_tree.insert_block_with_events(block, ExecutionOutcome::default()).await?;
    
    // Analyze reorg patterns
    let analysis = event_tree.analyze_reorg_patterns();
    println!("Reorg analysis: {:?}", analysis);
    
    Ok(())
}
```

### Assignment 3: Finality Tracker

Implement a system to track block finality:

```rust
use std::collections::{HashMap, BTreeMap};
use std::sync::Arc;
use tokio::sync::RwLock;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum FinalityStatus {
    /// Block is not finalized and can be reorged
    Pending,
    /// Block is safe (has confirmations but not finalized)
    Safe { confirmations: u64 },
    /// Block is finalized and cannot be reorged
    Finalized,
}

#[derive(Debug, Clone)]
pub struct FinalityInfo {
    pub status: FinalityStatus,
    pub confirmations: u64,
    pub finalized_at: Option<u64>, // timestamp
}

pub struct FinalityTracker {
    /// Current finalized block
    finalized_block: Arc<RwLock<Option<BlockNumber>>>,
    /// Block finality information
    block_finality: Arc<RwLock<BTreeMap<BlockNumber, FinalityInfo>>>,
    /// Configuration
    config: FinalityConfig,
}

#[derive(Debug, Clone)]
pub struct FinalityConfig {
    /// Number of confirmations needed for "safe" status
    pub safe_confirmations: u64,
    /// Number of confirmations needed for finalization (if not using PoS finality)
    pub finality_confirmations: u64,
    /// Whether to use beacon chain finality
    pub use_pos_finality: bool,
}

impl Default for FinalityConfig {
    fn default() -> Self {
        Self {
            safe_confirmations: 6,      // 6 blocks for "safe"
            finality_confirmations: 32, // 32 blocks for finalized (if no PoS)
            use_pos_finality: true,     // Use beacon chain finality
        }
    }
}

impl FinalityTracker {
    pub fn new(config: FinalityConfig) -> Self {
        Self {
            finalized_block: Arc::new(RwLock::new(None)),
            block_finality: Arc::new(RwLock::new(BTreeMap::new())),
            config,
        }
    }
    
    /// Update finality information when a new block is added
    pub async fn update_on_new_block(
        &self,
        new_block: BlockNumber,
        current_head: BlockNumber,
    ) -> Result<Vec<FinalityUpdate>, FinalityError> {
        let mut updates = Vec::new();
        let mut finality_map = self.block_finality.write().await;
        
        // Update confirmations for all pending blocks
        for (&block_num, finality_info) in finality_map.iter_mut() {
            if block_num <= current_head && finality_info.status != FinalityStatus::Finalized {
                let confirmations = current_head.saturating_sub(block_num);
                
                let old_status = finality_info.status;
                let new_status = self.calculate_finality_status(confirmations).await;
                
                finality_info.confirmations = confirmations;
                
                if old_status != new_status {
                    finality_info.status = new_status;
                    
                    if new_status == FinalityStatus::Finalized {
                        finality_info.finalized_at = Some(
                            std::time::SystemTime::now()
                                .duration_since(std::time::UNIX_EPOCH)
                                .unwrap()
                                .as_secs(),
                        );
                    }
                    
                    updates.push(FinalityUpdate {
                        block_number: block_num,
                        old_status,
                        new_status,
                    });
                }
            }
        }
        
        // Add new block as pending
        finality_map.insert(new_block, FinalityInfo {
            status: FinalityStatus::Pending,
            confirmations: 0,
            finalized_at: None,
        });
        
        Ok(updates)
    }
    
    /// Mark a block as finalized by beacon chain
    pub async fn finalize_block(&self, block_number: BlockNumber) -> Result<(), FinalityError> {
        let mut finalized_block = self.finalized_block.write().await;
        let mut finality_map = self.block_finality.write().await;
        
        // Update finalized block
        *finalized_block = Some(block_number);
        
        // Mark all blocks up to finalized block as finalized
        for (&block_num, finality_info) in finality_map.iter_mut() {
            if block_num <= block_number && finality_info.status != FinalityStatus::Finalized {
                finality_info.status = FinalityStatus::Finalized;
                finality_info.finalized_at = Some(
                    std::time::SystemTime::now()
                        .duration_since(std::time::UNIX_EPOCH)
                        .unwrap()
                        .as_secs(),
                );
            }
        }
        
        Ok(())
    }
    
    /// Handle reorg - update finality status for affected blocks
    pub async fn handle_reorg(
        &self,
        fork_point: BlockNumber,
        removed_blocks: &[BlockNumber],
        added_blocks: &[BlockNumber],
    ) -> Result<(), FinalityError> {
        let mut finality_map = self.block_finality.write().await;
        
        // Remove finality info for removed blocks
        for &block_num in removed_blocks {
            finality_map.remove(&block_num);
        }
        
        // Add finality info for added blocks
        for &block_num in added_blocks {
            finality_map.insert(block_num, FinalityInfo {
                status: FinalityStatus::Pending,
                confirmations: 0,
                finalized_at: None,
            });
        }
        
        // Reset finalized block if it was reorged
        let finalized_block = self.finalized_block.read().await;
        if let Some(finalized) = *finalized_block {
            if finalized > fork_point {
                drop(finalized_block);
                *self.finalized_block.write().await = Some(fork_point);
            }
        }
        
        Ok(())
    }
    
    /// Get finality status for a block
    pub async fn get_finality_status(&self, block_number: BlockNumber) -> Option<FinalityStatus> {
        let finality_map = self.block_finality.read().await;
        finality_map.get(&block_number).map(|info| info.status)
    }
    
    /// Get the latest finalized block
    pub async fn get_finalized_block(&self) -> Option<BlockNumber> {
        *self.finalized_block.read().await
    }
    
    /// Get all blocks with their finality status
    pub async fn get_finality_map(&self) -> BTreeMap<BlockNumber, FinalityInfo> {
        self.block_finality.read().await.clone()
    }
    
    /// Calculate finality status based on confirmations
    async fn calculate_finality_status(&self, confirmations: u64) -> FinalityStatus {
        if self.config.use_pos_finality {
            // With PoS, finality comes from beacon chain, not confirmations
            if confirmations >= self.config.safe_confirmations {
                FinalityStatus::Safe { confirmations }
            } else {
                FinalityStatus::Pending
            }
        } else {
            // With PoW-style finality based on confirmations
            if confirmations >= self.config.finality_confirmations {
                FinalityStatus::Finalized
            } else if confirmations >= self.config.safe_confirmations {
                FinalityStatus::Safe { confirmations }
            } else {
                FinalityStatus::Pending
            }
        }
    }
    
    /// Get finality statistics
    pub async fn get_finality_stats(&self) -> FinalityStats {
        let finality_map = self.block_finality.read().await;
        let finalized_block = *self.finalized_block.read().await;
        
        let total_blocks = finality_map.len();
        let mut pending_count = 0;
        let mut safe_count = 0;
        let mut finalized_count = 0;
        
        for info in finality_map.values() {
            match info.status {
                FinalityStatus::Pending => pending_count += 1,
                FinalityStatus::Safe { .. } => safe_count += 1,
                FinalityStatus::Finalized => finalized_count += 1,
            }
        }
        
        FinalityStats {
            total_blocks,
            pending_count,
            safe_count,
            finalized_count,
            latest_finalized: finalized_block,
        }
    }
}

#[derive(Debug, Clone)]
pub struct FinalityUpdate {
    pub block_number: BlockNumber,
    pub old_status: FinalityStatus,
    pub new_status: FinalityStatus,
}

#[derive(Debug)]
pub struct FinalityStats {
    pub total_blocks: usize,
    pub pending_count: usize,
    pub safe_count: usize,
    pub finalized_count: usize,
    pub latest_finalized: Option<BlockNumber>,
}

#[derive(Debug, thiserror::Error)]
pub enum FinalityError {
    #[error("Invalid block number")]
    InvalidBlock,
    #[error("Block already finalized")]
    AlreadyFinalized,
}

// Usage example with integration
pub struct EnhancedBlockchainTree {
    tree: BlockchainTree,
    finality_tracker: FinalityTracker,
}

impl EnhancedBlockchainTree {
    pub fn new(tree: BlockchainTree, finality_config: FinalityConfig) -> Self {
        Self {
            tree,
            finality_tracker: FinalityTracker::new(finality_config),
        }
    }
    
    /// Insert block and update finality
    pub async fn insert_block(
        &mut self,
        block: SealedBlock,
        execution_outcome: ExecutionOutcome,
    ) -> Result<InsertResultWithFinality, BlockchainTreeError> {
        let result = self.tree.insert_block(block.clone(), execution_outcome).await?;
        
        // Update finality tracking
        let finality_updates = self.finality_tracker
            .update_on_new_block(block.number, self.tree.canonical_tip().number)
            .await
            .unwrap_or_default();
        
        // Handle reorgs in finality tracker
        if let InsertResult::Reorg { removed_blocks, fork_point, .. } = &result {
            let removed_numbers: Vec<_> = removed_blocks.iter().map(|b| b.number).collect();
            let added_numbers = vec![block.number]; // Simplified
            
            self.finality_tracker
                .handle_reorg(*fork_point, &removed_numbers, &added_numbers)
                .await
                .unwrap();
        }
        
        Ok(InsertResultWithFinality {
            tree_result: result,
            finality_updates,
        })
    }
    
    /// Check if a block is safe to rely on
    pub async fn is_block_safe(&self, block_number: BlockNumber) -> bool {
        match self.finality_tracker.get_finality_status(block_number).await {
            Some(FinalityStatus::Safe { .. }) | Some(FinalityStatus::Finalized) => true,
            _ => false,
        }
    }
    
    /// Check if a block is finalized
    pub async fn is_block_finalized(&self, block_number: BlockNumber) -> bool {
        matches!(
            self.finality_tracker.get_finality_status(block_number).await,
            Some(FinalityStatus::Finalized)
        )
    }
}

#[derive(Debug)]
pub struct InsertResultWithFinality {
    pub tree_result: InsertResult,
    pub finality_updates: Vec<FinalityUpdate>,
}

// Example usage
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let config = FinalityConfig::default();
    let tree = BlockchainTree::new(/* config */);
    let mut enhanced_tree = EnhancedBlockchainTree::new(tree, config);
    
    // Simulate adding blocks and checking finality
    // let block = create_test_block(100);
    // let result = enhanced_tree.insert_block(block, ExecutionOutcome::default()).await?;
    
    // Check finality
    // let is_safe = enhanced_tree.is_block_safe(95).await;
    // let is_finalized = enhanced_tree.is_block_finalized(90).await;
    
    // Get finality statistics
    let stats = enhanced_tree.finality_tracker.get_finality_stats().await;
    println!("Finality stats: {:?}", stats);
    
    Ok(())
}
```

## Questions to Ponder - Detailed Answers

### 1. How does Reth handle deep reorganizations efficiently?

**Answer**: Reth handles deep reorganizations efficiently through several mechanisms:

1. **Staged Unwinding**: The pipeline unwinds stages in reverse order, ensuring that dependencies are respected. Each stage only unwinds what it needs to, minimizing work.

2. **Incremental Processing**: Rather than reprocessing everything from genesis, Reth only processes blocks from the fork point forward. The blockchain tree maintains multiple chain tips to avoid redundant work.

3. **State Snapshots**: Reth can maintain state snapshots at regular intervals, allowing it to quickly restore state to a known good point without replaying all transactions.

4. **Parallel Validation**: When validating a potential fork, multiple chains can be validated in parallel before deciding which should become canonical.

5. **ETL for Large Reorgs**: For extremely deep reorgs, Reth uses Extract-Transform-Load (ETL) processes to handle large amounts of data that don't fit in memory.

### 2. What are the trade-offs between different fork choice rules?

**Answer**: Different fork choice rules have distinct trade-offs:

**Longest Chain (Most Blocks)**:
- Pros: Simple to implement, resistant to grinding attacks
- Cons: Vulnerable to selfish mining, ignores work difficulty

**Heaviest Chain (Total Difficulty)**:
- Pros: Represents most computational work, standard for PoW
- Cons: Vulnerable to difficulty manipulation, complex in multi-chain scenarios

**GHOST (Greedy Heaviest Observed Subtree)**:
- Pros: More responsive to network conditions, includes uncle blocks
- Cons: More complex to implement and verify

**Proof of Stake Finality**:
- Pros: Cryptoeconomic finality, energy efficient, fast finalization
- Cons: Requires validator set management, slashing conditions, more complex

**Hybrid Approaches**:
- Pros: Combines benefits of multiple rules
- Cons: Increased complexity, potential edge cases

### 3. How does finality work in a Proof of Stake context?

**Answer**: PoS finality works fundamentally differently from PoW:

1. **Epoch-Based Finalization**: Validators vote on checkpoints at regular intervals (epochs). A checkpoint becomes finalized when it receives votes from 2/3 of validators.

2. **Justification and Finalization**: Blocks go through a two-step process:
   - Justification: Checkpoint receives 2/3 votes
   - Finalization: Next checkpoint is justified while previous is already justified

3. **Slashing Conditions**: Validators face economic penalties for:
   - Double voting (voting for conflicting blocks)
   - Surround voting (voting that contradicts finality)

4. **Reorg Protection**: Once finalized, blocks cannot be reorged without destroying at least 1/3 of the total stake (very expensive).

5. **Safe Head vs Finalized Head**: 
   - Safe head: Latest block that validators consider safe
   - Finalized head: Block that cannot be reverted without massive economic loss

6. **Integration with Execution**: The beacon chain provides finality signals to the execution layer through the Engine API, ensuring coordination between consensus and execution.

This creates much stronger finality guarantees than PoW systems while enabling faster confirmation times.