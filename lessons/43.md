# Lesson 43: The Staged Sync Pipeline

*"The first principle is that you must not fool yourself and you are the easiest person to fool." - Richard Feynman*

## Files with Inline Comments for This Lesson
- `crates/stages/api/src/pipeline/mod.rs` - Pipeline orchestration
- `crates/stages/api/src/stage.rs` - Stage interface and execution
- `crates/stages/api/src/pipeline/ctrl.rs` - Pipeline control flow
- `crates/stages/stages/src/sets.rs` - Default stage configuration
- `crates/stages/api/src/pipeline/progress.rs` - Progress tracking

## What is Staged Sync?

Think of traditional sync like a single person building a car: they mine the metal, forge the parts, assemble the engine, paint the body, and install the interior - all for one car before starting the next. Staged sync is like a modern assembly line: one team mines metal for 1000 cars, another team forges all the parts, another assembles all the engines, etc.

**Why stage the work?** Specialization leads to expertise and efficiency. A worker who only downloads headers becomes incredibly good at it - they know which peers are fastest, how to batch requests optimally, and how to detect bad data quickly. A worker who only validates blocks can use specialized algorithms and optimizations.

**The batching advantage:** Instead of "download header → download body → execute transactions → update trie" for each block, we do "download 10,000 headers → download 10,000 bodies → execute 10,000 blocks → update trie once." This reduces context switching and enables better optimizations.

**Think of it like a pipeline:** While one stage processes blocks 1000-2000, another stage can simultaneously process blocks 2000-3000. This parallelism across stages is different from parallelism within a stage.

```
Traditional vs Staged Sync:
┌─────────────────────────────────────────────────┐
│           Traditional Sync (Slow)               │
│  For each block:                                │
│  1. Download header                             │
│  2. Download body                               │
│  3. Execute transactions                        │
│  4. Update state                                │
│  5. Calculate roots                             │
│  Problem: Can't optimize each step separately!  │
└─────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────┐
│            Staged Sync (Fast)                   │
│  Stage 1: Download all headers                  │
│  Stage 2: Download all bodies                   │
│  Stage 3: Execute all transactions             │
│  Stage 4: Calculate all state roots            │
│  Benefit: Each stage can be optimized!         │
└─────────────────────────────────────────────────┘
```

## The Pipeline Architecture

The pipeline orchestrates stages, handles errors, and tracks progress:

```rust
/// Pipeline orchestration
/// Located in: crates/stages/api/src/pipeline/mod.rs

use crate::{Stage, StageId, StageCheckpoint, PipelineError};
use std::collections::VecDeque;

/// LESSON 43: Pipeline Orchestrator
/// The pipeline runs stages in sequence, managing:
/// 1. Stage execution order
/// 2. Checkpoint persistence
/// 3. Error handling and unwinding
/// 4. Progress tracking
pub struct Pipeline<N: ProviderNodeTypes> {
    /// Provider for database access
    provider_factory: ProviderFactory<N>,
    /// Ordered list of stages to execute
    stages: Vec<BoxedStage<DB>>,
    /// Maximum block to sync to
    max_block: Option<BlockNumber>,
    /// Progress tracker
    progress: PipelineProgress,
    /// Event sender for monitoring
    event_sender: EventSender<PipelineEvent>,
    /// Whether to fail on unwind (for trusted sources)
    fail_on_unwind: bool,
}

impl<N: ProviderNodeTypes> Pipeline<N> {
    /// Run the pipeline to completion
    /// LESSON 43: Main Execution Loop
    /// The pipeline runs stages repeatedly until:
    /// 1. All stages reach the target
    /// 2. An unrecoverable error occurs
    /// 3. Shutdown is requested
    pub async fn run(&mut self) -> Result<ControlFlow, PipelineError> {
        loop {
            // Check if we should stop
            if let Some(max_block) = self.max_block {
                if self.progress.block_number >= max_block {
                    return Ok(ControlFlow::Finished);
                }
            }
            
            // Run one cycle of all stages
            match self.run_once().await {
                Ok(ControlFlow::Continue) => continue,
                Ok(other) => return Ok(other),
                Err(err) => {
                    // Handle error - might trigger unwind
                    self.handle_error(err)?;
                }
            }
        }
    }
    
    /// Run all stages once
    async fn run_once(&mut self) -> Result<ControlFlow, PipelineError> {
        let mut made_progress = false;
        
        // LESSON 43: Stage Execution
        // Execute each stage in order
        for (stage_index, stage) in self.stages.iter_mut().enumerate() {
            let stage_id = stage.id();
            
            // Load checkpoint for this stage
            let checkpoint = self.load_checkpoint(stage_id)?;
            
            // Prepare execution input
            let input = ExecInput {
                target: self.max_block,
                checkpoint,
            };
            
            // Check if stage needs to run
            if input.target_reached() {
                trace!(target: "pipeline", stage = %stage_id, "Stage already at target");
                continue;
            }
            
            // Execute the stage
            info!(target: "pipeline", stage = %stage_id, "Executing stage");
            let output = self.execute_stage(stage, input).await?;
            
            // Save checkpoint
            if output.done {
                self.save_checkpoint(stage_id, output.checkpoint)?;
                made_progress = true;
            }
            
            // Check control flow
            match output.control_flow {
                ControlFlow::Continue => {}
                other => return Ok(other),
            }
        }
        
        if !made_progress {
            // No stage made progress - we might be done
            return Ok(ControlFlow::Finished);
        }
        
        Ok(ControlFlow::Continue)
    }
    
    /// Execute a single stage with error handling
    async fn execute_stage(
        &mut self,
        stage: &mut BoxedStage<DB>,
        input: ExecInput,
    ) -> Result<ExecOutput, PipelineError> {
        // Emit start event
        self.event_sender.send(PipelineEvent::StageStarted {
            stage_id: stage.id(),
            checkpoint: input.checkpoint,
        });
        
        let start = Instant::now();
        
        // LESSON 43: Stage Execution with Provider
        // Each stage gets a read-write database transaction
        let provider = self.provider_factory.database_provider_rw()?;
        
        let result = stage.execute(&provider, input).await;
        
        match result {
            Ok(output) => {
                // Commit changes
                provider.commit()?;
                
                // Emit progress
                self.event_sender.send(PipelineEvent::StageProgress {
                    stage_id: stage.id(),
                    checkpoint: output.checkpoint,
                    duration: start.elapsed(),
                });
                
                Ok(output)
            }
            Err(err) => {
                // Rollback changes
                drop(provider);
                
                // Emit error
                self.event_sender.send(PipelineEvent::StageError {
                    stage_id: stage.id(),
                    error: err.clone(),
                });
                
                Err(err.into())
            }
        }
    }
    
    /// Handle stage error - might trigger unwind
    /// LESSON 43: Error Recovery
    /// When a stage fails, we might need to unwind (rollback)
    /// previous stages to maintain consistency
    fn handle_error(&mut self, error: PipelineError) -> Result<(), PipelineError> {
        match error {
            PipelineError::Stage(StageError::Validation { block }) => {
                // Validation error - need to unwind
                warn!(target: "pipeline", ?block, "Validation error, unwinding");
                self.unwind_to(block.saturating_sub(1))?;
                
                if self.fail_on_unwind {
                    return Err(error);
                }
                
                Ok(())
            }
            PipelineError::Stage(StageError::DetachedHead { local, header }) => {
                // Chain reorg detected
                warn!(target: "pipeline", ?local, ?header, "Detached head, unwinding");
                
                // Unwind to common ancestor
                let target = self.find_unwind_target(local, header)?;
                self.unwind_to(target)?;
                
                Ok(())
            }
            other => Err(other),
        }
    }
}
```

## Stage Interface

Each stage implements a common interface:

```rust
/// Stage execution interface
/// Located in: crates/stages/api/src/stage.rs

/// LESSON 43: Stage Trait
/// Every stage must implement this trait to participate in the pipeline
#[async_trait]
pub trait Stage<DB: Database>: Send + Sync {
    /// Unique identifier for this stage
    fn id(&self) -> StageId;
    
    /// Execute the stage forward
    /// LESSON 43: Forward Execution
    /// Process blocks from checkpoint to target
    async fn execute(
        &mut self,
        provider: &DB,
        input: ExecInput,
    ) -> Result<ExecOutput, StageError>;
    
    /// Unwind the stage backwards
    /// LESSON 43: Unwinding
    /// Rollback changes from current state to target block
    async fn unwind(
        &mut self,
        provider: &DB,
        input: UnwindInput,
    ) -> Result<UnwindOutput, StageError>;
}

/// Input for stage execution
#[derive(Debug, Clone, Copy)]
pub struct ExecInput {
    /// Target block to sync to
    pub target: Option<BlockNumber>,
    /// Last checkpoint for this stage
    pub checkpoint: Option<StageCheckpoint>,
}

impl ExecInput {
    /// Get the next block to process
    pub fn next_block(&self) -> BlockNumber {
        self.checkpoint
            .map(|c| c.block_number + 1)
            .unwrap_or(0)
    }
    
    /// Check if we've reached the target
    pub fn target_reached(&self) -> bool {
        if let Some(target) = self.target {
            self.checkpoint
                .map(|c| c.block_number >= target)
                .unwrap_or(false)
        } else {
            false
        }
    }
    
    /// Get next block range to process
    /// LESSON 43: Batch Processing
    /// Stages process blocks in batches for efficiency
    pub fn next_block_range_with_threshold(
        &self,
        threshold: u64,
    ) -> (RangeInclusive<BlockNumber>, bool) {
        let start = self.next_block();
        let target = self.target.unwrap_or(u64::MAX);
        
        // Don't exceed threshold
        let end = min(target, start.saturating_add(threshold));
        
        let is_final = end == target;
        (start..=end, is_final)
    }
}

/// Output from stage execution
#[derive(Debug)]
pub struct ExecOutput {
    /// Updated checkpoint
    pub checkpoint: StageCheckpoint,
    /// Whether stage reached target
    pub done: bool,
    /// Control flow hint
    pub control_flow: ControlFlow,
}

/// Stage checkpoint - persisted progress
#[derive(Debug, Clone, Copy)]
pub struct StageCheckpoint {
    /// Last processed block
    pub block_number: BlockNumber,
    /// Stage-specific progress data
    pub stage_checkpoint: Option<StageSpecificCheckpoint>,
}
```

## Pipeline Control Flow

Control flow determines pipeline behavior:

```rust
/// Pipeline control flow
/// Located in: crates/stages/api/src/pipeline/ctrl.rs

/// LESSON 43: Control Flow
/// Stages can signal how the pipeline should proceed
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum ControlFlow {
    /// Continue with next stage
    Continue,
    /// Pipeline reached target
    Finished,
    /// Graceful shutdown requested
    Shutdown,
    /// Unwind was triggered
    Unwind,
}

impl ControlFlow {
    /// Check if pipeline should continue
    pub fn should_continue(&self) -> bool {
        matches!(self, Self::Continue)
    }
    
    /// Check if this is a terminal state
    pub fn is_terminal(&self) -> bool {
        matches!(self, Self::Finished | Self::Shutdown)
    }
}
```

## Progress Tracking

The pipeline tracks detailed progress:

```rust
/// Progress tracking for pipeline
/// Located in: crates/stages/api/src/pipeline/progress.rs

/// LESSON 43: Progress Tracking
/// Track stage progress for monitoring and resumption
#[derive(Debug, Default)]
pub struct PipelineProgress {
    /// Current block number across all stages
    pub block_number: BlockNumber,
    /// Per-stage progress
    pub stages: HashMap<StageId, StageProgress>,
    /// Overall sync percentage
    pub percentage: f64,
    /// ETA estimation
    pub eta: Option<Duration>,
}

#[derive(Debug, Clone)]
pub struct StageProgress {
    /// Stage checkpoint
    pub checkpoint: StageCheckpoint,
    /// Blocks processed in this run
    pub processed: u64,
    /// Processing rate (blocks/sec)
    pub rate: f64,
    /// Time spent in stage
    pub elapsed: Duration,
}

impl PipelineProgress {
    /// Update progress for a stage
    pub fn update_stage(
        &mut self,
        stage_id: StageId,
        checkpoint: StageCheckpoint,
        elapsed: Duration,
    ) {
        let stage_progress = self.stages.entry(stage_id).or_default();
        
        // Calculate rate
        let processed = checkpoint.block_number
            .saturating_sub(stage_progress.checkpoint.block_number);
        let rate = processed as f64 / elapsed.as_secs_f64();
        
        stage_progress.checkpoint = checkpoint;
        stage_progress.processed += processed;
        stage_progress.rate = rate;
        stage_progress.elapsed += elapsed;
        
        // Update overall progress
        self.update_overall();
    }
    
    fn update_overall(&mut self) {
        // Find minimum block number across stages
        self.block_number = self.stages
            .values()
            .map(|s| s.checkpoint.block_number)
            .min()
            .unwrap_or(0);
    }
    
    /// Estimate time to completion
    pub fn estimate_eta(&self, target: BlockNumber) -> Option<Duration> {
        let remaining = target.saturating_sub(self.block_number);
        
        // Use average rate across stages
        let avg_rate = self.stages
            .values()
            .map(|s| s.rate)
            .sum::<f64>() / self.stages.len() as f64;
        
        if avg_rate > 0.0 {
            let secs = remaining as f64 / avg_rate;
            Some(Duration::from_secs_f64(secs))
        } else {
            None
        }
    }
}
```

## Unwinding

When things go wrong, stages unwind in reverse:

```rust
/// Unwind support for pipeline
impl<N: ProviderNodeTypes> Pipeline<N> {
    /// Unwind stages to target block
    /// LESSON 43: Unwinding Process
    /// Unwind stages in reverse order to maintain consistency
    pub fn unwind_to(&mut self, target: BlockNumber) -> Result<(), PipelineError> {
        info!(target: "pipeline", ?target, "Starting unwind");
        
        // Unwind stages in reverse order
        for stage in self.stages.iter_mut().rev() {
            let checkpoint = self.load_checkpoint(stage.id())?;
            
            if let Some(checkpoint) = checkpoint {
                if checkpoint.block_number <= target {
                    // Stage already below target
                    continue;
                }
                
                let input = UnwindInput {
                    checkpoint,
                    unwind_to: target,
                };
                
                info!(
                    target: "pipeline",
                    stage = %stage.id(),
                    from = checkpoint.block_number,
                    to = target,
                    "Unwinding stage"
                );
                
                // Execute unwind
                let provider = self.provider_factory.database_provider_rw()?;
                stage.unwind(&provider, input)?;
                provider.commit()?;
                
                // Update checkpoint
                self.save_checkpoint(stage.id(), StageCheckpoint {
                    block_number: target,
                    stage_checkpoint: None,
                })?;
            }
        }
        
        // Update progress
        self.progress.block_number = target;
        
        Ok(())
    }
}

/// Input for stage unwinding
#[derive(Debug)]
pub struct UnwindInput {
    /// Current checkpoint
    pub checkpoint: StageCheckpoint,
    /// Target block to unwind to
    pub unwind_to: BlockNumber,
}

/// Output from unwinding
#[derive(Debug)]
pub struct UnwindOutput {
    /// New checkpoint after unwind
    pub checkpoint: StageCheckpoint,
}
```

## Assignments

### Assignment 1: Simple Pipeline (Easy)
Create a basic pipeline that runs two stages sequentially.

**Your Task**: Implement a `SimplePipeline` with a download stage and a process stage.

### Assignment 2: Checkpoint Recovery (Medium)
Build a pipeline that can resume from checkpoints after interruption.

**Your Task**: Create a `ResumablePipeline` that persists and recovers stage progress.

### Assignment 3: Adaptive Pipeline (Hard)
Design a pipeline that adjusts batch sizes based on performance.

**Your Task**: Implement an `AdaptivePipeline` that monitors stage performance and optimizes batch sizes.

## Assignment Answers

### Answer 1: Simple Pipeline

```rust
use std::sync::Arc;
use async_trait::async_trait;

/// Simple two-stage pipeline
pub struct SimplePipeline {
    stages: Vec<Box<dyn SimpleStage>>,
    current_block: u64,
    target_block: u64,
}

#[async_trait]
trait SimpleStage: Send + Sync {
    fn name(&self) -> &str;
    async fn execute(&mut self, from: u64, to: u64) -> Result<(), StageError>;
}

/// Download stage - fetches block data
struct DownloadStage {
    client: Arc<dyn BlockClient>,
    buffer: Vec<Block>,
}

#[async_trait]
impl SimpleStage for DownloadStage {
    fn name(&self) -> &str {
        "Download"
    }
    
    async fn execute(&mut self, from: u64, to: u64) -> Result<(), StageError> {
        println!("Downloading blocks {} to {}", from, to);
        
        self.buffer.clear();
        for block_num in from..=to {
            let block = self.client.get_block(block_num).await
                .map_err(|e| StageError::Download(e))?;
            self.buffer.push(block);
        }
        
        println!("Downloaded {} blocks", self.buffer.len());
        Ok(())
    }
}

/// Process stage - processes downloaded blocks
struct ProcessStage {
    processor: Arc<dyn BlockProcessor>,
}

#[async_trait]
impl SimpleStage for ProcessStage {
    fn name(&self) -> &str {
        "Process"
    }
    
    async fn execute(&mut self, from: u64, to: u64) -> Result<(), StageError> {
        println!("Processing blocks {} to {}", from, to);
        
        for block_num in from..=to {
            // In real implementation, would get block from previous stage
            self.processor.process_block(block_num).await
                .map_err(|e| StageError::Process(e))?;
        }
        
        println!("Processed {} blocks", to - from + 1);
        Ok(())
    }
}

impl SimplePipeline {
    pub fn new(target: u64) -> Self {
        let stages: Vec<Box<dyn SimpleStage>> = vec![
            Box::new(DownloadStage {
                client: Arc::new(MockBlockClient),
                buffer: Vec::new(),
            }),
            Box::new(ProcessStage {
                processor: Arc::new(MockBlockProcessor),
            }),
        ];
        
        Self {
            stages,
            current_block: 0,
            target_block: target,
        }
    }
    
    pub async fn run(&mut self) -> Result<(), PipelineError> {
        const BATCH_SIZE: u64 = 100;
        
        while self.current_block < self.target_block {
            let from = self.current_block + 1;
            let to = (from + BATCH_SIZE - 1).min(self.target_block);
            
            // Run each stage for this batch
            for stage in &mut self.stages {
                println!("Running stage: {}", stage.name());
                stage.execute(from, to).await?;
            }
            
            self.current_block = to;
            println!("Progress: {}/{}", self.current_block, self.target_block);
        }
        
        println!("Pipeline completed!");
        Ok(())
    }
}

#[derive(Debug)]
enum StageError {
    Download(String),
    Process(String),
}

#[derive(Debug)]
enum PipelineError {
    Stage(StageError),
}

impl From<StageError> for PipelineError {
    fn from(err: StageError) -> Self {
        PipelineError::Stage(err)
    }
}

// Mock implementations
struct MockBlockClient;
struct MockBlockProcessor;
struct Block {
    number: u64,
    data: Vec<u8>,
}

#[async_trait]
trait BlockClient: Send + Sync {
    async fn get_block(&self, number: u64) -> Result<Block, String>;
}

#[async_trait]
trait BlockProcessor: Send + Sync {
    async fn process_block(&self, number: u64) -> Result<(), String>;
}

#[async_trait]
impl BlockClient for MockBlockClient {
    async fn get_block(&self, number: u64) -> Result<Block, String> {
        Ok(Block {
            number,
            data: vec![0u8; 100],
        })
    }
}

#[async_trait]
impl BlockProcessor for MockBlockProcessor {
    async fn process_block(&self, _number: u64) -> Result<(), String> {
        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_simple_pipeline() {
        let mut pipeline = SimplePipeline::new(250);
        pipeline.run().await.unwrap();
        assert_eq!(pipeline.current_block, 250);
    }
}
```

### Answer 2: Checkpoint Recovery

```rust
use std::path::{Path, PathBuf};
use serde::{Serialize, Deserialize};

/// Pipeline with checkpoint persistence
pub struct ResumablePipeline {
    stages: Vec<Box<dyn ResumableStage>>,
    checkpoints: CheckpointManager,
    target: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct StageCheckpoint {
    stage_id: String,
    block_number: u64,
    custom_data: Option<Vec<u8>>,
    timestamp: u64,
}

/// Checkpoint manager for persistence
struct CheckpointManager {
    checkpoint_dir: PathBuf,
}

impl CheckpointManager {
    fn new<P: AsRef<Path>>(dir: P) -> Result<Self, std::io::Error> {
        let checkpoint_dir = dir.as_ref().to_path_buf();
        std::fs::create_dir_all(&checkpoint_dir)?;
        Ok(Self { checkpoint_dir })
    }
    
    fn save_checkpoint(&self, checkpoint: &StageCheckpoint) -> Result<(), std::io::Error> {
        let path = self.checkpoint_path(&checkpoint.stage_id);
        let data = serde_json::to_vec_pretty(checkpoint)?;
        std::fs::write(path, data)?;
        Ok(())
    }
    
    fn load_checkpoint(&self, stage_id: &str) -> Result<Option<StageCheckpoint>, std::io::Error> {
        let path = self.checkpoint_path(stage_id);
        if !path.exists() {
            return Ok(None);
        }
        
        let data = std::fs::read(path)?;
        let checkpoint = serde_json::from_slice(&data)?;
        Ok(Some(checkpoint))
    }
    
    fn checkpoint_path(&self, stage_id: &str) -> PathBuf {
        self.checkpoint_dir.join(format!("{}.json", stage_id))
    }
    
    fn clear_all(&self) -> Result<(), std::io::Error> {
        for entry in std::fs::read_dir(&self.checkpoint_dir)? {
            let entry = entry?;
            if entry.path().extension().and_then(|s| s.to_str()) == Some("json") {
                std::fs::remove_file(entry.path())?;
            }
        }
        Ok(())
    }
}

#[async_trait]
trait ResumableStage: Send + Sync {
    fn id(&self) -> &str;
    
    async fn execute(
        &mut self,
        from: u64,
        to: u64,
    ) -> Result<Option<Vec<u8>>, StageError>;
    
    fn restore_state(&mut self, data: Vec<u8>) -> Result<(), StageError>;
}

/// Example stage with state
struct StatefulStage {
    id: String,
    processed_count: u64,
    state_data: Vec<String>,
}

impl StatefulStage {
    fn new(id: String) -> Self {
        Self {
            id,
            processed_count: 0,
            state_data: Vec::new(),
        }
    }
}

#[async_trait]
impl ResumableStage for StatefulStage {
    fn id(&self) -> &str {
        &self.id
    }
    
    async fn execute(&mut self, from: u64, to: u64) -> Result<Option<Vec<u8>>, StageError> {
        println!("[{}] Processing blocks {} to {}", self.id, from, to);
        
        for block in from..=to {
            // Simulate processing
            self.state_data.push(format!("Processed block {}", block));
            self.processed_count += 1;
            
            // Simulate work
            tokio::time::sleep(tokio::time::Duration::from_millis(50)).await;
        }
        
        // Serialize custom state
        let state = serde_json::to_vec(&self.state_data)
            .map_err(|e| StageError::Serialization(e.to_string()))?;
        
        Ok(Some(state))
    }
    
    fn restore_state(&mut self, data: Vec<u8>) -> Result<(), StageError> {
        self.state_data = serde_json::from_slice(&data)
            .map_err(|e| StageError::Serialization(e.to_string()))?;
        self.processed_count = self.state_data.len() as u64;
        println!("[{}] Restored {} items", self.id, self.processed_count);
        Ok(())
    }
}

impl ResumablePipeline {
    pub fn new(target: u64, checkpoint_dir: &str) -> Result<Self, std::io::Error> {
        let stages: Vec<Box<dyn ResumableStage>> = vec![
            Box::new(StatefulStage::new("headers".to_string())),
            Box::new(StatefulStage::new("bodies".to_string())),
            Box::new(StatefulStage::new("execution".to_string())),
        ];
        
        let checkpoints = CheckpointManager::new(checkpoint_dir)?;
        
        Ok(Self {
            stages,
            checkpoints,
            target,
        })
    }
    
    pub async fn run(&mut self) -> Result<(), PipelineError> {
        const BATCH_SIZE: u64 = 50;
        
        // Restore checkpoints
        self.restore_checkpoints()?;
        
        // Run stages
        for stage in &mut self.stages {
            let stage_id = stage.id().to_string();
            
            // Get starting point
            let start_block = self.checkpoints
                .load_checkpoint(&stage_id)?
                .map(|c| c.block_number + 1)
                .unwrap_or(0);
            
            if start_block > self.target {
                println!("[{}] Already at target", stage_id);
                continue;
            }
            
            println!("[{}] Starting from block {}", stage_id, start_block);
            
            let mut current = start_block;
            while current <= self.target {
                let to = (current + BATCH_SIZE - 1).min(self.target);
                
                // Execute batch
                let custom_data = stage.execute(current, to).await?;
                
                // Save checkpoint
                let checkpoint = StageCheckpoint {
                    stage_id: stage_id.clone(),
                    block_number: to,
                    custom_data,
                    timestamp: std::time::SystemTime::now()
                        .duration_since(std::time::UNIX_EPOCH)
                        .unwrap()
                        .as_secs(),
                };
                
                self.checkpoints.save_checkpoint(&checkpoint)?;
                current = to + 1;
                
                println!("[{}] Checkpoint saved at block {}", stage_id, to);
            }
        }
        
        println!("Pipeline completed successfully!");
        Ok(())
    }
    
    fn restore_checkpoints(&mut self) -> Result<(), PipelineError> {
        for stage in &mut self.stages {
            if let Some(checkpoint) = self.checkpoints.load_checkpoint(stage.id())? {
                println!(
                    "[{}] Found checkpoint at block {}",
                    stage.id(),
                    checkpoint.block_number
                );
                
                if let Some(data) = checkpoint.custom_data {
                    stage.restore_state(data)?;
                }
            }
        }
        Ok(())
    }
    
    pub fn reset(&mut self) -> Result<(), PipelineError> {
        self.checkpoints.clear_all()?;
        println!("All checkpoints cleared");
        Ok(())
    }
}

#[derive(Debug)]
enum StageError {
    Serialization(String),
}

impl From<std::io::Error> for PipelineError {
    fn from(err: std::io::Error) -> Self {
        PipelineError::Io(err.to_string())
    }
}

impl From<StageError> for PipelineError {
    fn from(err: StageError) -> Self {
        PipelineError::Stage(err)
    }
}

#[derive(Debug)]
enum PipelineError {
    Stage(StageError),
    Io(String),
}
```

### Answer 3: Adaptive Pipeline

```rust
use std::time::{Duration, Instant};
use std::collections::VecDeque;

/// Pipeline that adapts batch sizes based on performance
pub struct AdaptivePipeline {
    stages: Vec<Box<dyn AdaptiveStage>>,
    optimizer: BatchOptimizer,
    target: u64,
    metrics: PipelineMetrics,
}

#[async_trait]
trait AdaptiveStage: Send + Sync {
    fn id(&self) -> &str;
    
    async fn execute_batch(
        &mut self,
        from: u64,
        to: u64,
    ) -> Result<StageMetrics, StageError>;
    
    fn suggested_batch_size(&self) -> u64;
}

/// Metrics for a stage execution
#[derive(Debug, Clone)]
struct StageMetrics {
    blocks_processed: u64,
    duration: Duration,
    memory_used: usize,
    errors: u64,
}

impl StageMetrics {
    fn throughput(&self) -> f64 {
        self.blocks_processed as f64 / self.duration.as_secs_f64()
    }
    
    fn efficiency(&self) -> f64 {
        if self.errors > 0 {
            0.0
        } else {
            self.throughput() / (self.memory_used as f64 / 1_000_000.0).max(1.0)
        }
    }
}

/// Batch size optimizer
struct BatchOptimizer {
    /// Per-stage batch configurations
    stage_configs: HashMap<String, StageConfig>,
    /// Global constraints
    max_memory: usize,
    min_batch: u64,
    max_batch: u64,
}

#[derive(Debug, Clone)]
struct StageConfig {
    /// Current batch size
    batch_size: u64,
    /// Historical performance
    history: VecDeque<BatchPerformance>,
    /// Optimization state
    state: OptimizationState,
}

#[derive(Debug, Clone)]
struct BatchPerformance {
    batch_size: u64,
    metrics: StageMetrics,
}

#[derive(Debug, Clone, Copy)]
enum OptimizationState {
    /// Exploring different batch sizes
    Exploring { direction: i64, step: u64 },
    /// Found good size, minor adjustments
    Tuning,
    /// Stable configuration
    Stable,
}

impl BatchOptimizer {
    fn new(max_memory: usize) -> Self {
        Self {
            stage_configs: HashMap::new(),
            max_memory,
            min_batch: 10,
            max_batch: 10_000,
        }
    }
    
    fn get_batch_size(&mut self, stage_id: &str) -> u64 {
        self.stage_configs
            .entry(stage_id.to_string())
            .or_insert_with(|| StageConfig {
                batch_size: 100, // Default
                history: VecDeque::with_capacity(20),
                state: OptimizationState::Exploring { direction: 1, step: 50 },
            })
            .batch_size
    }
    
    fn record_performance(
        &mut self,
        stage_id: &str,
        batch_size: u64,
        metrics: StageMetrics,
    ) {
        let config = self.stage_configs.get_mut(stage_id).unwrap();
        
        // Add to history
        config.history.push_back(BatchPerformance {
            batch_size,
            metrics: metrics.clone(),
        });
        
        if config.history.len() > 20 {
            config.history.pop_front();
        }
        
        // Optimize batch size
        self.optimize_stage(stage_id, &metrics);
    }
    
    fn optimize_stage(&mut self, stage_id: &str, latest_metrics: &StageMetrics) {
        let config = self.stage_configs.get_mut(stage_id).unwrap();
        
        match config.state {
            OptimizationState::Exploring { direction, step } => {
                // Check if we should change direction
                if latest_metrics.errors > 0 || 
                   latest_metrics.memory_used > self.max_memory {
                    // Too aggressive, reduce
                    config.batch_size = config.batch_size.saturating_sub(step * 2);
                    config.state = OptimizationState::Exploring {
                        direction: -1,
                        step: step / 2,
                    };
                } else if config.history.len() >= 3 {
                    // Check trend
                    let recent: Vec<_> = config.history.iter().rev().take(3).collect();
                    let improving = recent.windows(2).all(|w| {
                        w[0].metrics.efficiency() >= w[1].metrics.efficiency()
                    });
                    
                    if improving {
                        // Continue in same direction
                        let new_size = if direction > 0 {
                            config.batch_size + step
                        } else {
                            config.batch_size.saturating_sub(step)
                        };
                        
                        config.batch_size = new_size.clamp(self.min_batch, self.max_batch);
                    } else {
                        // Performance degraded, reverse direction
                        config.state = OptimizationState::Exploring {
                            direction: -direction,
                            step: step / 2,
                        };
                    }
                    
                    if step <= 10 {
                        config.state = OptimizationState::Tuning;
                    }
                }
            }
            OptimizationState::Tuning => {
                // Fine adjustments based on throughput variance
                if let Some(avg_throughput) = self.average_throughput(stage_id) {
                    let variance = (latest_metrics.throughput() - avg_throughput).abs() / avg_throughput;
                    
                    if variance < 0.05 {
                        // Stable performance
                        config.state = OptimizationState::Stable;
                    } else if latest_metrics.throughput() < avg_throughput * 0.9 {
                        // Performance dropped, adjust
                        config.batch_size = (config.batch_size as f64 * 0.95) as u64;
                    }
                }
            }
            OptimizationState::Stable => {
                // Monitor for significant changes
                if let Some(avg_throughput) = self.average_throughput(stage_id) {
                    let variance = (latest_metrics.throughput() - avg_throughput).abs() / avg_throughput;
                    
                    if variance > 0.2 {
                        // Significant change, re-explore
                        config.state = OptimizationState::Exploring {
                            direction: if latest_metrics.throughput() > avg_throughput { 1 } else { -1 },
                            step: 50,
                        };
                    }
                }
            }
        }
    }
    
    fn average_throughput(&self, stage_id: &str) -> Option<f64> {
        let config = self.stage_configs.get(stage_id)?;
        if config.history.is_empty() {
            return None;
        }
        
        let sum: f64 = config.history.iter()
            .map(|p| p.metrics.throughput())
            .sum();
        
        Some(sum / config.history.len() as f64)
    }
}

/// Pipeline metrics collection
#[derive(Debug, Default)]
struct PipelineMetrics {
    stage_metrics: HashMap<String, Vec<StageMetrics>>,
    total_blocks: u64,
    total_duration: Duration,
}

impl PipelineMetrics {
    fn record_stage(&mut self, stage_id: &str, metrics: StageMetrics) {
        self.stage_metrics
            .entry(stage_id.to_string())
            .or_default()
            .push(metrics);
    }
    
    fn report(&self) {
        println!("\n=== Pipeline Performance Report ===");
        println!("Total blocks: {}", self.total_blocks);
        println!("Total duration: {:?}", self.total_duration);
        println!("Overall throughput: {:.2} blocks/sec", 
                self.total_blocks as f64 / self.total_duration.as_secs_f64());
        
        println!("\nPer-stage metrics:");
        for (stage, metrics) in &self.stage_metrics {
            let avg_throughput = metrics.iter()
                .map(|m| m.throughput())
                .sum::<f64>() / metrics.len() as f64;
            
            println!("  {}: {:.2} blocks/sec", stage, avg_throughput);
        }
    }
}

/// Example adaptive stage
struct AdaptiveProcessingStage {
    id: String,
    complexity_factor: f64,
}

#[async_trait]
impl AdaptiveStage for AdaptiveProcessingStage {
    fn id(&self) -> &str {
        &self.id
    }
    
    async fn execute_batch(&mut self, from: u64, to: u64) -> Result<StageMetrics, StageError> {
        let start = Instant::now();
        let blocks = to - from + 1;
        
        // Simulate variable processing time
        let base_time = 10.0 * self.complexity_factor;
        let total_time = base_time * blocks as f64;
        tokio::time::sleep(Duration::from_millis(total_time as u64)).await;
        
        // Simulate memory usage
        let memory_used = (blocks as usize * 1024 * rand::random::<u8>() as usize)
            .clamp(1024, 10_000_000);
        
        // Random errors for testing
        let errors = if rand::random::<f64>() < 0.01 { 1 } else { 0 };
        
        Ok(StageMetrics {
            blocks_processed: blocks,
            duration: start.elapsed(),
            memory_used,
            errors,
        })
    }
    
    fn suggested_batch_size(&self) -> u64 {
        (100.0 / self.complexity_factor) as u64
    }
}

impl AdaptivePipeline {
    pub fn new(target: u64) -> Self {
        let stages: Vec<Box<dyn AdaptiveStage>> = vec![
            Box::new(AdaptiveProcessingStage {
                id: "headers".to_string(),
                complexity_factor: 0.5,
            }),
            Box::new(AdaptiveProcessingStage {
                id: "bodies".to_string(),
                complexity_factor: 1.0,
            }),
            Box::new(AdaptiveProcessingStage {
                id: "execution".to_string(),
                complexity_factor: 2.0,
            }),
        ];
        
        Self {
            stages,
            optimizer: BatchOptimizer::new(50_000_000), // 50MB limit
            target,
            metrics: PipelineMetrics::default(),
        }
    }
    
    pub async fn run(&mut self) -> Result<(), PipelineError> {
        let pipeline_start = Instant::now();
        
        for stage in &mut self.stages {
            let stage_id = stage.id().to_string();
            let mut current = 0u64;
            
            println!("\nStarting stage: {}", stage_id);
            
            while current < self.target {
                // Get optimized batch size
                let batch_size = self.optimizer.get_batch_size(&stage_id);
                let to = (current + batch_size).min(self.target);
                
                println!(
                    "[{}] Processing blocks {}-{} (batch size: {})",
                    stage_id, current, to, batch_size
                );
                
                // Execute batch
                let metrics = stage.execute_batch(current, to).await?;
                
                // Record performance
                self.optimizer.record_performance(&stage_id, batch_size, metrics.clone());
                self.metrics.record_stage(&stage_id, metrics.clone());
                
                println!(
                    "[{}] Throughput: {:.2} blocks/sec, Memory: {:.2} MB",
                    stage_id,
                    metrics.throughput(),
                    metrics.memory_used as f64 / 1_000_000.0
                );
                
                current = to;
            }
        }
        
        self.metrics.total_blocks = self.target;
        self.metrics.total_duration = pipeline_start.elapsed();
        
        // Print performance report
        self.metrics.report();
        
        Ok(())
    }
}

// Import HashMap
use std::collections::HashMap;
// Mock rand for demonstration
mod rand {
    pub fn random<T>() -> T
    where
        T: From<u8>,
    {
        T::from(128u8)
    }
}
```

## Why These Design Decisions Matter

**Checkpoint granularity:** Stages save progress frequently (every ~10,000 blocks) rather than only at completion. Why? If sync fails, you don't want to restart the entire stage. It's like saving your document every few paragraphs rather than only when finished.

**Unwinding in reverse order:** When a bad block is detected, stages unwind in reverse order. This maintains referential integrity - you can't remove transaction data before removing the block headers that reference it.

**ETL (Extract, Transform, Load) pattern:** Why not just insert data directly into the database? Because bulk operations are 10-100x faster than individual inserts. ETL collects data in memory/temp files, sorts it, then bulk-loads - like collecting all your photos before organizing them into albums.

**Stage interdependencies:** Headers must complete before Bodies can start (bodies need headers to validate against). But Execution and Merkle stages can run somewhat in parallel - showing how staged sync can still capture some parallelism.

**Common pitfalls to avoid:**
- **Memory leaks in ETL:** Always clear collectors after processing - accumulated data can exhaust memory
- **Partial failure recovery:** Never assume a stage completed successfully - always check final checkpoints
- **Resource contention:** Multiple stages competing for disk I/O can hurt overall performance

## Questions to Ponder

1. How do we handle dependencies between stages?
2. What's the optimal batch size for different stage types?
3. How do we coordinate resource usage across parallel stages?
4. Should stages be able to skip blocks already processed by other nodes?
5. How do we handle stage-specific optimizations without breaking the abstraction?

Remember: The power of staged sync comes from specialization. Each stage does one thing really well, making the entire pipeline fast and maintainable!