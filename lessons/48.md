# Lesson 48: Transaction Lookup Stage

*"Study hard what interests you the most in the most undisciplined, irreverent and original manner possible." - Richard Feynman*

## Files with Inline Comments for This Lesson
- `crates/stages/stages/src/stages/tx_lookup.rs` - Transaction lookup stage
- `crates/db-api/src/tables/mod.rs` - TransactionHashNumbers table
- `crates/etl/src/collector.rs` - ETL collector for batch processing
- `crates/provider/src/providers/database/provider.rs` - Transaction queries
- `crates/static-file/static-file/src/segments/transactions.rs` - Transaction storage

## What is the Transaction Lookup Stage?

The transaction lookup stage creates an index from transaction hashes to their locations. Without this index, finding a transaction by its hash would require scanning the entire blockchain. It's like creating a phone book where you can look up someone's address by their name.

```
Transaction Lookup Index:
┌─────────────────────────────────────────────────┐
│           Transactions in Blocks                │
│  Block 1: [Tx1, Tx2, Tx3]                      │
│  Block 2: [Tx4, Tx5]                           │
│  Block 3: [Tx6, Tx7, Tx8, Tx9]                 │
└─────────────────────┬───────────────────────────┘
                      │ Extract hashes
┌─────────────────────▼───────────────────────────┐
│         Transaction Hash → Number Map           │
│  hash(Tx1) → 0                                 │
│  hash(Tx2) → 1                                 │
│  hash(Tx3) → 2                                 │
│  hash(Tx4) → 3                                 │
│  hash(Tx5) → 4                                 │
│  hash(Tx6) → 5                                 │
│  ...                                           │
└─────────────────────────────────────────────────┘

Query: "Find transaction 0xabc..."
Result: Transaction #5, which is in Block 3
```

## The Transaction Lookup Stage Implementation

The stage processes transactions in chunks using ETL:

```rust
/// Transaction lookup stage implementation
/// Located in: crates/stages/stages/src/stages/tx_lookup.rs

use reth_etl::Collector;
use reth_stages_api::{Stage, ExecInput, ExecOutput, StageError};

/// LESSON 48: Transaction Lookup Stage
/// Creates hash → number mappings for fast transaction queries
#[derive(Debug, Clone)]
pub struct TransactionLookupStage {
    /// Maximum entries to buffer before writing
    chunk_size: u64,
    /// ETL configuration for temporary files
    etl_config: EtlConfig,
    /// Optional pruning configuration
    prune_mode: Option<PruneMode>,
}

impl Default for TransactionLookupStage {
    fn default() -> Self {
        Self {
            // 5 million entries before flushing to disk
            chunk_size: 5_000_000,
            etl_config: EtlConfig::default(),
            prune_mode: None,
        }
    }
}

impl<Provider> Stage<Provider> for TransactionLookupStage
where
    Provider: DBProvider + TransactionsProviderExt,
{
    fn execute(&mut self, provider: &Provider, mut input: ExecInput) -> Result<ExecOutput, StageError> {
        // LESSON 48: Pruning Check
        // Handle pruning configuration if set
        if let Some((target_prunable_block, prune_mode)) = self.calculate_prune_target(&input)? {
            if target_prunable_block > input.checkpoint().block_number {
                // Skip already pruned blocks
                input.checkpoint = Some(StageCheckpoint::new(target_prunable_block));
                
                // Save pruning checkpoint
                self.save_prune_checkpoint(provider, target_prunable_block, prune_mode)?;
            }
        }
        
        if input.target_reached() {
            return Ok(ExecOutput::done(input.checkpoint()));
        }
        
        // LESSON 48: ETL Collector
        // Use ETL for efficient batch processing
        let mut hash_collector: Collector<TxHash, TxNumber> = Collector::new(
            self.etl_config.file_size,  // 500MB temporary files
            self.etl_config.dir.clone()
        );
        
        info!(
            target: "sync::stages::transaction_lookup",
            tx_range = ?input.checkpoint().block_number..=input.target(),
            "Updating transaction lookup"
        );
        
        // Process transactions in chunks
        loop {
            // LESSON 48: Chunk Processing
            // Get next chunk based on transaction count threshold
            let (tx_range, block_range, is_final_range) = 
                input.next_block_range_with_transaction_threshold(
                    provider,
                    self.chunk_size
                )?;
            
            let end_block = *block_range.end();
            
            info!(
                target: "sync::stages::transaction_lookup",
                ?tx_range,
                "Calculating transaction hashes"
            );
            
            // LESSON 48: Hash Collection
            // Extract hash → number mappings
            for (hash, tx_number) in provider.transaction_hashes_by_range(tx_range)? {
                hash_collector.insert(hash, tx_number)?;
            }
            
            // Update checkpoint
            input.checkpoint = Some(
                StageCheckpoint::new(end_block)
                    .with_entities_stage_checkpoint(stage_checkpoint(provider)?)
            );
            
            if is_final_range {
                // Write all collected hashes to database
                self.write_hash_index(provider, &mut hash_collector)?;
                break;
            }
        }
        
        Ok(ExecOutput {
            checkpoint: StageCheckpoint::new(input.target())
                .with_entities_stage_checkpoint(stage_checkpoint(provider)?),
            done: true,
        })
    }
}
```

## Writing the Hash Index

The collected hashes are written efficiently:

```rust
impl TransactionLookupStage {
    /// LESSON 48: Batch Writing
    /// Write collected hashes to the database
    fn write_hash_index(
        &self,
        provider: &Provider,
        hash_collector: &mut Collector<TxHash, TxNumber>,
    ) -> Result<(), StageError> {
        // Check if we're appending to empty table (optimization)
        let append_only = provider
            .count_entries::<tables::TransactionHashNumbers>()?
            .is_zero();
            
        let mut txhash_cursor = provider
            .tx_ref()
            .cursor_write::<tables::TransactionHashNumbers>()?;
        
        let total_hashes = hash_collector.len();
        let interval = (total_hashes / 10).max(1);
        
        // LESSON 48: Progress Reporting
        // Report progress during large writes
        for (index, hash_to_number) in hash_collector.iter()?.enumerate() {
            let (hash, number) = hash_to_number?;
            
            if index > 0 && index % interval == 0 {
                info!(
                    target: "sync::stages::transaction_lookup",
                    ?append_only,
                    progress = %format!("{:.2}%", (index as f64 / total_hashes as f64) * 100.0),
                    "Inserting hashes"
                );
            }
            
            // LESSON 48: Append vs Insert
            // Use append for better performance on empty table
            if append_only {
                txhash_cursor.append(hash, &number)?;
            } else {
                txhash_cursor.insert(hash, &number)?;
            }
        }
        
        trace!(
            target: "sync::stages::transaction_lookup",
            total_hashes,
            "Transaction hashes inserted"
        );
        
        Ok(())
    }
}
```

## Unwinding the Stage

During reorgs, remove hash mappings:

```rust
impl TransactionLookupStage {
    fn unwind(&mut self, provider: &Provider, input: UnwindInput) -> Result<UnwindOutput, StageError> {
        let (range, unwind_to, _) = input.unwind_block_range_with_threshold(self.chunk_size);
        
        // LESSON 48: Reverse Iteration
        // Walk backwards through blocks to unwind
        let mut tx_hash_cursor = provider
            .tx_ref()
            .cursor_write::<tables::TransactionHashNumbers>()?;
            
        let static_file_provider = provider.static_file_provider();
        
        // Get block bodies in reverse order
        let rev_walker = provider
            .block_body_indices_range(range.clone())?
            .into_iter()
            .zip(range.collect::<Vec<_>>())
            .rev();
        
        for (body, number) in rev_walker {
            if number <= unwind_to {
                break;
            }
            
            // LESSON 48: Transaction Deletion
            // Delete all transactions in this block
            for tx_id in body.tx_num_range() {
                if let Some(transaction) = static_file_provider.transaction_by_id(tx_id)? {
                    // Remove hash → number mapping
                    if tx_hash_cursor.seek_exact(transaction.hash())?.is_some() {
                        tx_hash_cursor.delete_current()?;
                    }
                }
            }
        }
        
        Ok(UnwindOutput {
            checkpoint: StageCheckpoint::new(unwind_to)
                .with_entities_stage_checkpoint(stage_checkpoint(provider)?),
        })
    }
}
```

## Checkpoint Calculation

Track progress including pruned entries:

```rust
/// LESSON 48: Progress Tracking
/// Calculate stage checkpoint accounting for pruning
fn stage_checkpoint<Provider>(provider: &Provider) -> Result<EntitiesCheckpoint, StageError>
where
    Provider: PruneCheckpointReader + StaticFileProviderFactory + StatsReader,
{
    // Get number of pruned entries
    let pruned_entries = provider
        .get_prune_checkpoint(PruneSegment::TransactionLookup)?
        .and_then(|checkpoint| checkpoint.tx_number)
        // +1 because TxNumber is 0-indexed
        .map(|tx_number| tx_number + 1)
        .unwrap_or_default();
        
    Ok(EntitiesCheckpoint {
        // LESSON 48: Pruning Adjustment
        // Add pruned entries to get accurate processed count
        processed: provider.count_entries::<tables::TransactionHashNumbers>()? as u64 
            + pruned_entries,
        // Total from static files (source of truth)
        total: provider
            .static_file_provider()
            .count_entries::<tables::Transactions>()? as u64,
    })
}
```

## Transaction Provider Extension

How the provider fetches transaction hashes:

```rust
/// LESSON 48: Transaction Hash Extraction
impl TransactionsProviderExt for DatabaseProvider {
    fn transaction_hashes_by_range(
        &self,
        range: Range<TxNumber>,
    ) -> Result<Vec<(TxHash, TxNumber)>, ProviderError> {
        let static_file_provider = self.static_file_provider();
        let mut hashes = Vec::with_capacity(range.len());
        
        for tx_number in range {
            if let Some(transaction) = static_file_provider.transaction_by_id(tx_number)? {
                hashes.push((transaction.hash(), tx_number));
            }
        }
        
        Ok(hashes)
    }
    
    fn transaction_id(&self, hash: TxHash) -> Result<Option<TxNumber>, ProviderError> {
        // Use the lookup table we're building!
        self.tx_ref()
            .get::<tables::TransactionHashNumbers>(hash)
            .map_err(Into::into)
    }
}
```

## Summary

The transaction lookup stage creates a critical index that maps transaction hashes to their sequential numbers. This enables fast transaction queries by hash, which is essential for RPC endpoints like `eth_getTransactionByHash`. The stage uses ETL for efficient batch processing and supports pruning for nodes that don't need full history.

## Assignments

### Assignment 1: Hash Collector Stats
Create a function that reports ETL collector statistics:

```rust
fn report_collector_stats(collector: &Collector<TxHash, TxNumber>) {
    // TODO: Report size, entry count, memory usage
}
```

### Assignment 2: Chunk Size Calculator
Implement dynamic chunk size based on available memory:

```rust
fn calculate_optimal_chunk_size(available_memory: usize) -> u64 {
    // TODO: Calculate chunk size based on memory
}
```

### Assignment 3: Transaction Query Cache
Create a simple LRU cache for transaction lookups:

```rust
struct TxLookupCache {
    cache: LruCache<TxHash, TxNumber>,
}

impl TxLookupCache {
    fn get(&mut self, hash: &TxHash) -> Option<&TxNumber> {
        // TODO: Implement cache lookup
    }
    
    fn insert(&mut self, hash: TxHash, number: TxNumber) {
        // TODO: Implement cache insertion
    }
}
```

## Questions to Ponder

1. Why does the stage use ETL instead of writing directly to the database?
2. How does append-only mode improve performance for initial sync?
3. What happens to the lookup index when transactions are pruned?
4. Why are transaction hashes stored separately from transaction data?
5. How does chunking help with memory management during indexing?

## Assignment Answers

### Answer 1: Hash Collector Stats

```rust
use reth_etl::Collector;
use alloy_primitives::{TxHash, TxNumber};

fn report_collector_stats(collector: &Collector<TxHash, TxNumber>) {
    let entry_count = collector.len();
    
    // Estimate memory usage
    // TxHash = 32 bytes, TxNumber = 8 bytes
    let entry_size = 32 + 8;
    let estimated_memory = entry_count * entry_size;
    
    // ETL uses temporary files when buffer is full
    let buffer_usage = if entry_count > 0 {
        (collector.buffer_size_hint() as f64 / collector.max_buffer_size() as f64) * 100.0
    } else {
        0.0
    };
    
    info!(
        target: "sync::stages::transaction_lookup",
        entries = entry_count,
        memory_mb = estimated_memory / (1024 * 1024),
        buffer_usage = %format!("{:.1}%", buffer_usage),
        "ETL collector statistics"
    );
    
    // Detailed breakdown
    if entry_count > 1_000_000 {
        info!(
            target: "sync::stages::transaction_lookup",
            millions = entry_count / 1_000_000,
            remainder = entry_count % 1_000_000,
            "Large collection: {} million + {} entries",
            entry_count / 1_000_000,
            entry_count % 1_000_000
        );
    }
}

// Extended version with file stats
fn report_collector_stats_detailed(
    collector: &Collector<TxHash, TxNumber>,
    etl_dir: &Path,
) -> Result<CollectorStats, StageError> {
    let stats = CollectorStats {
        entry_count: collector.len(),
        memory_bytes: collector.len() * 40, // 32 + 8 bytes per entry
        buffer_usage_percent: collector.buffer_usage_percent(),
        temp_files: count_temp_files(etl_dir)?,
        temp_file_size: calculate_temp_file_size(etl_dir)?,
    };
    
    debug!(target: "sync::stages::transaction_lookup", ?stats, "Detailed collector stats");
    
    Ok(stats)
}

struct CollectorStats {
    entry_count: usize,
    memory_bytes: usize,
    buffer_usage_percent: f64,
    temp_files: usize,
    temp_file_size: u64,
}
```

### Answer 2: Chunk Size Calculator

```rust
fn calculate_optimal_chunk_size(available_memory: usize) -> u64 {
    // Each entry is ~40 bytes (32 byte hash + 8 byte number)
    const ENTRY_SIZE: usize = 40;
    
    // Reserve 25% of memory for other operations
    const MEMORY_RESERVE_FACTOR: f64 = 0.75;
    
    // Minimum and maximum bounds
    const MIN_CHUNK_SIZE: u64 = 100_000;      // 100k entries minimum
    const MAX_CHUNK_SIZE: u64 = 50_000_000;   // 50M entries maximum
    const DEFAULT_CHUNK_SIZE: u64 = 5_000_000; // 5M entries default
    
    if available_memory == 0 {
        return DEFAULT_CHUNK_SIZE;
    }
    
    // Calculate how many entries fit in available memory
    let usable_memory = (available_memory as f64 * MEMORY_RESERVE_FACTOR) as usize;
    let max_entries = usable_memory / ENTRY_SIZE;
    
    // Convert to u64 and apply bounds
    let chunk_size = max_entries as u64;
    
    chunk_size.clamp(MIN_CHUNK_SIZE, MAX_CHUNK_SIZE)
}

// More sophisticated version considering system state
fn calculate_adaptive_chunk_size(
    available_memory: usize,
    current_throughput: f64, // entries per second
    pending_entries: u64,
) -> u64 {
    let base_chunk_size = calculate_optimal_chunk_size(available_memory);
    
    // Adjust based on throughput
    // If processing is fast, use larger chunks
    let throughput_factor = if current_throughput > 1_000_000.0 {
        1.5 // Increase chunk size by 50%
    } else if current_throughput < 100_000.0 {
        0.5 // Decrease chunk size by 50%
    } else {
        1.0
    };
    
    // Adjust based on remaining work
    // Use smaller chunks near the end for responsiveness
    let remaining_factor = if pending_entries < base_chunk_size * 2 {
        0.5
    } else {
        1.0
    };
    
    let adjusted = (base_chunk_size as f64 * throughput_factor * remaining_factor) as u64;
    
    // Ensure we make progress
    adjusted.max(MIN_CHUNK_SIZE)
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_chunk_size_calculation() {
        // 1 GB available memory
        let chunk = calculate_optimal_chunk_size(1_000_000_000);
        assert_eq!(chunk, 18_750_000); // 750MB / 40 bytes
        
        // Very little memory
        let chunk = calculate_optimal_chunk_size(10_000_000);
        assert_eq!(chunk, MIN_CHUNK_SIZE);
        
        // Huge memory
        let chunk = calculate_optimal_chunk_size(10_000_000_000);
        assert_eq!(chunk, MAX_CHUNK_SIZE);
    }
}
```

### Answer 3: Transaction Query Cache

```rust
use lru::LruCache;
use std::num::NonZeroUsize;
use parking_lot::RwLock;

struct TxLookupCache {
    cache: RwLock<LruCache<TxHash, TxNumber>>,
    hits: AtomicU64,
    misses: AtomicU64,
}

impl TxLookupCache {
    fn new(capacity: usize) -> Result<Self, &'static str> {
        let capacity = NonZeroUsize::new(capacity)
            .ok_or("Cache capacity must be non-zero")?;
            
        Ok(Self {
            cache: RwLock::new(LruCache::new(capacity)),
            hits: AtomicU64::new(0),
            misses: AtomicU64::new(0),
        })
    }
    
    fn get(&self, hash: &TxHash) -> Option<TxNumber> {
        let mut cache = self.cache.write();
        
        if let Some(&number) = cache.get(hash) {
            self.hits.fetch_add(1, Ordering::Relaxed);
            Some(number)
        } else {
            self.misses.fetch_add(1, Ordering::Relaxed);
            None
        }
    }
    
    fn insert(&self, hash: TxHash, number: TxNumber) {
        let mut cache = self.cache.write();
        cache.put(hash, number);
    }
    
    fn get_or_insert_with<F>(
        &self,
        hash: &TxHash,
        f: F,
    ) -> Result<TxNumber, StageError>
    where
        F: FnOnce() -> Result<Option<TxNumber>, StageError>,
    {
        // Fast path - check cache first
        if let Some(number) = self.get(hash) {
            return Ok(number);
        }
        
        // Slow path - fetch from database
        if let Some(number) = f()? {
            self.insert(*hash, number);
            Ok(number)
        } else {
            Err(StageError::TransactionNotFound(*hash))
        }
    }
    
    fn stats(&self) -> CacheStats {
        let hits = self.hits.load(Ordering::Relaxed);
        let misses = self.misses.load(Ordering::Relaxed);
        let total = hits + misses;
        
        CacheStats {
            hits,
            misses,
            hit_rate: if total > 0 {
                (hits as f64 / total as f64) * 100.0
            } else {
                0.0
            },
            size: self.cache.read().len(),
            capacity: self.cache.read().cap().get(),
        }
    }
    
    fn clear(&self) {
        self.cache.write().clear();
        self.hits.store(0, Ordering::Relaxed);
        self.misses.store(0, Ordering::Relaxed);
    }
}

#[derive(Debug)]
struct CacheStats {
    hits: u64,
    misses: u64,
    hit_rate: f64,
    size: usize,
    capacity: usize,
}

// Integration with provider
impl DatabaseProvider {
    fn transaction_id_with_cache(
        &self,
        hash: TxHash,
        cache: &TxLookupCache,
    ) -> Result<Option<TxNumber>, ProviderError> {
        cache.get_or_insert_with(&hash, || {
            self.tx_ref()
                .get::<tables::TransactionHashNumbers>(hash)
                .map_err(Into::into)
        })
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_tx_lookup_cache() {
        let cache = TxLookupCache::new(100).unwrap();
        
        let hash1 = TxHash::random();
        let hash2 = TxHash::random();
        
        // Test miss
        assert_eq!(cache.get(&hash1), None);
        assert_eq!(cache.stats().misses, 1);
        
        // Test insert and hit
        cache.insert(hash1, 42);
        assert_eq!(cache.get(&hash1), Some(42));
        assert_eq!(cache.stats().hits, 1);
        
        // Test multiple entries
        cache.insert(hash2, 99);
        assert_eq!(cache.get(&hash2), Some(99));
        
        let stats = cache.stats();
        assert_eq!(stats.size, 2);
        assert_eq!(stats.hits, 2);
        assert_eq!(stats.misses, 1);
    }
}
```